<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Concepts Guide: Concepts Guide</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="doxygen_manual.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Concepts Guide
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('index.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title"></div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p> 
<img src="infa_logo.png" width="400" height="138" alt="Informatica"/><br/><br/>
<big><b>Ultra Messaging</b></big> <small>(Version 6.11.1)</small><br/>
<br/><br/><br/>
<center class="mytitle">Concepts Guide</center>
<center>Copyright (C) 2004-2018, Informatica Corporation.  All Rights Reserved.</center>
<br/><br/><br/>
[&nbsp;<a href="../index.html">Multi-page HTML</a>&nbsp;]&nbsp;&nbsp;|&nbsp;&nbsp;[&nbsp;<a href="../Concepts_Guide=en.pdf">PDF</a>&nbsp;]
<br/><br/>
 </p>
<h1><a class="anchor" id="firstsect"></a>
Introduction</h1>
<p>This document introduces the basic concepts and design approaches used by Ultra Messaging.</p>
<dl class="section attention"><dt>Attention</dt><dd><b>See the <a href="../../DocIntro=en.pdf">Documentation Introduction</a> for important information on copyright, patents, information resources (including Knowledge Base, and How To articles), Marketplace, Support, and other information about Informatica and its products.</b></dd></dl>
<p>Ultra Messaging comprises a software layer, supplied in the form of a dynamic library (shared object), which provides applications with message delivery functionality that adds considerable value to the basic networking services contained in the host operating system. The UMP and UMQ products also include a "store" daemon that implements Persistence. The UMQ product also includes a "broker" daemon that implements Brokered Queuing.</p>
<p>Applications access Ultra Messaging features through the Ultra Messaging Application Programming Interface (API).</p>
<p>Ultra Messaging includes the following APIs: the UM C API, the UM Java API, and the UM .NET API. These APIs are very similar, and for the most part this document concentrates on the C API. The translation from C functions to Java or .NET methods should be reasonably straightforward; see the UM Quick Start Guide for sample applications in Java and .NET. The UMQ product also supports the JMS API.</p>
<p>The three most important design goals of Ultra Messaging are to minimize message latency (the time that a given message spends "in transit"), maximize throughput, and insure delivery of all messages under a wide variety of operational and failure scenarios. Ultra Messaging achieves these goals by not duplicating services provided by the underlying network whenever possible. Instead of implementing special messaging servers and daemons to receive and re-transmit messages, Ultra Messaging routes messages primarily with the network infrastructure at wire speed. Placing little or nothing in between the sender and receiver is an important and unique design principle of Ultra Messaging.</p>
<p>See <a class="el" href="index.html#umglossary">UM Glossary</a> for Ultra Messaging terminology, abbreviations, and acronyms.</p>
<p><br />
 </p>
<h1><a class="anchor" id="fundamentalconcepts"></a>
Fundamental Concepts</h1>
<p>A UM application can function either as a source or a receiver. A source application sends messages, and a receiver application receives them. (It is also common for an application to function as both source and receiver; we separate the concepts for organizational purposes.)</p>
<p><br />
 </p>
<h2><a class="anchor" id="topicstructureandmanagement"></a>
Topic Structure and Management</h2>
<p>UM offers the Publish/Subscribe model for messaging ("Pub/Sub"), whereby one or more receiver programs express interest in a topic ("subscribe"), and one or more source programs send to that topic ("publish"). So, a topic can be thought of as a data stream that can have multiple producers and multiple consumers. One of the functions of the messaging layer is to make sure that all messages sent to a given topic are distributed to all receivers listening to that topic. UM does this through an automatic process known as topic resolution.</p>
<p>A topic is just an arbitrary string. For example:</p>
<pre class="fragment">Orders
Market/US/DJIA/Sym1
</pre><p>It is not unusual for an application system to have many thousands of topics, perhaps even more than a million, with each one carrying a very specific range of information (e.g. quotes for a single stock symbol).</p>
<p>It is also possible to configure receiving programs to match multiple topics using wildcards. UM uses powerful regular expression pattern matching to allow applications to match topics in a very flexible way. Messages cannot be <em>sent</em> to wildcarded topic names. See <a class="el" href="index.html#umwildcardreceivers">UM Wildcard Receivers</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="topicresolutionoverview"></a>
Topic Resolution Overview</h3>
<p>Topic Resolution ("TR") is the process by which subscribers discover publishers for their topics of interest. Once discovered, a subscriber will join those publishers' data streams.</p>
<p>The process operates by newly started publishers sending a series of <em>Advertisements</em> in the form of Topic Information Records (TIRs). These advertisements are carried on a pre-configured Topic Resolution channel (usually a multicast group, although there is a <a class="el" href="index.html#unicasttopicresolution">unicast alternative</a>, described later.) All applications are expected to connect to the same TR channel.</p>
<p>As publishers send these TIRs (advertisements) out the TR channel, subscribers will receive them and determine if they are of interest. If so, the subscribers initiate a connection to the publisher's data stream.</p>
<p>In addition, newly started subscribers send a series of <em>Queries</em> in the form of Topic Query Records (TQRs) over the same TR channel. The purpose of TQRs is essentially to trigger publishers of the interested topics to send the corresponding TIRs as soon as possible.</p>
<p>For details, see <a class="el" href="index.html#topicresolutiondescription">Topic Resolution Description</a>.</p>
<p><br />
 </p>
<h2><a class="anchor" id="persistence"></a>
Persistence</h2>
<p>The UMP and UMQ products include a component known as the Persistent Store, which provides stable storage (disk or memory) of message streams. UM delivers a persisted message stream to receiving applications with no additional latency in the vast majority of cases. This offers the functionality of durable subscriptions and confirmed message delivery. Ultra Messaging Streaming applications build and run with the Persistence feature without modification. For more information, see the <a href="../../UME/UM_Guide_for_Persistence=en.pdf">UM Guide for Persistence</a>.</p>
<p><br />
 </p>
<h2><a class="anchor" id="queuing"></a>
Queuing</h2>
<p>The UMQ product, which contains Streaming and Persistence functionality, also includes message queuing capabilities. See <a href="../../UMQ/index.html">UM Guide to Queuing</a> for more information.</p>
<p><br />
 </p>
<h2><a class="anchor" id="umrouter"></a>
UM Router</h2>
<p>The Ultra Messaging Dynamic Routing Option (DRO) consists of a daemon called the "UM Router" (or just the DRO) that bridges disjoint Topic Resolution Domains (TRDs) by effectively forwarding control and user traffic between them. Thus, the UM Router facilitates WAN routing where multicast routing capability is absent, possibly due to technical obstacles or enterprise policies.</p>
<p>The UM Router transfers multicast and/or unicast topic resolution information, thus ensuring that receivers in disjoint topic resolution domains from the source can receive the topic messages to which they subscribe.</p>
<p>See The <a href="../../Gateway/index.html">Dynamic Routing Guide</a> for more information.</p>
<p><br />
 </p>
<h2><a class="anchor" id="latejoin"></a>
Late Join</h2>
<p>In many applications, a new receiver may be interested in messages that were sent before the receiver was created. The Ultra Messaging Late Join feature allows a new receiver to obtain previously-sent messages from a source. Without the Late Join feature, the receiver would only deliver messages sent after the receiver successfully subscribes. With Late Join, the source locally stores recently sent messages according to its Late Join configuration options, and a new receiver is able to retrieve these messages.</p>
<p>Source-side configuration options:</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#latejoinsource">late_join (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#retransmitretentionagethresholdsource">retransmit_retention_age_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizelimitsource">retransmit_retention_size_limit (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpinterfacecontext">request_tcp_interface (context)</a> </li>
</ul>
<p>Receiver-side configuration options:</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#uselatejoinreceiver">use_late_join (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestintervalreceiver">retransmit_request_interval (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestmessagetimeoutreceiver">retransmit_request_message_timeout (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestoutstandingmaximumreceiver">retransmit_request_outstanding_maximum (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#latejoininforequestintervalreceiver">late_join_info_request_interval (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#latejoininforequestmaximumreceiver">late_join_info_request_maximum (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitinitialsequencenumberrequestreceiver">retransmit_initial_sequence_number_request (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresponseoperation.html#responsetcpinterfacecontext">response_tcp_interface (context)</a> </li>
</ul>
<dl class="section note"><dt>Note</dt><dd>With <a class="el" href="index.html#smartsources">Smart Sources</a>, the following configuration options have limited or no support: <ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizelimitsource">retransmit_retention_size_limit (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#retransmitretentionagethresholdsource">retransmit_retention_age_threshold (source)</a> </li>
</ul>
</dd>
<dd>
You cannot use Late Join with Queuing functionality (UMQ).</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="requestresponse"></a>
Request/Response</h2>
<p>Ultra Messaging also offers a Request/Response messaging model. A sending application (the requester) sends a message to a topic. Every receiving application listening to that topic gets a copy of the request. One or more of those receiving applications (responder) can then send one or more responses back to the original requester. Ultra Messaging sends the request message via the normal pub/sub method, whereas Ultra Messaging delivers the response message directly to the requester.</p>
<p>An important aspect of the Ultra Messaging Request/Response model is that it allows the application to keep track of which request corresponds to a given response. Due to the asynchronous nature of Ultra Messaging requests, any number of requests can be outstanding, and as the responses come in, they can be matched to their corresponding requests.</p>
<p>Request/Response can be used in many ways and is often used during the initialization of Ultra Messaging receiver objects. When an application starts a receiver, it can issue a request on the topic the receiver is interested in. Source objects for the topic can respond and begin publishing data. This method prevents the Ultra Messaging source objects from publishing to a topic without subscribers.</p>
<p>Be careful not to be confused with the sending/receiving terminology. Any application can send a request, including one that creates and manages Ultra Messaging receiver objects. And any application can receive and respond to a request, including one that creates and manages Ultra Messaging source objects.</p>
<dl class="section note"><dt>Note</dt><dd>You cannot use Request/Response with Queuing functionality (UMQ).</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="umtransports"></a>
UM Transports</h2>
<p>A source application uses a UM transport to send messages to a receiver application. A Ultra Messaging transport is built on top of a standard IP protocol. The different Ultra Messaging transport types have different trade offs in terms of latency, scalability, throughput, bandwidth sharing, and flexibility. The sending application chooses the transport type that is most appropriate for the data being sent, at the topic level. A programmer might choose different transport types for different topics within the same application.</p>
<p>An Ultra Messaging sending application can make use of very many topics - possibly over a million. Ultra Messaging maps those topics onto a much smaller number of transport sessions. A transport session can be thought of as a specific instance of a transport type. A given transport session might carry a single topic, or might carry hundreds of thousands of topics. A receiving application might express interest in a small set of those topics, in which case Ultra Messaging joins the transport session and receives messages for all topics carried on that transport session. Ultra Messaging then discards any messages for topics that the application is not interested in. This user-space filtering does consume system resources (primarily CPU and bandwidth), and can be minimized by carefully mapping topics onto transport sessions according to receiving application interest.</p>
<p>When Ultra Messaging sets up a transport session and receives the first data over the live data stream, Ultra Messaging generates a BOS (Beginning Of Session) to all receivers that currently exist. When a receiver joins an active transport, this immediately generates a BOS event. When the last topic on a transport session concludes or when a transport path is broken in the network (also referred to as a TCP breakage), Ultra Messaging tears down the transport session and notifies all receivers with an EOS (End Of Session) event. There is no correlation between the deletion of a source by an application and when an EOS is received by a receiver, except if it is the last source sharing the transport.</p>
<p>Be aware that in a deployment that includes the UM Router, BOS and EOS may only indicate the link between the receiver and the local UM Router portal, not necessarily full end-to-end connectivity.</p>
<dl class="section note"><dt>Note</dt><dd>Non-multicast Ultra Messaging transport types can use source-side filtering to decrease user-space filtering on the receiving side by doing the filtering on the sending side. However, be aware that system resources consumed on the source side affect all receivers, and that the filtering for multiple receivers must be done serially, whereas letting the receivers do the filtering allows that filtering to be done in parallel, only affecting those receivers that need the filtering.</dd></dl>
<p>With the UMQ product, a ULB source makes use of the same transport types as Streaming, but a Brokered Queuing source must use the <b>broker</b> transport.</p>
<p><br />
 </p>
<h3><a class="anchor" id="multitransportthreads"></a>
Multi-Transport Threads</h3>
<dl class="section note"><dt>Note</dt><dd>The "Multi-Transport Threads" feature is deprecated as of UM version 6.9 and may be eliminated from a future UM version. It is replaced in UM version 6.11 by <a class="el" href="index.html#transportservicesproviderxsp">Transport Services Provider (XSP)</a>.</dd></dl>
<p>Part of UM's design is a single threaded model for message data delivery which reduces latency in the receiving CPU. UM, however, also has the ability to distribute data delivery across multiple CPUs by using a receiving thread pool. Receivers created with the configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#usetransportthreadreceiver">use_transport_thread (receiver)</a> set to 1 use a thread from the thread pool instead of the context thread. The option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#receivethreadpoolsizecontext">receive_thread_pool_size (context)</a> controls the pool size.</p>
<p>As receivers discover new sources through Topic Resolution, UM assigns the network sockets created for the receivers to receive data to either the context thread (default) or to a thread from the pool if <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#usetransportthreadreceiver">use_transport_thread (receiver)</a> is set for the receiver. It is important to understand that thread assignment occurs at the socket level - not the transport level. Transports aggregated on to the same network socket use the same thread.</p>
<p>UM distributes data from different sockets to different threads allowing better process distribution and higher aggregate throughput. Distributing transports across threads also ensures that activity on each transport has no impact on transports assigned to other threads leading to lower latencies in some traffic patterns, e.g. heavy loss conditions.</p>
<p>The following lists restrictions to using multi-transport threads:</p>
<ul>
<li>
Only LBT-RM, LBT-RU, TCP and TCP-LB transport types may be distributed to threads. </li>
<li>
Multi-Transport threads are not supported under sequential mode . </li>
<li>
UM processes sources using the same transport socket, e.g. multicast address and port, on the same thread (regardless of the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#usetransportthreadreceiver">use_transport_thread (receiver)</a> setting. To leverage threading of different sources, assign each source to a different transport destination, e.g. multicast address/port. </li>
<li>
Hot failover sources using LBT-RM on the same topic must not be distributed across threads because they must share the same multicast address and port. </li>
<li>
Hot failover sources using other transport types may not be distributed across threads and must use the context thread. </li>
<li>
Each transport thread has its own Unicast Listener (request) port. Ultra Messaging recommends that you expand the range <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpportlowcontext">request_tcp_port_low (context)</a> - <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpporthighcontext">request_tcp_port_high (context)</a> to a larger range when using transport threads. When late join is occurring, UM creates a TCP connection from the transport thread to the source. </li>
<li>
Multi-transport threads are not recommended for use over the UM Router. </li>
<li>
Multi-Transport Threads do not support Persistent Stores or Persistent receivers (UMP/UMQ products). </li>
<li>
Multi-Transport Threads do not support or queuing receivers (UMQ product). </li>
<li>
Multi-Transport Threads are not compatible with UMDS Server or UMCache </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="eventdelivery"></a>
Event Delivery</h2>
<p>There are many different events that UM may want to deliver to the application. Many events carry data with them (e.g. received messages); some do not (e.g. end-of-stream events). Some examples of UM events:</p>
<ul>
<li>
A received message on a topic that the application has expressed interest in. </li>
<li>
A timer expiring. Applications can schedule timers to expire in a desired number of milliseconds (although the OS may not deliver them with millisecond precision). </li>
<li>
An application-managed file descriptor event. The application can register its own file descriptors with UM to be monitored for state changes (readable, writable, error, etc.). </li>
<li>
New source notification. UM can inform the application when sources are discovered by Topic Resolution. </li>
<li>
Receiver loss. UM can inform the application when a data gap is detected that could not be recovered through the normal retransmission mechanism. </li>
<li>
End of Stream. UM can inform a receiving application when a data stream (transport session) has terminated. </li>
</ul>
<p>UM delivers events to the application by callbacks. The application explicitly gives UM a pointer to one of its functions to be the handler for a particular event, and UM calls that function to deliver the event, passing it the parameters that the application requires to process the event. In particular, the last parameter of each callback type is a client data pointer (clientdp). This pointer can be used at the application's discretion for any purpose. It's value is specified by the application when the callback function is identified to UM (typically when UM objects are created), and that same value is passed back to the application when the callback function is called.</p>
<p>There are two methods that UM can use to call the application callbacks: through context thread callback, or event queue dispatch.</p>
<p>In the context thread callback method (sometimes called direct callback), the UM context thread calls the application function directly. This offers the lowest latency, but imposes significant restrictions on the application function. See <a class="el" href="index.html#eventqueueobject">Event Queue Object</a>.</p>
<p>The event queue dispatch of application callback introduces a dynamic buffer into which the UM context thread writes events. The application then uses a thread of its own to dispatch the buffered events. Thus, the application callback functions are called from the application thread, not directly from the context thread.</p>
<p>With event queue dispatching, the use of the application thread to make the callback allows the application function to make full, unrestricted use of the UM API. It also allows parallel execution of UM processing and application processing, which can significantly improve throughput on multi-processor hardware. The dynamic buffering provides resilience between the rate of event generation and the rate of event consumption (e.g. message arrival rate v.s. message processing rate).</p>
<p>In addition, an UM event queue allows the application to be warned when the queue exceeds a threshold of event count or event latency. This allows the application to take corrective action if it is running too slow, such as throwing away all events older than a threshold, or all events that are below a given priority.</p>
<p><br />
 </p>
<h2><a class="anchor" id="ratecontrols"></a>
Rate Controls</h2>
<p>For UDP-based communications (LBT-RU, LBT-RM, and <a class="el" href="index.html#topicresolutionoverview">Topic Resolution</a>), UM network stability is ensured through the use of rate controls. Without rate controls, sources can send UDP data so fast that the network can be flooded. Using rate controls, the source's bandwidth usage is limited. If the source attempts to exceed its bandwidth allocation, it is slowed down.</p>
<p>Setting the rate controls properly requires some planning; see <a href="https://www.informatica.com/downloads/1568_high_perf_messaging_wp/Topics-in-High-Performance-Messaging.htm#GROUP-RATE-CONTROL">Topics in High Performance Messaging, Group Rate Control</a> for details.</p>
<p>Ultra Messaging's rate limiter algorithms are based on dividing time into intervals (configurable), and only allowing a certain number of bits of data to be sent during each interval. That number is divided by the number of intervals per second. For example, a limit of 1,000,000 bps and an interval of 100 ms results in the limiter allowing 100,000 bits to be sent during each interval. Dividing by 8 to get bytes gives 12,500 bytes per interval.</p>
<p>Data are not sent over a network as individual bytes, but rather are grouped into datagrams. Since it is not possible to send only part of a datagram, the rate limiter algorithm needs to decide what to do if an outgoing datagram would exceed the number of bits allowed during the current time interval. The data transport rate limiter algorithm, for LBT-RM and LBT-RU, differs from the Topic Resolution rate limiter algorithm.</p>
<p><br />
 </p>
<h3><a class="anchor" id="transportratecontrol"></a>
Transport Rate Control</h3>
<p>With data transport, if an outgoing datagram would exceed the number of bits allowed during the current time interval, that datagram is queued and the transport type is put into a "blocked" state in the current context. Any subsequent sends within the same time interval will not queue, but instead will either block (for blocking sends), or return <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a75f0f83b8684df30d9816210cc20b4b0">LBM_EWOULDBLOCK</a> (for non-blocking sends). When the time interval expires, the context thread will refresh the number of allowable bits, send the queued datagram, and unblock the transport type.</p>
<p>Note that for very small settings of transport rate limit, the end-of-interval refresh of allowable bits may still not be enough to send a queued full datagram. In that case, the datagram will remain on the queue for additional intervals to pass, until enough bits have accumulated to send the queued datagram. However, it would be very unusual for a transport rate limit to be set that small.</p>
<p>Configuration parameters of interest are: </p><ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmrateintervalcontext">transport_lbtrm_rate_interval (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmdataratelimitcontext">transport_lbtrm_data_rate_limit (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmretransmitratelimitcontext">transport_lbtrm_retransmit_rate_limit (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtruoperation.html#transportlbtrurateintervalcontext">transport_lbtru_rate_interval (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtruoperation.html#transportlbtrudataratelimitcontext">transport_lbtru_data_rate_limit (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtruoperation.html#transportlbtruretransmitratelimitcontext">transport_lbtru_retransmit_rate_limit (context)</a> </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="topicresolutionratecontrol"></a>
Topic Resolution Rate Control</h3>
<p>With Topic Resolution ("TR"), the algorithm acts differently. It is designed to allow at least one datagram per time interval, and is allowed to exceed the rate limit by at most one topic's worth. Thus, the TR rate limiter value should only be considered a "reasonably accurate" approximation.</p>
<p>This approximation can seem very inaccurate at very small rate limits. As an extreme example, suppose that a user configures a rate limiter to 1 bit per second. Since the TR rate limiter allows at least one Advertisement (TIR) to be sent per interval, and a TIR of a 240-character topic creates a datagram about 400 bytes long (exact size depends on user options), ten of those per second is 32,000 bits, which is over 3 million percent of the desired rate. This sounds extreme, but understand that this works out to only 10 packets per second, a trivial load for modern networks. In practice, the minimum <em>effective</em> rate limit works out to be one datagram per interval.</p>
<p>For details of Topic Resolution, see <a class="el" href="index.html#topicresolutiondescription">Topic Resolution Description</a>.</p>
<p><br />
 </p>
<h2><a class="anchor" id="operationalstatistics"></a>
Operational Statistics</h2>
<p>UM maintains a variety of transport-level statistics which gives a real-time snapshot of UM's internal handling. For example, it gives counts for transport messages transferred, bytes transferred, retransmissions requested, unrecoverable loss, etc.</p>
<p>The UM monitoring API provides framework to allow the convenient gathering and transmission of UM statistics to a central monitoring point. For more information, see the <a href="../../Config/index.html">UM Configuration Guide</a>.</p>
<p><br />
 </p>
<h1><a class="anchor" id="umobjects"></a>
UM Objects</h1>
<p>Many UM documents use the term object. Be aware that with the C API, they do not refer to formal objects as supported by C++ (i.e. class instances). The term is used here in an informal sense to denote an entity that can be created, used, and (usually) deleted, has functionality and data associated with it, and is managed through the API. The handle that is used to refer to an object is usually implemented as a pointer to a data structure (defined in <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html">lbm.h</a>), but the internal structure of an object is said to be opaque, meaning that application code should not read or write the structure directly.</p>
<p>However, the UM Java JNI and C# .NET APIs are object oriented, with formal Java/C# objects. See the Java API documentation and .NET API documentation for more information.</p>
<p><br />
 </p>
<h2><a class="anchor" id="contextobject"></a>
Context Object</h2>
<p>A UM context object conceptually is an environment in which UM runs. An application creates a context, typically during initialization, and uses it for most other UM operations. In the process of creating the context, UM normally starts an independent thread (the context thread) to do the necessary background processing such as the following: </p><ul>
<li>
Topic resolution </li>
<li>
Enforce rate controls for sending messages </li>
<li>
Manage timers </li>
<li>
Manage state </li>
<li>
Implement UM protocols </li>
<li>
Manage transport sessions </li>
</ul>
<p>You create a context with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8058947690bd0995bc2c59d4a61b462f">lbm_context_create()</a>. When an application is finished with the context (no more message passing needed), it should delete the context by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a962bfceb336c65191ba08497ac70602b">lbm_context_delete()</a>.</p>
<dl class="section warning"><dt>Warning</dt><dd>Before deleting a context, you must first delete all objects contained within that context (sources, receivers, wildcard receivers).</dd></dl>
<p>Your application can give a context a name, which are optional but should be unique across your UM network. You set a context name before calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8058947690bd0995bc2c59d4a61b462f">lbm_context_create()</a> in the following ways:</p>
<ul>
<li>
If you are using XML UM configuration files, call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a3a97ec59981f5b863b0b40faf82eceb8">lbm_context_attr_set_from_xml()</a> or <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a04d99cc97d32f359888c5befcc50512e">lbm_context_attr_create_from_xml()</a> and set the name in the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#contextnamecontext">context_name (context)</a> parameter. </li>
<li>
If you are using plain text UM configuration files, call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab67f641d5a0ad1a9fe53d415da58d961">lbm_context_attr_setopt()</a> and specify <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#contextnamecontext">context_name (context)</a> as the optname and the context's name as the optval. Don't forget to set the optlen. </li>
<li>
Create a plain text UM configuration file with the option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#contextnamecontext">context_name (context)</a> set to the name of the context. </li>
</ul>
<p>Context names are optional but should be unique within a process. UM does not enforce uniqueness, rather issues a log warning if it encounters duplicate context names. Application context names are only used to load template and individual option values within an XML UM configuration file.</p>
<p>One of the more important functions of a context is to hold configuration information that is of context scope. See the <a href="../../Config/index.html">UM Configuration Guide</a> for options that are of context scope.</p>
<p>Most UM applications create a single context. However, there are some specialized circumstances where an application would create multiple contexts. For example, with appropriate configuration options, two contexts can provide separate topic name spaces. Also, multiple contexts can be used to portion available bandwidth across topic sub-spaces (in effect allocating more bandwidth to high-priority topics).</p>
<dl class="section attention"><dt>Attention</dt><dd>Regardless of the number of contexts created by your application, a good practice is to keep them open throughout the life of your application. Do not close them until you close the application.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="topicobject"></a>
Topic Object</h2>
<p>A UM topic object is conceptually very simple; it is little more than a container for a string (the topic name). However, UM uses the topic object to hold a variety of state information used by UM for internal processing. It is conceptually contained within a context. Topic objects are used by applications in the creation of <a class="el" href="index.html#sourceobject">sources</a> and <a class="el" href="index.html#receiverobject">receivers</a>.</p>
<p>Technically, the user's application does not create or delete topic objects. Their management is handled internally by UM, as needed. The application uses APIs to gain access to topic objects. A publishing application calls <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a1ba60407fa2bde0997aab6d5a5d2da1a">lbm_src_topic_alloc()</a> to get a reference to a topic object that it intends to use for creation of a <a class="el" href="index.html#sourceobject">Source Object</a>. A subscribing application calls <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a3de8a6a659896f76475c453683db4e18">lbm_rcv_topic_lookup()</a> to get a reference to a topic object that it intends to use for creation of a <a class="el" href="index.html#receiverobject">Receiver Object</a>.</p>
<p>The application does not need to explicitly tell UM when it no longer needs the topic object. The application's reference can simply be discarded.</p>
<p><br />
 </p>
<h2><a class="anchor" id="sourceobject"></a>
Source Object</h2>
<p>A UM source object is used to send messages to the topic that it is bound to. It is conceptually contained within a context.</p>
<p>You create a source object by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab8dd76271bf9df7a5f88476d431f523e">lbm_src_create()</a>. One of its parameters is a <a class="el" href="index.html#topicobject">Topic Object</a>. A source object can be bound to only one topic. The application is responsible for deleting a source object when it is no longer needed by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a29d45db8f76835b4ae78f4568c25712f">lbm_src_delete()</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="sourcestring"></a>
Source String</h3>
<p>Every source that a publishing application creates has associated with it a unique <em>source string</em>. Note that if multiple publishing UM contexts (applications) create sources for the same topic, each context's source will have its own unique source string. Similarly, if one publishing UM context (application) creates multiple sources for different topics, each topic's source will have its own unique source string. So a source string identifies one specific instance of a topic within a UM context.</p>
<p>The source string is used in a few different ways in the UM API, for example to identify which transport session to retrieve statistics for in <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a4094c703f97a7ebe340b985b2ed1ac2b">lbm_rcv_retrieve_transport_stats()</a>. The source string is made available to the application in several callbacks, for example <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a20d2e77507380a39c081a95462acb995">lbm_src_notify_function_cb</a>, or the "source" field of <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/structlbm__msg__t__stct.html">lbm_msg_t_stct</a> of a received message. See also <a class="el" href="index.html#sendingtosources">Sending to Sources</a>.</p>
<p>The format of a source string depends on the transport type: </p><ul>
<li>
<p class="startli">TCP:src_ip:src_port:session_id[topic_idx] <br />
 session_id is optional, per configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransporttcpoperation.html#transporttcpusesessionidsource">transport_tcp_use_session_id (source)</a> <br />
 example: <code>TCP:192.168.0.4:45789:f1789bcc[1539853954]</code></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">LBTRM:src_ip:src_port:session_id:mc_group:dest_port[topic_idx] <br />
 example: <code>LBTRM:10.29.3.88:14390:e0679abb:231.13.13.13:14400[1539853954]</code></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">LBT-RU:src_ip:src_port:session_id[topic_idx] <br />
 session_id is optional, per configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtruoperation.html#transportlbtruusesessionidsource">transport_lbtru_use_session_id (source)</a> <br />
 example: <code>LBT-RU:192.168.3.189:34678[1539853954]</code></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">LBT-IPC:session_id:transport_id[topic_idx] <br />
 example: <code>LBT-IPC:6481f8d4:20000[1539853954]</code></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">LBT-SMX:session_id:transport_id[topic_idx] <br />
 example: <code>LBT-SMX:6481f8d4:20000[1539853954]</code></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">LBT-RDMA:src_ip:src_port:session_id[topic_idx] <br />
 example: <code>LBT-RDMA:192.168.3.189:34678:6471e9c4[1539853954]</code></p>
<p class="endli"></p>
</li>
<li>
BROKER <br />
 example: <code>BROKER</code> </li>
</ul>
<p>Please note that the topic index field (topic_idx) may or may not be present depending on your version of UM and/or the setting for configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#sourceincludestopicindexcontext">source_includes_topic_index (context)</a>.</p>
<p>See also <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#afa35ad2c7d5d473ffeda6727022f9b94">lbm_transport_source_format()</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a30bf33dce2021f6ea8915b45f511af56">lbm_transport_source_parse()</a>.</p>
<p><b>Message Properties Performance Considerations</b></p>
<p>Ultra Messaging sends property names on the wire with every message. To reduce bandwidth requirements, minimize the length and number of properties. When coding sources, consider the following sequence of guidelines:</p>
<ol>
<li>
Allocate a data structure to store message properties objects. This can be a thread-local structure if you use a relatively small number of threads, or a thread-safe pool of objects. </li>
<li>
Before sending, retrieve a message properties object from the pool. If an object is not available, create a new object. </li>
<li>
Set properties for the message. </li>
<li>
Send the message using the appropriate API call, passing in the properties object. </li>
<li>
After the send completes, clear the message properties object and return it to the pool. </li>
</ol>
<p>When coding receivers in Java or .NET, call Dispose() on messages before returning from the application callback. This allows Ultra Messaging to internally recycle objects, and limits object allocation.</p>
<p><br />
 </p>
<h3><a class="anchor" id="sourceconfigurationandtransportsessions"></a>
Source Configuration and Transport Sessions</h3>
<p>As with contexts, a source holds configuration information that is of source scope. This includes network options, operational options and reliability options for LBT-RU and LBT-RM. For example, each source can use a different transport and would therefore configure a different network address to which to send topic messages. See the <a href="../../Config/index.html">UM Configuration Guide</a> for source configuration options.</p>
<p>As stated in <a class="el" href="index.html#umtransports">UM Transports</a>, many topics (and therefore sources) can be mapped to a single transport. Many of the configuration options for sources actually control or influence transport session activity. If many sources are sending topic messages over a single transport session (TCP, LBT-RU or LBT-RM), UM only uses the configuration options for the first source assigned to the transport.</p>
<p>For example, if the first source to use a LBT-RM transport session sets the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmreliability.html#transportlbtrmnakgenerationintervalreceiver">transport_lbtrm_nak_generation_interval (receiver)</a> to 24 MB and the second source sets the same option to 2 MB, UM assigns 24 MB to the transport session's <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmreliability.html#transportlbtrmnakgenerationintervalreceiver">transport_lbtrm_nak_generation_interval (receiver)</a>.</p>
<p>The <a href="../../Config/index.html">UM Configuration Guide</a> identifies the source configuration options that may be ignored when UM assigns the source to an existing transport session. Log file warnings also appear when UM ignores source configuration options.</p>
<p><br />
 </p>
<h3><a class="anchor" id="zeroobjectdeliverysource"></a>
Zero Object Delivery (Source)</h3>
<p>The Zero Object Delivery (ZOD) feature for Java and .NET lets sources deliver events to an application with no per-event object creation. (ZOD can also be utilized with context source events.) See <a class="el" href="index.html#zeroobjectdelivery">Zero Object Delivery</a> for information on how to employ ZOD.</p>
<p><br />
 </p>
<h2><a class="anchor" id="receiverobject"></a>
Receiver Object</h2>
<p>A UM receiver object is used to receive messages from the topic that it is bound to. It is conceptually contained within a context. Messages are delivered to the application by an application callback function, specified when the receiver object is created.</p>
<p>You create a receiver object by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aa7491c50fefbc2b70f8035fce7ac1477">lbm_rcv_create()</a>. One of its parameters is a <a class="el" href="index.html#topicobject">Topic Object</a>. A receiver object can be bound to only one topic. The application is responsible for deleting a receiver object when it is no longer needed by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8d5e8713f5ae776330b23a1e371f934d">lbm_rcv_delete()</a>.</p>
<p>Multiple receiver objects can be created for the same topic within a single context, which can be used to trigger multiple delivery callbacks when messages arrive for that topic.</p>
<p><br />
 </p>
<h3><a class="anchor" id="receiverconfigurationandtransportsessions"></a>
Receiver Configuration and Transport Sessions</h3>
<p>A receiver holds configuration information that is of receiver scope. This includes network options, operational options and reliability options for LBT-RU and LBT-RM. See the <a href="../../Config/index.html">UM Configuration Guide</a> for receiver configuration options.</p>
<p>As stated above in <a class="el" href="index.html#sourceconfigurationandtransportsessions">Source Configuration and Transport Sessions</a>, multiple topics (and therefore receivers) can be mapped to a single transport. As with source configuration options, many receiver configuration options control or influence transport session activity. If multiple receivers are receiving topic messages over a single transport session (TCP, LBT-RU or LBT-RM), UM only uses the configuration options for the first receiver assigned to the transport.</p>
<p>For example, if the first receiver to use a LBT-RM transport session sets the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmreliability.html#transportlbtrmnakgenerationintervalreceiver">transport_lbtrm_nak_generation_interval (receiver)</a> to 10 seconds, that value is applied to the transport session. If a second receiver sets the same option to 2 seconds, that value is ignored.</p>
<p>The <a href="../../Config/index.html">UM Configuration Guide</a> identifies the receiver configuration options that may be ignored when UM assigns the receiver to an existing transport session. Log file warnings also appear when UM ignores receiver configuration options.</p>
<p><br />
 </p>
<h3><a class="anchor" id="umwildcardreceivers"></a>
UM Wildcard Receivers</h3>
<p>You create a wildcard receiver object by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a5b5d52f6b87499213757b73b09bc8160">lbm_wildcard_rcv_create()</a>. Instead of a topic object, the caller supplies a pattern which UM uses to match multiple topics. Because the application does not explicitly lookup the topics, UM passes the topic attribute into <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a5b5d52f6b87499213757b73b09bc8160">lbm_wildcard_rcv_create()</a> so that it can set options. Also, wildcard receivers have their own set of options, such as pattern type. The application is responsible for deleting a wildcard receiver object when it is no longer needed by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a64407f3874012efaebcba322ea6d229d">lbm_wildcard_rcv_delete()</a>.</p>
<p>The wildcard pattern supplied for matching is a PCRE regular expression that Perl recognizes. See <a href="http://perldoc.perl.org/perlrequick.html">http://perldoc.perl.org/perlrequick.html</a> for details about PCRE. See also the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpwildcardreceiver.html#patterntypewildcardreceiver">pattern_type (wildcard_receiver)</a> option.</p>
<dl class="section note"><dt>Note</dt><dd>Ultra Messaging has deprecated two other wildcard receiver pattern types, regex POSIX extended regular expressions and appcb application callback, as of UM Version 6.1.</dd></dl>
<p>Be aware that some platforms may not support all of the regular expression wildcard types. For example, UM does not support the use of Unicode PCRE characters in wildcard receiver patterns on any system that communicates with a HP-UX or AIX system. See the Informatica Knowledge Base article, <a href="https://kb.informatica.com/faq/5/Pages/80077.aspx">Platform-Specific Dependencies</a> for details.</p>
<p>For an example of wildcard usage, see <a href="../../example/lbmwrcv.c">lbmwrcv.c</a></p>
<p>For more information on wildcard receivers, see <a class="el" href="index.html#wildcardreceivertopicresolution">Wildcard Receiver Topic Resolution</a>, and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpwildcardreceiver.html">Wildcard Receiver Options</a>.</p>
<p>TIBCO™ users see the Informatica Knowledge Base articles, <a href="https://kb.informatica.com/faq/5/Pages/80075.aspx">Wildcard topic regular expressions and SmartSockets wildcards</a> and <a href="https://kb.informatica.com/faq/5/Pages/80277.aspx">Wildcard topic regular expressions and Rendezvous wildcards</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="transportservicesproviderobject"></a>
Transport Services Provider Object</h3>
<p>The Transport Services Provider object ("XSP") is introduced with UM version 6.11 and beyond to manage sockets, threads, and other receive-side resources associated with subscribed transport sessions. The primary purpose for an XSP object is to allow the programmer to control the threading of received messages, based on the transport sessions of those messages.</p>
<p>For more information on XSP, see <a class="el" href="index.html#transportservicesproviderxsp">Transport Services Provider (XSP)</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="umhotfailoveracrosscontextsobjects"></a>
UM Hot Failover Across Contexts Objects</h3>
<p>Hot Failover Across Contexts objects ("HFX") provide a form of hot failover that can operate across multiple network interfaces.</p>
<p>For more information, see <a class="el" href="index.html#hotfailoveracrossmultiplecontexts">Hot Failover Across Multiple Contexts</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="zeroobjectdelivery"></a>
Zero Object Delivery</h3>
<p>The Zero Object Delivery (ZOD) feature for Java and .NET lets receivers (and sources) deliver messages and events to an application with no per-message or per-event object creation. This facilitates source/receiver applications that would require little to no garbage collection at runtime, producing lower and more consistent message latencies.</p>
<p>To take advantage of this feature, you must call dispose() on a message to mark it as available for reuse. To access data from the message when using ZOD, you use a specific pair of LBMMessage-class methods (see below) to extract message data directly from the message, rather than the standard data() method. Using the latter method creates a byte array, and consequently, an object. It is the subsequent garbage collecting to recycle those objects that can affect performance.</p>
<p>For using ZOD, the LBMMessage class methods are: </p><ul>
<li>
Java: dispose(), dataBuffer(), and dataLength() </li>
<li>
.NET: dispose(), dataPointer(), and length() </li>
</ul>
<p>On the other hand, you may need to keep the message as an object for further use after callback. In this case, ZOD is not appropriate and you must call promote() on the message, and also you can use data() to extract message data.</p>
<p>For more details see the Java API Overview or the .Net LBMMessage Class description. This feature does not apply to the C API.</p>
<p><br />
 </p>
<h2><a class="anchor" id="eventqueueobject"></a>
Event Queue Object</h2>
<p>A UM event queue object is a serialization queue structure and execution thread for delivery of other objects' events. For example, a <a class="el" href="index.html#sourceobject">Source Object</a> can generate events that the user's application wants to receive via callback. When the source is created, an event queue can be specified as the delivery agent of those events. Multiple UM <a class="el" href="index.html#contextobject">contexts</a>, <a class="el" href="index.html#sourceobject">sources</a>, and <a class="el" href="index.html#receiverobject">receivers</a> can specify the same event queue, and these events will be delivered in a FIFO manner (first-in, first-out).</p>
<p>Without event queues, these events are delivered via callback from the originating object's context thread, which places the following restrictions on the application callback function being called:</p>
<ul>
<li>
The application function is not allowed to make certain API calls (mostly having to do with creating or deleting UM objects). </li>
<li>
The application function must execute very quickly without blocking. </li>
<li>
The application does not have control over when the callback executes. It can't prevent callbacks during critical sections of application code. </li>
</ul>
<p>Some circumstances require the use of UM event queues. As mentioned above, if the receive callback needs to use UM functions that create or delete objects. Or if the receive callback performs operations that potentially block. You may also want to use an event queue if the receive callback is CPU intensive and can make good use of multiple CPU hardware. Not using an event queue provides the lowest latency, however, high message rates or extensive message processing can negate the low latency benefit if the context thread continually blocks.</p>
<p>Of course, your application can create its own queues, which can be bounded, blocking queues or unbounded, non-blocking queues. For transports that are flow-controlled, a bounded, blocking application queue preserves flow control in your messaging layer because the effect of a filled or blocked queue extends through the message path all the way to source. The speed of the application queue becomes the speed of the source.</p>
<p>UM event queues are unbounded, non-blocking queues and provide the following unique features:</p>
<ul>
<li>
Your application can set a queue size threshold with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpeventqueue.html#queuesizewarningeventqueue">queue_size_warning (event_queue)</a> and be warned when the queue contains too many messages. </li>
<li>
Your application can set a delay threshold with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpeventqueue.html#queuedelaywarningeventqueue">queue_delay_warning (event_queue)</a> and be warned when events have been in the queue for too long. </li>
<li>
The application callback function has no UM API restrictions. </li>
<li>
Your application can control exactly when UM delivers queued events with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac06b127bae882dd5fb68b7044fdceb5f">lbm_event_dispatch()</a>. And you can have control return to your application either when specifically asked to do so (by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#af4b1b274cb142acefe0826673ecffdbe">lbm_event_dispatch_unblock()</a>), or optionally when there are no events left to deliver. </li>
<li>
Your application can take advantage of parallel processing on multiple processor hardware since UM processes asynchronously on a separate thread from your application's processing of received messages. By using multiple application threads to dispatch an event queue, or by using multiple event queues, each with its own dispatch thread, your application can further increase parallelism. </li>
</ul>
<p>You create an UM event queue in the C API by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac7ebe02319363c84bef08f34be7865ec">lbm_event_queue_create()</a>. When finished with an event queue, delete it by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a189f4c0178374d488acacf592c3015e4">lbm_event_queue_delete()</a>. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpeventqueue.html">Event Queue Options</a> for configuration options related to event queues.</p>
<dl class="section warning"><dt>Warning</dt><dd>Before deleting an event queue, you must first delete all objects that reference that event queue (sources, receivers, wildcard receivers, contexts).</dd></dl>
<p>In the Java API and the .NET API, use the LBMEventQueue class.</p>
<p><br />
 </p>
<h1><a class="anchor" id="transporttypes"></a>
Transport Types</h1>
<p><br />
 </p>
<h2><a class="anchor" id="transporttcp"></a>
Transport TCP</h2>
<p>The TCP UM transport uses normal TCP connections to send messages from sources to receivers. This is the default transport when it's not explicitly set. TCP is a good choice when:</p>
<ul>
<li>
Flow control is desired. For example, when one or more receivers cannot keep up, you wish to slow down the source. This is a "better late than never" philosophy. </li>
<li>
Equal bandwidth sharing with other TCP traffic is desired. I.e. when it is desired that the source slow down when general network traffic becomes heavy. </li>
<li>
There are few receivers listening to each topic. Multiple receivers for a topic requires multiple transmissions of each message, which places a scaling burden on the source machine and the network. </li>
<li>
The application is not sensitive to latency. Use of TCP as a messaging transport can result in unbounded latency. </li>
<li>
The messages must pass through a restrictive firewall which does not pass multicast traffic. </li>
</ul>
<p>UM's TCP transport includes a Session ID. A UM source using the TCP transport generates a unique, 32-bit non-zero random Session ID for each TCP transport (IP:port) it uses. The source also includes the Session ID in its Topic Resolution advertisement (TIR). When a receiver resolves its topic and discovers the transport information, the receiver also obtains the transport's Session ID. The receiver sends a message to the source to confirm the Session ID.</p>
<p>The TCP Session ID enables multiple receivers for a topic to connect to a source across UM Router(s). In the event of a UM Router failure, UM establishes new topic routes which can cause cached Topic Resolution and transport information to be outdated. Receivers use this cached information to find sources. Session IDs add a unique identifier to the cached transport information. If a receiver tries to connect to a source with outdated transport information, the source recognizes an incorrect Session ID and disconnects the receiver. The receiver can then attempt to reconnect with different cached transport information.</p>
<dl class="section note"><dt>Note</dt><dd>To maintain interoperability between version pre-6.0 receivers and version 6.0 and beyond TCP sources, you can turn off TCP Session IDs with the UM configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransporttcpoperation.html#transporttcpusesessionidsource">transport_tcp_use_session_id (source)</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="transportlbtru"></a>
Transport LBT-RU</h2>
<p>The LBT-RU UM transport adds reliable delivery to unicast UDP to send messages from sources to receivers. This provides greater flexibility in the control of latency. For example, the application can further limit latency by allowing the use of arrival order delivery. See the Knowledge Base article, <a href="https://kb.informatica.com/faq/5/Pages/80043.aspx">FAQ: How do arrival-order delivery and in-order delivery affect latency?</a>. Also, LBT-RU is less sensitive to overall network load; it uses source rate controls to limit its maximum send rate.</p>
<p>Since it is based on unicast addressing, LBT-RU can pass through most firewalls. However, it has the same scaling issues as TCP when multiple receivers are present for each topic.</p>
<p>UM's LBT-RU transport includes a Session ID. A UM source using the LBT-RU transport generates a unique, 32-bit non-zero random Session ID for each transport it uses. The source also includes the Session ID in its Topic Resolution advertisement (TIR). When a receiver resolves its topic and discovers the transport information, the receiver also obtains the transport's Session ID.</p>
<p>The LBT-RU Session ID enables multiple receivers for a topic to connect to a source across UM Router(s). In the event of a UM Router failure, UM establishes new topic routes which can cause cached Topic Resolution and transport information to be outdated. Receivers use this cached information to find sources. Session IDs add a unique identifier to the cached transport information. If a receiver tries to connect to a source with outdated transport information, the transport drops the received data and times out. The receiver can then attempt to reconnect with different cached transport information.</p>
<dl class="section note"><dt>Note</dt><dd>To maintain interoperability between version pre-3.3 receivers and version 3.3 and beyond LBT-RU sources, you can turn off LBT-RU Session IDs with the UM configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtruoperation.html#transportlbtruusesessionidsource">transport_lbtru_use_session_id (source)</a>.</dd>
<dd>
LBT-RU can benefit from hardware acceleration. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportacceleration.html">Transport Acceleration Options</a> in the <a href="../../Config/index.html">UM Configuration Guide</a> for more information.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="transportlbtrm"></a>
Transport LBT-RM</h2>
<p>The LBT-RM transport adds reliable multicast to UDP to send messages. This provides the maximum flexibility in the control of latency. In addition, LBT-RM can scale effectively to large numbers of receivers per topic using network hardware to duplicate messages only when necessary at wire speed. One limitation is that multicast is often blocked by firewalls.</p>
<p>LBT-RM is a UDP-based, reliable multicast protocol designed with the use of UM and its target applications specifically in mind. The protocol is very similar to <a href="http://www.ietf.org/rfc/rfc3208.txt">PGM</a>, but with changes to aid low latency messaging applications.</p>
<ul>
<li>
Topic Mapping - Several topics may map onto the same LBT-RM session. Thus a multiplexing mechanism to LBT-RM is used to distinguish topic level concerns from LBT-RM session level concerns (such as retransmissions, etc.). Each message to a topic is given a sequence number in addition to the sequence number used at the LBT-RM session level for packet retransmission. </li>
<li>
Negative Acknowledgments (NAKs) - LBT-RM uses NAKs as PGM does. NAKs are unicast to the sender. For simplicity, LBT-RM uses a similar NAK state management approach as PGM specifies. </li>
<li>
Time Bounded Recovery - LBT-RM allows receivers to specify a maximum time to wait for a lost piece of data to be retransmitted. This allows a recovery time bound to be placed on data that has a definite lifetime of usefulness. If this time limit is exceeded and no retransmission has been seen, then the piece of data is marked as an unrecoverable loss and the application is informed. The data stream may continue and the unrecoverable loss will be ordered as a discrete event in the data stream just as a normal piece of data. </li>
<li>
Flexible Delivery Ordering - LBT-RM receivers have the option to have the data for an individual topic delivered "in order" or "arrival order". Messages delivered "in order" will arrive in sequence number order to the application. Thus loss may delay messages from being delivered until the loss is recovered or unrecoverable loss is determined. With "arrival-order" delivery, messages will arrive at the application as they are received by the LBT-RM session. Duplicates are ignored and lost messages will have the same recovery methods applied, but the ordering may not be preserved. Delivery order is a topic level concern. Thus loss of messages in one topic will not interfere or delay delivery of messages in another topic. </li>
<li>
Session State Advertisements - In PGM, SPM packets are used to advertise session state and to perform PGM router assist in the routers. For LBT-RM, these advertisements are only used when data are not flowing. Once data stops on a session, advertisements are sent with an exponential back-off (to a configurable maximum interval) so that the bandwidth taken up by the session is minimal. </li>
<li>
Sender Rate Control - LBT-RM can control a sender's rate of injection of data into the network by use of a rate limiter. This rate is configurable and will back pressure the sender, not allowing the application to exceed the rate limit it has specified. In addition, LBT-RM senders have control over the rate of retransmissions separately from new data. This allows sending application to guarantee a minimum transmission rate even in the face of massive loss at some or all receivers. </li>
<li>
Low Latency Retransmissions - LBT-RM senders do not mandate the use of NCF packets as PGM does. Because low latency retransmissions is such an important feature, LBT-RM senders by default send retransmissions immediately upon receiving a NAK. After sending a retransmission, the sender ignores additional NAKs for the same data and does not repeatedly send NCFs. The oldest data being requested in NAKs has priority over newer data so that if retransmissions are rate controlled, then LBT-RM sends the most important retransmissions as fast as possible. </li>
</ul>
<p>UM's LBT-RM transport includes a Session ID. A UM source using the LBT-RM transport generates a unique, 32-bit non-zero random Session ID for each transport it uses. The source also includes the Session ID in its Topic Resolution advertisement (TIR). When a receiver resolves its topic and discovers the transport information, the receiver also obtains the transport's Session ID.</p>
<dl class="section note"><dt>Note</dt><dd>LBT-RM can benefit from hardware acceleration. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportacceleration.html">Transport Acceleration Options</a> in the <a href="../../Config/index.html">UM Configuration Guide</a> for more information.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="transportlbtipc"></a>
Transport LBT-IPC</h2>
<p>The LBT-IPC transport is an Interprocess Communication (IPC) UM transport that allows sources to publish topic messages to a shared memory area managed as a static ring buffer from which receivers can read topic messages. Message exchange takes place at memory access speed which can greatly improve throughput when sources and receivers can reside on the same host. LBT-IPC can be either source-paced or receiver-paced.</p>
<p>The LBT-IPC transport uses a "lock free" design that eliminates calls to the Operating System and allows receivers quicker access to messages. An internal validation method enacted by receivers while reading messages from the Shared Memory Area ensures message data integrity. The validation method compares IPC header information at different times to ensure consistent, and therefore, valid message data. Sources can send individual messages or a batch of messages, each of which possesses an IPC header.</p>
<dl class="section note"><dt>Note</dt><dd>Transport LBT-IPC is not supported on the OpenVMS® platform.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="lbtipcsharedmemoryarea"></a>
LBT-IPC Shared Memory Area</h3>
<p>The following diagram illustrates the Shared Memory Area used for LBT-IPC:</p>
<div class="image">
<img src="IPC_Shared_Memory_Layout.png" alt="IPC_Shared_Memory_Layout.png"/>
</div>
 <p><b>Header</b></p>
<p>The Header contains information about the shared memory area resource.</p>
<ul>
<li>
Shared Lock - shared receiver pool semaphore (mutex on Microsoft Windows) to ensure mutually exclusive access to the receiver pool. </li>
<li>
Version - LBT-IPC version number which is independent of any UM product version number. </li>
<li>
Buffer Length - size of shared memory area. </li>
<li>
Receiver Map Size - Number of entries available in the Receiver Pool which you configure with the source option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcmaximumreceiverspertransportsource">transport_lbtipc_maximum_receivers_per_transport (source)</a>. </li>
<li>
New Client Flag - set by the receiver after setting its Receiver Pool entry and before releasing the Shared Lock. Indicates to the source that a new receiver has joined the transport. </li>
<li>
Receiver Paced - Indicates if you've configured the transport for receiver-pacing. </li>
<li>
Old Message Start - pointer indicating messages that may be reclaimed. </li>
<li>
New Message Start - pointer indicating messages that may be read. </li>
<li>
New Message End - pointer indicating the end of messages that may be read, which may not be the same as the Old Message Start pointer. </li>
</ul>
<p><b>Receiver Pool</b></p>
<p>The receiver pool is a collection of receiver connections maintained in the Shared Memory Area. The source reads this information if you've configured receiver-pacing to determine if a message can be reclaimed or to monitor a receiver. Each receiver is responsible for finding a free entry in the pool and marking it as used.</p>
<ul>
<li>
In Use flag - set by receiver while holding the Shared Lock, which effectively indicates the receiver has joined the transport session. Using the Shared Lock ensures mutually exclusive access to the receiver connection pool. </li>
<li>
Oldest Message Start - set by receiver after reading a message. If you enable receiver-pacing the source reads it to determine if message memory can be reclaimed. </li>
<li>
Monitor Shared Lock - checked by the source to monitor a receiver (semaphore on Linux, event on Microsoft Windows). </li>
<li>
Signal Shared Lock - Set by source to notify receiver that new data has been written. (semaphore on Linux, mutex on Microsoft Windows) If you set <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcreceiverthreadbehaviorcontext">transport_lbtipc_receiver_thread_behavior (context)</a> to busy_wait, the receiver sets this semaphore to zero and the source does not notify. </li>
</ul>
<p><b>Source-to-Receiver Message Buffer</b></p>
<p>This area contains message data. You specify the size of the shared memory area with a source option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipctransmissionwindowsizesource">transport_lbtipc_transmission_window_size (source)</a>. The size of the shared memory area cannot exceed your platform's shared memory area maximum size. UM stores the memory size in the shared memory area's header. The Old Message Start and New Message Start point to positions in this buffer.</p>
<p><br />
 </p>
<h3><a class="anchor" id="sourcesandlbtipc"></a>
Sources and LBT-IPC</h3>
<p>When you create a source with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab8dd76271bf9df7a5f88476d431f523e">lbm_src_create()</a> and you've set the transport option to IPC, UM creates a shared memory area object. UM assigns one of the transport IDs to this area specified with the UM context configuration options, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcidhighcontext">transport_lbtipc_id_high (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcidlowcontext">transport_lbtipc_id_low (context)</a>. You can also specify a shared memory location outside of this range with a source configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcidsource">transport_lbtipc_id (source)</a>, to prioritize certain topics, if needed.</p>
<p>UM names the shared memory area object according to the format, LBTIPC_x_d where x is the hexadecimal Session ID and d is the decimal Transport ID. Example names are <b>LBTIPC_42792ac_20000</b> or <b>LBTIPC_66e7c8f6_20001</b>. Receivers access a shared memory area with this object name to receive (read) topic messages.</p>
<p>Using the configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcbehaviorsource">transport_lbtipc_behavior (source)</a>, you can choose source-paced or receiver-paced message transport. See Transport LBT-IPC Operation Options in the <a href="../../Config/index.html">UM Configuration Guide</a>.</p>
<p><b>Sending over LBT-IPC</b></p>
<p>To send on a topic (write to the shared memory area) the source writes to the Shared Memory Area starting at the Oldest Message Start position. It then increments each receiver's Signal Lock if the receiver has not set this to zero.</p>
<p><br />
 </p>
<h3><a class="anchor" id="receiversandlbtipc"></a>
Receivers and LBT-IPC</h3>
<p>Receivers operate identically to receivers for all other UM transports. A receiver can actually receive topic messages from a source sending on its topic over TCP, LBT-RU or LBT-RM and from a second source sending on LBT-IPC with out any special configuration. The receiver learns what it needs to join the LBT-IPC session through the topic advertisement.</p>
<p>The configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcreceiverthreadbehaviorcontext">transport_lbtipc_receiver_thread_behavior (context)</a> controls the IPC receiving thread behavior when there are no messages available. The default behavior, '<b>pend</b>', has the receiving thread pend on a semaphore for a new message. When the source adds a message, it posts to each pending receiver's semaphore to wake the receiving thread up. Alternatively, '<b>busy_wait</b>' can be used to prevent the receiving thread going to sleep. In this case, the source does not need to post to the receiver's semaphore. It simply adds the message to shared memory, which the looping receiving thread detects with the lowest possible latency.</p>
<p>Although '<b>busy_wait</b>' has the lowest latency, it has the drawback of consuming 100% of a CPU core during periods of idleness. This limits the number of IPC data flows that can be used on a given machine to the number of available cores. (If more busy looping receivers are deployed than there are cores, then receivers can suffer 10 millisecond time sharing quantum latencies.)</p>
<p>For application that cannot afford '<b>busy_wait</b>', there is another configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcpendbehaviorlingerloopcountcontext">transport_lbtipc_pend_behavior_linger_loop_count (context)</a>, which allows a middle ground between '<b>pend</b>' and '<b>busy_wait</b>'. The receiver is still be configured as '<b>pend</b>', but instead of going to sleep on the semaphore <em>immediately</em> upon emptying the shared memory, it busy loops for the configured number of times. If a new message arrives, it processes the message immediately without a sleep/wakeup. This can be very useful during bursts of high incoming message rates to reduce latency. By making the loop count large enough to cover the incoming message interval during a burst, only the first message of the burst will incur the wakeup latency.</p>
<p><b>Topic Resolution and LBT-IPC</b></p>
<p>Topic resolution operates identically with LBT-IPC as other UM transports albeit with a new advertisement type, LBMIPC. Advertisements for LBT-IPC contain the Transport ID, Session ID and Host ID. Receivers obtain LBT-IPC advertisements in the normal manner (resolver cache, advertisements received on the multicast resolver address:port and responses to queries.) Advertisements for topics from LBT-IPC sources can reach receivers on different machines if they use the same topic resolution configuration, however, those receivers silently ignore those advertisements since they cannot join the IPC transport. See <a class="el" href="index.html#sendingtobothlocalandremotereceivers">Sending to Both Local and Remote Receivers</a>.</p>
<p><b>Receiver Pacing</b></p>
<p>Although receiver pacing is a source behavior option, some different things must happen on the receiving side to ensure that a source does not reclaim (overwrite) a message until all receivers have read it. When you use the default <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcbehaviorsource">transport_lbtipc_behavior (source)</a> (source-paced), each receiver's Oldest Message Start position in the Shared Memory Area is private to each receiver. The source writes to the Shared Memory Area independently of receivers' reading. For receiver-pacing, however, all receivers share their Oldest Message Start position with the source. The source will not reclaim a message until all receivers have successfully read that message.</p>
<p><b>Receiver Monitoring</b></p>
<p>To ensure that a source does not wait on a receiver that is not running, the source monitors a receiver via the Monitor Shared Lock allocated to each receiving context. (This lock is in addition to the semaphore already allocated for signaling new data.) A new receiver takes and holds the Monitor Shared Lock and releases the resource when it dies. If the source is able to obtain the resource, it knows the receiver has died. The source then clears the receiver's In Use flag in it's Receiver Pool Connection.</p>
<p><br />
 </p>
<h3><a class="anchor" id="similaritieswithotherumtransports"></a>
Similarities with Other UM Transports</h3>
<p>Although no actual network transport occurs, IPC functions in much the same way as if you send packets across the network as with other UM transports.</p>
<ul>
<li>
If you use a range of LBT-IPC transport IDs, UM assigns multiple topics sent by multiple sources to all the transport sessions in a round robin manner just like other UM transports. </li>
<li>
Transport sessions assume the configuration option values of the first source assigned to the transport session. </li>
<li>
Sources are subject to message batching. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="differencesfromotherumtransports"></a>
Differences from Other UM Transports</h3>
<ul>
<li>
Unlike LBT-RM which uses a transmission window to specify a buffer size to retain messages in case they must be retransmitted, LBT-IPC uses the transmission window option to establish the size of the shared memory. </li>
<li>
LBT-IPC does not retransmit messages. Since LBT-IPC transport is essentially a memory write/read operation, messages should not be be lost in transit. However, if the shared memory area fills up, new messages overwrite old messages and the loss is absolute. No retransmission of old messages that have been overwritten occurs. </li>
<li>
Receivers also do not send NAKs when using LBT-IPC. </li>
<li>
LBT-IPC does not support <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a> options. However, if you set <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a> 1 or -1, LBT-IPC reassembles any large messages. </li>
<li>
LBT-IPC does not support Rate Control. </li>
<li>
LBT-IPC creates a separate receiver thread in the receiving context. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="sendingtobothlocalandremotereceivers"></a>
Sending to Both Local and Remote Receivers</h3>
<p>A source application that wants to support both local and remote receivers should create two UM Contexts with different topic resolution configurations, one for IPC sends and one for sends to remote receivers. Separate contexts allows you to use the same topic for both IPC and network sources. If you simply created two source objects (one IPC, one say LBT-RM) in the same UM Context, you would have to use separate topics and suffer possible higher latency because the sending thread would be blocked for the duration of two send calls.</p>
<p>A UM source will never automatically use IPC when the receivers are local and a network transport for remote receivers because the discovery of a remote receiver would hurt the performance of local receivers. An application that wants transparent switching can implement it in a simple wrapper.</p>
<p><br />
 </p>
<h3><a class="anchor" id="lbtipcconfigurationexample"></a>
LBT-IPC Configuration Example</h3>
<p>The following diagram illustrates how sources and receivers interact with the shared memory area used in the LBT-IPC transport:</p>
<div class="image">
<img src="IPC_Objects.png" alt="IPC_Objects.png"/>
</div>
 <p>In the diagram above, 3 sources send (write) to two Shared Memory Areas while four receivers in two different contexts receive (read) from the areas. The assignment of sources to Shared Memory Areas demonstrate UM's round robin method. UM assigns the source sending on Topic A to Transport 20001, the source sending on Topic B to Transport 20002 and the source sending on Topic C back to the top of the transport ID range, 20001.</p>
<p>The diagram also shows the UM configuration options that set up this scenario:</p>
<ul>
<li>
The options <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcidhighcontext">transport_lbtipc_id_high (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcidlowcontext">transport_lbtipc_id_low (context)</a> establish the range of Transport IDs between 20001 and 20002. </li>
<li>
The option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#transportsource">transport (source)</a> is used to set the source's transport to LBT-IPC. </li>
<li>
The option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipctransmissionwindowsizesource">transport_lbtipc_transmission_window_size (source)</a> sets the size of each Shared Memory Area to 24 MB. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="requiredprivileges"></a>
Required privileges</h3>
<p>LBT-IPC requires no special operating system authorities, except on Microsoft Windows Vista and Microsoft Windows Server 2008, which require Administrator privileges. In addition, on Microsoft Windows XP, applications must be started by the same user, however, the user is not required to have administrator privileges. In order for applications to communicate with a service, the service must use a user account that has Administrator privileges.</p>
<p><br />
 </p>
<h3><a class="anchor" id="hostresourceusageandlimits"></a>
Host Resource Usage and Limits</h3>
<p>LBT-IPC contexts and sources consume host resources as follows:</p>
<ul>
<li>
Per Source - 1 shared memory segment, 1 shared lock (semaphore on Linux, mutex on Microsoft Windows) </li>
<li>
Per Receiving Context - 2 shared locks (semaphores on Linux, one event and one mutex on Microsoft Windows) </li>
</ul>
<p>Across most operating system platforms, these resources have the following limits. </p><ul>
<li>
4096 shared memory segments, though some platforms use different limits </li>
<li>
32,000 shared semaphores (128 shared semaphore sets * 250 semaphores per set) </li>
</ul>
<p>Consult your operating system documentation for specific limits per type of resource. Resources may be displayed and reclaimed using the <a class="el" href="index.html#lbtipcresourcemanager">LBT-IPC Resource Manager</a>. See also the KB article <a href="https://kb.informatica.com/faq/5/Pages/80201.aspx">Managing LBT-IPC Host Resources</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="lbtipcresourcemanager"></a>
LBT-IPC Resource Manager</h3>
<p>Deleting an IPC source or deleting an IPC receiver reclaims the shared memory area and locks allocated by the IPC source or receiver. However, if a less than graceful exit from a process occurs, global resources remain allocated but unused. To address this possibility, the LBT-IPC Resource Manager maintains a resource allocation database with a record for each global resource (memory or semaphore) allocated or freed. You can use the LBT-IPC Resource Manager to discover and reclaim resources. See the three example outputs below.</p>
<p><b>Displaying Resources</b></p>
<pre class="fragment">$&gt; lbtipc_resource_manager
Displaying Resources (to reclaim you must type '-reclaim' exactly)

--Memory Resources--
Memory resource: Process ID: 24441 SessionID: ab569cec XportID: 20001

--Semaphore Resources-- Semaphore key: 0x68871d75
Semaphore resource Index 0: reserved

Semaphore resource: Process ID: 24441 Sem Index: 1
Semaphore resource: Process ID: 24436 Sem Index: 2
</pre><p><b>Reclaiming Unused Resources</b></p>
<pre class="fragment">$&gt; lbtipc_resource_manager -reclaim
Reclaiming Resources
Process 24441 not found: reclaiming Memory resource (SessionID: ab569cec XPortID: 20001)
Process 24441 not found: reclaiming Semaphore resource: Key: 0x68871d75 Sem Index: 1
Process 24436 not found: reclaiming Semaphore resource: Key: 0x68871d75 Sem Index: 2
</pre><p><br />
 </p>
<h2><a class="anchor" id="transportlbtsmx"></a>
Transport LBT-SMX</h2>
<p>The LBT-SMX (shared memory acceleration) transport is an Interprocess Communication (IPC) transport you can use for the lowest latency message Streaming. LBT-SMX is faster than the LBT-IPC transport. Like LBT-IPC, sources can publish topic messages to a shared memory area from which receivers can read topic messages. Unlike LBT-IPC, the native APIs for the LBT-SMX transport are not thread safe and do not support all UM features such as message batching or fragmentation.</p>
<p>You can use either the native LBT-SMX API calls, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8a56e2f08924d25caea26d205cf730c5">lbm_src_buff_acquire()</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a4f857abe9088918c618cdd248ccf7d83">lbm_src_buffs_complete()</a> to send over LBT-SMX or you can use lbm_src_send_*() API calls. The existing send APIs are thread safe with SMX, but they incur a synchronization overhead and thus are slower than the native LBT-SMX API calls.</p>
<p>LBT-SMX operates on the following Ultra Messaging 64-bit packages:</p>
<ul>
<li>
SunOS-5.10-amd64 </li>
<li>
Linux-glibc-2.5-x86_64 </li>
<li>
Win2k-x86_64 </li>
</ul>
<p>The example applications, <a href="../../example/lbmlatping.c">lbmlatping.c</a> and <a href="../../example/lbmlatpong.c">lbmlatpong.c</a> show how to use the C LBT-SMX API calls. For Java, see <a href="../../java_example/lbmlatpong.java">lbmlatpong.java</a> and <a href="../../java_example/lbmlatpong.java">lbmlatpong.java</a>. For .NET, see <a href="../../dotnet_example/lbmlatpong.cs">lbmlatpong.cs</a> and <a href="../../dotnet_example/lbmlatpong.cs">lbmlatpong.cs</a>.</p>
<p>Other example applications can use the LBT-SMX transport with the use of a UM configuration flat file containing '<b>source transport lbtsmx</b>'. You cannot use LBT-SMX with example applications for features not supported by LBT-SMX, such as <b>lbmreq</b>, <b>lbmresp</b>, <b>lbmrcvq</b> or <b>lbmwrcvq</b>.</p>
<p>The LBT-SMX configuration options are similar to the LBT-IPC transport options. See Transport LBT-SMX Operation Options in the <a href="../../Config/index.html">UM Configuration Guide</a> for a full explanation of these options.</p>
<p>You can use Automatic Monitoring, UM API retrieve/reset calls, and LBMMON APIs to access LBT-SMX source and receiver transport statistics. To increase performance, the LBT-SMX transport does not collect statistics by default. Set the UM configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxmessagestatisticsenabledcontext">transport_lbtsmx_message_statistics_enabled (context)</a> to 1 to enable the collection of transport statistics.</p>
<p><br />
 </p>
<h3><a class="anchor" id="sourcesandlbtsmx"></a>
Sources and LBT-SMX</h3>
<p>When you create a source with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab8dd76271bf9df7a5f88476d431f523e">lbm_src_create()</a> and you've set the source's transport configuration option to LBT-SMX, UM creates a shared memory area object. UM assigns one of the transport IDs to this area from a range of transport IDs specified with the UM context configuration options, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxidhighcontext">transport_lbtsmx_id_high (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxidlowcontext">transport_lbtsmx_id_low (context)</a>. You can also specify a shared memory location inside or outside of this range with a source configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxidsource">transport_lbtsmx_id (source)</a>, to group certain topics in the same shared memory area, if needed. See Transport LBT-SMX Operation Options in the UM Configuration Guide.</p>
<dl class="section note"><dt>Note</dt><dd>For every context created by your application, UM creates an additional shared memory area for control information. The name for these control information memory areas ends with the suffix, _0, which is the Transport ID.</dd></dl>
<p>UM names the shared memory area object according to the format, <b>LBTSMX_x_d</b> where <b>x</b> is the hexadecimal Session ID and <b>d</b> is the decimal Transport ID. Example names are <b>LBTSMX_42792ac_20000</b> or <b>LBTSMX_66e7c8f6_20001</b>. Receivers access a shared memory area with this object name to receive (read) topic messages.</p>
<p>Sending on a topic with the native LBT-SMX APIs requires the two API calls <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8a56e2f08924d25caea26d205cf730c5">lbm_src_buff_acquire()</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a4f857abe9088918c618cdd248ccf7d83">lbm_src_buffs_complete()</a>. A third convenience API, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a661393cae3ab4f8c90d26ce0a27e8d33">lbm_src_buffs_complete_and_acquire()</a>, combines a call to <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a4f857abe9088918c618cdd248ccf7d83">lbm_src_buffs_complete()</a> followed by a call to <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8a56e2f08924d25caea26d205cf730c5">lbm_src_buff_acquire()</a> into one function call to eliminate the overhead of an additional function call.</p>
<p>The native LBT-SMX APIs fail with an appropriate error message if a sending application uses them for a source configured to use a transport other than LBT-SMX.</p>
<dl class="section note"><dt>Note</dt><dd>The native LBT-SMX APIs are not thread safe at the source object or LBT-SMX transport session levels for performance reasons. Applications that use the native API LBT-SMX calls for either the same source or a group of sources that map to the same LBT-SMX transport session must serialize the calls either directly in the application or through their own mutex.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="sendingoverlbtsmxwithnativeapis"></a>
Sending over LBT-SMX with Native APIs</h3>
<p>Sending with LBT-SMX's native API is a two-step process.</p>
<ol>
<li>
<p class="startli">The sending application first calls <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8a56e2f08924d25caea26d205cf730c5">lbm_src_buff_acquire()</a>, which returns a pointer into which the sending application writes the message data.</p>
<p>The pointer points directly into the shared memory region. UM guarantees that the shared memory area has at least the value specified with the len parameter of contiguous bytes available for writing when <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8a56e2f08924d25caea26d205cf730c5">lbm_src_buff_acquire()</a> returns. If your application set the LBM_SRC_NONBLOCK flag with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8a56e2f08924d25caea26d205cf730c5">lbm_src_buff_acquire()</a>, UM returns an LBM_EWOULDBLOCK error condition if the shared memory region does not have enough contiguous space available.</p>
<p>Because LBT-SMX does not support fragmentation, your application must limit message lengths to a maximum equal to the value of the source's configured <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxdatagrammaxsizesource">transport_lbtsmx_datagram_max_size (source)</a> option minus 16 bytes for headers.</p>
<p>After the user acquires the pointer into shared memory and writes the message data, the application may call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8a56e2f08924d25caea26d205cf730c5">lbm_src_buff_acquire()</a> repeatedly to send a batch of messages to the shared memory area. If your application writes multiple messages in this manner, sufficient space must exist in the shared memory area. <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8a56e2f08924d25caea26d205cf730c5">lbm_src_buff_acquire()</a> returns an error if the available shared memory space is less than the size of the next message.</p>
<p class="endli"></p>
</li>
<li>
The sending application calls one of the two following APIs. <ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a4f857abe9088918c618cdd248ccf7d83">lbm_src_buffs_complete()</a>, which publishes the message or messages to all listening receivers. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a661393cae3ab4f8c90d26ce0a27e8d33">lbm_src_buffs_complete_and_acquire()</a>, which publishes the message or messages to all listening receivers and returns another pointer. </li>
</ul>
</li>
</ol>
<p><br />
 </p>
<h3><a class="anchor" id="sendingoverlbtsmxwithexistingapis"></a>
Sending over LBT-SMX with Existing APIs</h3>
<p>LBT-SMX supports lbm_src_send_* API calls. These API calls are fully thread-safe. The LBT-SMX feature restrictions still apply, however, when using lbm_src_send_* API calls. The lbm_src_send_ex_info_t argument to the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a091b5806bf18d10ebd0d9117e0c70229">lbm_src_send_ex()</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a4d883eaaa22baf81abf21d495f471c8b">lbm_src_sendv_ex()</a> APIs must be NULL when using an LBT-SMX source, because LBT-SMX does not support any of the features that the lbm_src_send_ex_info_t parameter can enable. See <a class="el" href="index.html#differencesbetweenlbtsmxandotherumtransports">Differences Between LBT-SMX and Other UM Transports</a>.</p>
<p>Since LBT-SMX does not support an implicit batcher or corresponding implicit batch timer, UM flushes all messages for all sends on LBT-SMX transports done with lbm_src_send_* APIs, which is similar to setting the LBM_MSG_FLUSH flag. LBT-SMX also supports the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#afec0ee6822fe721f21c67536660506ea">lbm_src_flush()</a> API call, which behaves like a thread-safe version of <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a4f857abe9088918c618cdd248ccf7d83">lbm_src_buffs_complete()</a>.</p>
<dl class="section note"><dt>Note</dt><dd>Users should not use both the native LBT-SMX APIs and the lbm_src_send_* API calls in the same application. Users should choose one or the other type of API for consistency and to avoid thread safety problems.</dd></dl>
<p>The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a1ba60407fa2bde0997aab6d5a5d2da1a">lbm_src_topic_alloc()</a> API call generates log warnings if the given attributes specify an LBT-SMX transport and enable any of the features that LBT-SMX does not support. The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a1ba60407fa2bde0997aab6d5a5d2da1a">lbm_src_topic_alloc()</a> call succeeds, but UM does not enable the unsupported features indicated in the log warnings. Other API functions that operate on lbm_src_t objects, such as <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab8dd76271bf9df7a5f88476d431f523e">lbm_src_create()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a29d45db8f76835b4ae78f4568c25712f">lbm_src_delete()</a>, or <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a33d3ee1d815f4a51b68653d8a063f87f">lbm_src_topic_dump()</a>, operate with LBT-SMX sources normally.</p>
<p>Because LBT-SMX does not support fragmentation, your application must limit message lengths to a maximum equal to the value of the source's configured <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxdatagrammaxsizesource">transport_lbtsmx_datagram_max_size (source)</a> option minus 16 bytes for headers. Any send API calls with a length parameter greater than this configured value fail.</p>
<p><br />
 </p>
<h3><a class="anchor" id="receiversandlbtsmx"></a>
Receivers and LBT-SMX</h3>
<p>Receivers operate identically over LBT-SMX to receivers as all other UM transports. The msg-&gt;data pointer of a delivered lbm_msg_t object points directly into the shared memory region.</p>
<p>The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2b7788ff58f9e78bc89ea890dad0cccf">lbm_msg_retain()</a> API function operates differently for LBT-SMX. <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2b7788ff58f9e78bc89ea890dad0cccf">lbm_msg_retain()</a> creates a full copy of the message in order to access the data outside the receiver callback.</p>
<dl class="section attention"><dt>Attention</dt><dd>You application should not pass the msg-&gt;data pointer to other threads or outside the receiver callback until your application has called <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2b7788ff58f9e78bc89ea890dad0cccf">lbm_msg_retain()</a> on the message.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Any API calls documented as not safe to call from a context thread callback are also not safe to call from an LBT-SMX receiver thread.</dd></dl>
<p><b>Topic Resolution and LBT-SMX</b></p>
<p>Topic resolution operates identically with LBT-SMX as other UM transports albeit with the advertisement type, LBMSMX. Advertisements for LBT-SMX contain the Transport ID, Session ID, and Host ID. Receivers get LBT-SMX advertisements in the normal manner, either from the resolver cache, advertisements received on the multicast resolver address:port, or responses to queries.</p>
<p><br />
 </p>
<h3><a class="anchor" id="similaritiesbetweenlbtsmxandotherumtransports"></a>
Similarities Between LBT-SMX and Other UM Transports</h3>
<p>Although no actual network transport occurs, SMX functions in much the same way as if you send packets across the network as with other UM transports.</p>
<ul>
<li>
If you use a range of LBT-SMX transport IDs, UM assigns multiple topics sent by multiple sources to all the transport sessions in a round robin manner just like other UM transports. </li>
<li>
Transport sessions assume the configuration option values of the first source assigned to the transport session. </li>
<li>
Source applications and receiver applications based on any of the three available APIs can interoperate with each other. For example, sources created by a C sending application can send to receivers created by a Java receiving application. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="differencesbetweenlbtsmxandotherumtransports"></a>
Differences Between LBT-SMX and Other UM Transports</h3>
<ul>
<li>
Unlike LBT-RM which uses a transmission window to specify a buffer size to retain messages for retransmission, LBT-SMX uses the transmission window option to establish the size of the shared memory. LBT-SMX uses transmission window sizes that are powers of 2. You can set <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxtransmissionwindowsizesource">transport_lbtsmx_transmission_window_size (source)</a> to any value, but UM rounds the option value up to the nearest power of 2. </li>
<li>
The largest transmission window size for Java applications is 1 GB. </li>
<li>
LBT-SMX does not retransmit messages. Since LBT-SMX transport is a memory write-read operation, messages should not be lost in transit. No retransmission of old messages that have been overwritten occurs. </li>
<li>
Receivers do not send NAKs when using LBT-SMX. </li>
</ul>
<p><b>You cannot use the following UM features with LBT-SMX:</b></p>
<ul>
<li>
Arrival Order Delivery </li>
<li>
Late Join </li>
<li>
Off Transport Recovery </li>
<li>
Request and Response </li>
<li>
Multi-transport Threads </li>
<li>
Source-side Filtering </li>
<li>
Hot Failover </li>
<li>
Message Properties </li>
<li>
Application Headers </li>
<li>
Implicit and Explicit Message Batching </li>
<li>
Fragmentation and Reassembly </li>
<li>
Immediate Messaging </li>
<li>
Receiver thread behaviors other than "busy_wait" </li>
<li>
Persistent sources </li>
<li>
Queued sources, both brokered and ULB </li>
</ul>
<p>You also cannot use LBT-SMX to send egress traffic from a UM daemon, such as the Persistent Store, UM Router, UM Cache, or UMDS.</p>
<p><br />
 </p>
<h3><a class="anchor" id="lbtsmxconfigurationexample"></a>
LBT-SMX Configuration Example</h3>
<p>The following diagram illustrates how sources and receivers interact with the shared memory area used in the LBT-SMX transport.</p>
<div class="image">
<img src="SMX_Objects.png" alt="SMX_Objects.png"/>
</div>
 <p>In the diagram above, three sources send (write) to two Shared Memory Areas while four receivers in two different contexts receive (read) from the areas. The assignment of sources to Shared Memory Areas demonstrate UM's round robin method. UM assigns the source sending on Topic A to Transport 30001, the source sending on Topic B to Transport 30002 and the source sending on Topic C back to the top of the transport ID range, 30001.</p>
<p>The diagram also shows the UM configuration options that set up this scenario.</p>
<ul>
<li>
The options <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxidhighcontext">transport_lbtsmx_id_high (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxidlowcontext">transport_lbtsmx_id_low (context)</a> establish the range of Transport IDs between 30001 and 30002. </li>
<li>
The option "source transport lbtsmx" sets the source's transport to LBT-SMX. </li>
<li>
<p class="startli">The option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtsmxoperation.html#transportlbtsmxtransmissionwindowsizesource">transport_lbtsmx_transmission_window_size (source)</a> sets the size of each Shared Memory Area to 33554432 bytes or 32 MB. This option's value must be a power of 2. If you configured the transmission window size to 25165824 bytes (24 MB) for example, UM logs a warning message and then rounds the value of this option up to the next power of 2 or 33554432 bytes or 32 MB.</p>
<p class="endli"><br />
 </p>
</li>
</ul>
<h3><a class="anchor" id="javacodeexamplesforlbtsmx"></a>
Java Code Examples for LBT-SMX</h3>
<p>The Java code examples for LBT-SMX send and receive one million messages. Start the receiver example application before you start the source example application.</p>
<p><b>Java Source Example</b></p>
<pre class="fragment">import java.nio.ByteBuffer; import com.latencybusters.lbm.*;

public class SimpleSrc
{
  private LBMContext ctx;
  private LBMSource src;

  public static void main(String[] args)
  {
    try
    {
      SimpleSrc test = new SimpleSrc();
      test.sendMessages();
      System.out.println("Send Complete");
    } catch (LBMException ex)
    {
      System.err.println(ex.getMessage());
      ex.printStackTrace();
    }
  }  /* main */

  public SimpleSrc() throws LBMException
  {
    ctx = new LBMContext();
    LBMSourceAttributes sattr = new LBMSourceAttributes();
    sattr.setValue("transport", "lbtsmx");
    LBMTopic top = ctx.allocTopic("SimpleSmx", sattr);
    src = ctx.createSource(top);
  }

  public void sendMessages() throws LBMException
  {
    /* Keep a reference to the source buffer, which does not change */
    final ByteBuffer srcBuffer = src.getMessagesBuffer();
    /* Sends will block waiting for receivers */
    final int flags = LBM.SRC_BLOCK;
    final int msgLength = 8;
    int pos;

    /* Delay a second to let topic resolution complete. */
    try { Thread.sleep(1000); } catch (Exception ex) { }

    for (long i = 0; i &lt; 1000000; i++)
    {
      /* Acquire a position in the buffer */
      pos = src.acquireMessageBufferPosition(msgLength, flags);
      /* Place data at acquired position */
      srcBuffer.putLong(pos, i);
      /* Inform receivers data has been written */
      src.messageBuffersComplete();
    }

    /* Linger for a short while to allow retransmissions, etc. */
    try { Thread.sleep(1000); } catch (Exception ex) { }

    src.close();
    ctx.close();
  }  /* sendMessages */
}  /* SimpleSrc */
</pre><p>The source sends one million messages using the native LBT-SMX Java APIs. The sendMessages() method obtains a reference to the source's message buffer, which does not change for the life of the source. The method acquireMessageBufferPosition(int, int) contains the requested message length of 8 bytes. When this call returns, it gives an integer position into the previously obtained messages buffer, which is the position of the message data. UM guarantees that you can safely write the value of the counter i into the buffer at this position.</p>
<p><b>Java Receiver Example</b></p>
<pre class="fragment">import java.nio.ByteBuffer;
import com.latencybusters.lbm.*;

/* Extend LBMReceiver to avoid onReceive synchronization */
public class SimpleSmxRcv extends LBMReceiver
{
  protected SimpleSmxRcv(LBMContext lbmctx, LBMTopic lbmtopic) throws LBMException
  {
    super(lbmctx, lbmtopic);
  }

  long lastReceivedValue = -1;
  /* Override LBMReceiver onReceive method */
  protected int onReceive(LBMMessage lbmmsg)
  {
    if (lbmmsg.type() == LBM.MSG_DATA)
    {
      /* New API gets byte buffer with position and limit set */
      ByteBuffer msgsBuffer = lbmmsg.getMessagesBuffer();
      /* Get the message data directly from the buffer */
      lastReceivedValue = msgsBuffer.getLong();
    }
    return 0;
  }  /* on Receive */

  public static void main(String[] args)
  {
    LBMContext ctx = null;
    SimpleSmxRcv rcv = null;

    try
    {
      ctx = new LBMContext();
      LBMTopic top = ctx.lookupTopic("SimpleSmx");
      rcv = new SimpleSmxRcv(ctx, top);
    } catch (LBMException ex)
    {
      System.out.println(ex.getMessage());
      ex.printStackTrace();
      System.exit(1);
    }

    while (rcv.lastReceivedValue &lt; 999999) {
      try { Thread.sleep(250); } catch (Exception ex) {}
    }
    try
    {
      rcv.close();
      ctx.close();
      System.out.println("Last Received Value: " + rcv.lastReceivedValue);
    } catch (LBMException ex)
    {
      System.out.println(ex.getMessage());
      ex.printStackTrace();
    }
  }  /* main */
}
</pre><p>The receiver reads messages from an LBT-SMX Source using the new API on LBMMessage. The example extends the LBMReceiver class so that you can overwrite the onReceive() method, which bypasses synchronization of multiple receiver callbacks. As a result, the addReceiver() and removeReceiver() methods do not work with this class, but we don't want them anyway. In the overridden onReceive() callback, we call getMessagesBuffer(), which returns a ByteBuffer view of the underlying transport. This allows the application to do zero copy reads directly from the memory that stores the message data. The returned ByteBuffer position and limit is set to the beginning and end of the message data. The message data does not start at position 0. The application reads a long out of the buffer, which is the same long that was placed by the source example.</p>
<p><b>Batching Example</b></p>
<pre class="fragment">public void sendMessages() throws LBMException
{
  ...
  for (long i = 0; i &lt; 1000000; i += 2)
  {
    /* Acquire a position in the buffer */
    pos = src.acquireMessageBufferPosition(msgLength, flags);
    /* Place data at acquired position */
    srcBuffer.putLong(pos, i);
    pos = src.acquireMessageBufferPosition(msgLength, flags); srcBuffer.putLong(pos, i+1);
    /* Inform receivers two messages have been written */
    src.messageBuffersComplete();
  }
  ...
}
</pre><p>You can implement a batching algorithm at the source by doing multiple acquires before calling complete. When receivers notice that there are new message available, they deliver all new messages in a single loop.</p>
<p><b>Blocking and Non-blocking Sends Example</b></p>
<pre class="fragment">public void sendMessages() throws LBMException
{
  ...
  /* Acquire will return -1 if need to wait for receivers */
  final int flags = LBM.SRC_NONBLOCK;
  ...
  for (long i = 0; i &lt; 1000000; i++)
  {
    /* Acquire a position in the buffer */
    pos = src.acquireMessageBufferPosition(msgLength, flags);
    while (pos == -1)
    {
      /* Implement a backoff algorithm here */
      try { Thread.sleep(1); } catch (Exception ex) { }

      pos = src.acquireMessageBufferPosition(msgLength, flags);
      /* Place data at acquired position */
      srcBuffer.putLong(pos, i);
      /* Inform receivers data has been written */
      src.messageBuffersComplete();
    }
    ...
  }
}
</pre><p>By default, acquireMessageBufferPosition() waits for receivers to catch up before it writes the requested number of bytes to the buffer. The resulting spin wait block happens only if you did not set the flags argument to LBM.SRC_NONBLOCK. If the flags argument sets the LBM.SRC_NONBLOCK value, then the function returns -1 if the call would have blocked. For performance reasons, acquireMessageBufferPosition() does not throw new LBMEWouldBlock exceptions like standard send APIs.</p>
<p><b>Complete and Acquire Function</b></p>
<pre class="fragment">public void sendMessages() throws LBMException
{
  ...
  for (long i = 0; i &lt; 1000000; i++)
  {
    /* Mark previous acquires complete and reserve space */
    pos = src.messageBuffersCompleteAndAcquirePosition(msgLength, flags);
    /* Place data at acquired position */
    srcBuffer.putLong(pos, i);
  }
  /* final buffers complete after loop */
  src.messageBuffersComplete();
  ...
}
</pre><p>The function, messageBuffersCompleteAndAcquirePosition(), is a convenience function for the source and calls messageBuffersComplete() followed immediately by acquireMessageBufferPosition(), which reduces the number of method calls per message.</p>
<p><br />
 </p>
<h3><a class="anchor" id="netcodeexamplesforlbtsmx"></a>
.NET Code Examples for LBT-SMX</h3>
<p>The .NET code examples for LBT-SMX send and receive one million messages. Start the receiver example application before you start the source example application.</p>
<p><b>.NET Source Example</b></p>
<pre class="fragment">using System;
using System.Collections.Generic;
using System.Text;
using System.Threading;
using System.Runtime.InteropServices;
using com.latencybusters.lbm;

namespace UltraMessagingApplication.SimpleSrc
{
  class SimpleSrc
  {
    LBMContext ctx;
    LBMSource src;

    static void Main(string[] args)
    {
      SimpleSrc test = new SimpleSrc(); test.sendMessages(); Console.WriteLine("Send Complete");
    }

    public SimpleSrc()
    {
      ctx = new LBMContext();
      LBMSourceAttributes sattr = new LBMSourceAttributes();
      sattr.setValue("transport", "lbtsmx");
      LBMTopic top = ctx.allocTopic("SimpleSmx", sattr);
      src = ctx.createSource(top);
    }

    private void sendMessages()
    {
      IntPtr writePtr;
      // Sends will block waiting for receivers
      int flags = LBM.SRC_BLOCK;
      uint msgLength = 8; Thread.Sleep(1000);
      for (long i = 0; i &lt; 1000000; i++) {
        // Acquire a position in the buffer src.
        buffAcquire(out writePtr, msgLength, flags);
        // Place data at acquired position Marshal.
        WriteInt64(writePtr, i);
        // Inform receivers data has been written.
        src.buffsComplete();
      }

      Thread.Sleep(1000);
      src.close();
      ctx.close();
    }
  }
}
</pre><p>You can access the shared memory region directly with the IntPtr structs. The src.buffAcquire() API modifies writePtr to point to the next available location in shared memory. When buffAcquire() returns, you can safely write to the writePtr location up to the length specified in buffAcquire(). The Marshal.WriteInt64() writes 8 bytes of data to the shared memory region. The call to buffsComplete() signals new data to connected receivers.</p>
<p><b>.NET Receiver Example</b></p>
<pre class="fragment">using System;
using System.Collections.Generic;
using System.Text;
using System.Threading;
using System.Runtime.InteropServices;
using com.latencybusters.lbm;

namespace UltraMessagingApplication.SimpleRcv
{
  class SimpleRcv
  {
    private LBMContext ctx;
    private LBMReceiver rcv;
    private long lastReceivedValue = -1;

    static void Main(string[] args)
    {
      SimpleRcv simpleRcv = new SimpleRcv();
      while (simpleRcv.lastReceivedValue &lt; 999999)
      {
        Thread.Sleep(250);
      }
      simpleRcv.rcv.close();
      simpleRcv.ctx.close();
      Console.WriteLine("Last Received Value: {0}", simpleRcv.lastReceivedValue);
    }

    public SimpleRcv()
    {
      ctx = new LBMContext();
      LBMTopic top = new LBMTopic(ctx, "SimpleSmx");
      rcv = new LBMReceiver(ctx, top, new LBMReceiverCallback(onReceive), null);
    }

    public int onReceive(Object obj, LBMMessage msg)
    {
      if (msg.type() == LBM.MSG_DATA)
      {
        // Read data out of shared memory
        lastReceivedValue = Marshal.ReadInt64(msg.dataPointerSafe());
      }
      // dispose the message so the LBMMessage object can be re-used msg.
      dispose();
      return 0;
    }
  }
}
</pre><p>The application calls the simpleRcv::onReceive callback after the source places new data in the shared memory region. The msg.dataPointerSafe() API returns an IntPtr to the data, which does not create any new objects. The Marshal.ReadInt64 API then reads data directly from the shared memory.</p>
<p><b>Batching</b></p>
<pre class="fragment">private void sendMessages()
{
  ...
  for (int i = 0; i &lt; 1000000; i += 2) {
    // Acquire a position in the buffer src.
    buffAcquire(out writePtr, msgLength, flags);
    // Place data at acquired position Marshal.
    WriteInt32(writePtr, i);
    // Acquire a position in the buffer src.
    buffAcquire(out writePtr, msgLength, flags);
    // Place data at acquired position Marshal.
    WriteInt32(writePtr, i);
    // Inform receivers two messages has been written src.
    buffsComplete();
  }

  ...
}
</pre><p>You can implement a batching algorithm at the source by doing multiple acquires before calling complete. When receivers notice that new message are available, they deliver all new messages in a single loop.</p>
<p><b>Blocking and Non-blocking Sends</b></p>
<pre class="fragment">private void sendMessages()
{
  ...
  // buffAcquire will return -1 if need to wait for receivers int flags = LBM.SRC_NONBLOCK;
  ...
  for (long i = 0; i &lt; 1000000; i++)
  {
    // Acquire a position in the buffer
    int rc = src.buffAcquire(out writePtr, msgLength, flags);
    while (rc == -1)
    {
      // Implement a backoff algorithm here Thread.Sleep(0);
      rc = src.buffAcquire(out writePtr, msgLength, flags);
    }
    // Place data at acquired position Marshal.
    WriteInt64(writePtr, i);
    // Inform receivers that a message has been written src.
    buffsComplete();
    ...
  }
}
</pre><p>By default, buffAcquire() waits for receivers to catch up before it writes the requested number of bytes to the buffer. The resulting spin wait block happens only if you did not set the flags argument to <b>LBM.SRC_NONBLOCK</b>. If the flags argument sets the <b>LBM.SRC_NONBLOCK</b> value, then the function returns -1 if the call would have blocked. For performance reasons, buffAcquire() does not throw new <b>LBMEWouldBlock</b> exceptions like standard send APIs.</p>
<p><b>Complete and Acquire Function</b></p>
<pre class="fragment">private void sendMessages()
{
  ...
  for (long i = 0; i &lt; 1000000; i++) {
    // Acquire a position in the buffer src.
    buffsCompleteAndAcquire(out writePtr, msgLength, flags);
    // Place data at acquired position Marshal.
    WriteInt64(writePtr, i);
  }

  // final buffsComplete after loop src.buffsComplete();

  ...
}
</pre><p>The function, buffsCompleteAndAcquire(), is a convenience function for the source and calls buffsComplete() followed immediately by buffAcquire(), which reduces the number of method calls per message.</p>
<p><b>Reduce Synchronization Overhead</b></p>
<pre class="fragment">public SimpleRcv()
  {
  ctx = new LBMContext();
  LBMReceiverAttributes rattr = new LBMReceiverAttributes();
  // Set the enableSingleReceiverCallback attribute to 'true' rattr.
  enableSingleReceiverCallback(true);
  LBMTopic top = new LBMTopic(ctx, "SimpleSmx", rattr);
  // With enableSingleReceiverCallback, a callback must be specified in the ver constructor.

  rcv = new LBMReceiver(ctx, top, new LBMReceiverCallback(onReceive), null);
  // rcv.addReceiver and rcv.removeReceiver will result in log warnings.
}
</pre><p>Delivery latency to an LBMReceiver callback can be reduced with a single callback. Call LBMReceiverAttributes::enableSingleReceiverCallback on the attributes object used to create the LBMReceiver. The addReceiver() and removeReceiver() APIs become defunct, and your application calls the application receiver callback without any locks taken. The enableSingelReceiverCallback() API eliminates callback related synchronization overhead.</p>
<dl class="section note"><dt>Note</dt><dd>In Java, inheriting from LBMReceiver and overriding the onReceive can achieve the same thing.</dd></dl>
<p><b>Increase Performance with unsafe Code Constructs</b></p>
<pre class="fragment">for (long i = 0; i &lt; 1000000; i++) {
  // Acquire a position in the buffer src.buffAcquire(out writePtr, msgLength, flags);
  // Place data at acquired position
  unsafe
  {
    *((long*)(writePtr)) = i;
  }
  // Inform receivers data has been written src.buffsComplete();
}

public int onReceive(Object obj, LBMMessage msg)
{
  if (msg.type() == LBM.MSG_DATA)
  {
    unsafe
    {
      lastReceivedValue = *((long*)msg.dataPointer());
    }
  }
  // dispose the message so the object can be re-used msg.dispose();
  return 0;
}
</pre><p>Using .NET unsafe code constructs can increase performance. By manipulating pointers directly, you can eliminate calls to external APIs, resulting in lower latencies.</p>
<p><br />
 </p>
<h3><a class="anchor" id="lbtsmxresourcemanager"></a>
LBT-SMX Resource Manager</h3>
<p>Deleting an SMX source or deleting an SMX receiver reclaims the shared memory area and locks allocated by the SMX source or receiver. However, if an ungraceful exit from a process occurs, global resources remain allocated but unused. To address this possibility, the LBT-SMX Resource Manager maintains a resource allocation database with a record for each global resource (memory or semaphore) allocated or freed. You can use the LBT-SMX Resource Manager to discover and reclaim resources. See the three example outputs below.</p>
<p><b>Displaying Resources</b></p>
<pre class="fragment">$&gt; lbtsmx_resource_manager
Displaying Resources (to reclaim you must type '-reclaim' exactly)

--Memory Resources--
Memory resource: Process ID: 24441 SessionID: ab569cec XportID: 20001

--Semaphore Resources-- Semaphore key: 0x68871d75
Semaphore resource Index 0: reserved

Semaphore resource: Process ID: 24441 Sem Index: 1
Semaphore resource: Process ID: 24436 Sem Index: 2
</pre><p><b>Reclaiming Unused Resources</b></p>
<dl class="section warning"><dt>Warning</dt><dd>This operation should never be done while SMX-enabled applications or daemons are running. If you have lost or unused resources that need to be reclaimed, you should exit all SMX applications prior to running this command.</dd></dl>
<pre class="fragment">$&gt; lbtsmx_resource_manager -reclaim
Reclaiming Resources
Process 24441 not found: reclaiming Memory resource (SessionID: ab569cec XPortID: 20001)
Process 24441 not found: reclaiming Semaphore resource: Key: 0x68871d75 Sem Index: 1
Process 24436 not found: reclaiming Semaphore resource: Key: 0x68871d75 Sem Index: 2
</pre><p><br />
 </p>
<h2><a class="anchor" id="transportlbtrdma"></a>
Transport LBT-RDMA</h2>
<p>The existing RDMA transport is deprecated and will be removed in a future release.</p>
<p>The LBT-RDMA transport is Remote Direct Memory Access (RDMA) UM transport that allows sources to publish topic messages to a shared memory area from which receivers can read topic messages. LBT-RDMA runs across InfiniBand and 10 Gigabit Ethernet hardware.</p>
<dl class="section note"><dt>Note</dt><dd>Use of the LBT-RDMA transport requires the purchase and installation of the Ultra Messaging RDMA Transport Module. See your Ultra Messaging representative for licensing specifics. Restriction: Transport LBT-RDMA is supported on only the X86 Linux 64-bit platform.</dd></dl>
<p>When you create a source with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab8dd76271bf9df7a5f88476d431f523e">lbm_src_create()</a> and you've set the transport option to RDMA, UM creates a shared memory area object on the sending machine's Host Channel Adapter (HCA) card. UM assigns one of the RDMA transport ports to this area specified with the UM context configuration options, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#transportlbtrdmaporthighcontext">transport_lbtrdma_port_high (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#transportlbtrdmaportlowcontext">transport_lbtrdma_port_low (context)</a>. You can also specify a shared memory location outside of this range with a source configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#transportlbtrdmaportsource">transport_lbtrdma_port (source)</a>, to prioritize certain topics, if needed.</p>
<p>When you create a receiver with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aa7491c50fefbc2b70f8035fce7ac1477">lbm_rcv_create()</a> for a topic being sent over LBT-RDMA, UM creates a shared memory area on the receiving machine's HCA card. The network hardware immediately copies any new data from the sending HCA to the receiving HCA. UM receivers monitor the receiving shared memory area for new topic messages. You configure receiver monitoring with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#transportlbtrdmareceiverthreadbehaviorcontext">transport_lbtrdma_receiver_thread_behavior (context)</a>.</p>
<p>The following diagram illustrates how sources and receivers interact with the shared memory area used in the LBT-RDMA transport.</p>
<div class="image">
<img src="RDMA_Objects.png" alt="RDMA_Objects.png"/>
</div>
 <p><br />
 </p>
<h3><a class="anchor" id="similaritieswithotherumstransports"></a>
Similarities with Other UM Transports</h3>
<p>UM functions in much the same way as if you send packets across a traditional Ethernet network as with other UM transports.</p>
<ul>
<li>
If you use a range of ports, UM assigns multiple topics that have been sent by multiple sources in a round robin manner to all the transport sessions configured my the port range. </li>
<li>
Transport sessions assume the configuration option values of the first source assigned to the transport session. </li>
<li>
Sources are subject to message batching. </li>
<li>
<p class="startli">Topic resolution operates identically with LBT-RDMA as other UM transports.</p>
<p class="endli"><br />
 </p>
</li>
</ul>
<h3><a class="anchor" id="differencesfromotherumstransports"></a>
Differences from Other UM Transports</h3>
<ul>
<li>
Unlike LBT-RM, which uses a transmission window to set a retransmission buffer size, LBT-RDMA uses the transmission window option to set the size of the shared memory. </li>
<li>
LBT-RDMA does not retransmit messages. </li>
<li>
Receivers also do not send NAKs when using LBT-RDMA. </li>
<li>
LBT-RDMA is inherently ordered in its message delivery. If you set <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a> to 0, then UM delivers message fragments individually in sequence number order, without reassembly. </li>
<li>
LBT-RDMA is source-paced but does not support Rate Control. If the source message rate exceeds the receiver's consumption rate, unrecoverable message loss eventually occurs. </li>
<li>
LBT-RDMA creates a separate receiver thread in the receiving context. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="transportbroker"></a>
Transport Broker</h3>
<p>With the UMQ product, you use the '<b>broker</b>' transport to send messages from a source to a Queuing Broker, or from a Queuing Broker to a receiver.</p>
<p>When sources or receivers connect to a Queuing Broker, you must use the '<b>broker</b>' transport. You cannot use the '<b>broker</b>' transport with UMS or UMP products.</p>
<p><br />
 </p>
<h1><a class="anchor" id="architecture"></a>
Architecture</h1>
<p>UM is designed to be a flexible architecture. Unlike many messaging systems, UM does not require an intermediate daemon to handle routing issues or protocol processing. This increases the performance of UM and returns valuable computation time and memory back to applications that would normally be consumed by messaging daemons.</p>
<p><br />
 </p>
<h2><a class="anchor" id="embeddedmode"></a>
Embedded Mode</h2>
<p>When you create a context (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8058947690bd0995bc2c59d4a61b462f">lbm_context_create()</a>) with the UM configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#operationalmodecontext">operational_mode (context)</a> set to embedded (the default), UM creates an independent thread, called the context thread, which handles timer and socket events, and does protocol-level processing, like retransmission of dropped packets.</p>
<p><br />
 </p>
<h2><a class="anchor" id="sequentialmode"></a>
Sequential Mode</h2>
<p>When you create a context (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8058947690bd0995bc2c59d4a61b462f">lbm_context_create()</a>) with the UM configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#operationalmodecontext">operational_mode (context)</a> set to sequential, the context thread is NOT created. It becomes the application's responsibility to donate a thread to UM by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ad9416b1f0b474b5d4c4f39bb3c4bda77">lbm_context_process_events()</a> regularly, typically in a tight loop. Use Sequential mode for circumstances where your application wants control over the attributes of the context thread. For example, some applications raise the priority of the context thread so as to obtain more consistent latencies. In sequential mode, no separate thread is spawned when a context is created.</p>
<p>You enable Sequential mode with the following configuration option.</p>
<pre class="fragment">context operational_mode sequential
</pre><p>In addition to the context thread, there are other UM features which rely on specialized threads: </p><ul>
<li>
The LBT-IPC transport type, when used, creates its own specialized receive thread. Similar to the context thread, the creation of this thread can be suppressed by setting the option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtipcoperation.html#transportlbtipcreceiveroperationalmodecontext">transport_lbtipc_receiver_operational_mode (context)</a> to sequential. The application must then call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8729a284ef9f01f329fbf0edbc147227">lbm_context_process_lbtipc_messages()</a> regularly. </li>
<li>
The LBT-SMX transport type, when used, creates its own specialized receive thread. However, unlike the context thread and the LBT-IPC threads, the creation of the LBT-SMX thread is handled by UM. There is no sequential mode for the LBT-SMX thread. </li>
<li>
The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportacceleration.html#myricomdatagrambypasslayerdbl">DBL transport acceleration</a>, when used, creates its own specialized receive thread. However, unlike the context thread and the LBT-IPC threads, the creation of the DBL thread is handled by UM. There is no sequential mode for the DBL thread. </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="topicresolutiondescription"></a>
Topic Resolution Description</h2>
<p>Topic resolution is the discovery of a topic's transport session information by a receiver to enable the receipt of topic messages. By default, Ultra Messaging Ultra Messaging relies on multicast requests and responses to resolve topics to transport sessions. (You can also use Unicast requests and responses, if needed.) Ultra Messaging receivers multicast their topic requests, or queries, to an IP multicast address and UDP port configured with the Ultra Messaging configuration options, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastresolvernetwork.html#resolvermulticastaddresscontext">resolver_multicast_address (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastresolvernetwork.html#resolvermulticastportcontext">resolver_multicast_port (context)</a>). Ultra Messaging sources also multicast their advertisements and responses to receiver queries to the same multicast address and UDP port.</p>
<p>Topic Resolution occurs in the following phases:</p>
<ul>
<li>
Initial Phase - Period that allows you to resolve a topic aggressively. Can be used to resolve all known topics before message sending begins. This phase can be configured to run differently from the defaults or completely disabled. </li>
<li>
Sustaining Phase - Period that allows new receivers to resolve a topic after the Initial Phase. Can also be the primary period of topic resolution if you disable the Initial Phase. This phase can also be configured to run differently from the defaults or completely disabled. </li>
<li>
Quiescent Phase - The "steady state" period during which a topic is resolved and Ultra Messaging uses no system resources for topic resolution. </li>
</ul>
<p>The phases of topic resolution pertain to individual topics. Therefore if your system has 100 topics, 100 different topic resolution advertisement and query phases may be running concurrently. This describes the three phases of Ultra Messaging topic resolution.</p>
<dl class="section note"><dt>Note</dt><dd>With the UMQ product, topic resolution does not apply to brokered queuing sources, receivers, or the brokers themselves. However, ULB queuing does make use of topic resolution.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="multicasttopicresolution"></a>
Multicast Topic Resolution</h3>
<p>The following diagram depicts the UM topic resolution using multicast.</p>
<div class="image">
<img src="TopicResolution.png" alt="TopicResolution.png"/>
</div>
 <p>UM performs topic resolution automatically. Your application does not need to call any API functions to initiate topic resolution, however, you can influence topic resolution with <a class="el" href="index.html#topicresolutionconfigurationoptions">Topic Resolution Configuration Options</a>. Moreover, you can set configuration options for individual topics by using the lbm_*_attr_setopt() functions in your application. See <a class="el" href="index.html#topicresolutionconfigurationoptions">Topic Resolution Configuration Options</a> for details.</p>
<p>Topic Resolution also occurs across UM Routers, which means between Topic Resolution Domains. A Topic Resolution Domain refers to all the UM contexts that use the same UM topic resolution configuration values, such as <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastresolvernetwork.html#resolvermulticastaddresscontext">resolver_multicast_address (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastresolvernetwork.html#resolvermulticastportcontext">resolver_multicast_port (context)</a>. UM Routers automatically assign Topic Resolution Domain IDs and manage Topic resolution traffic across them. See the UM Router Guide for more information.</p>
<p>Multicast topic resolution traffic can benefit from hardware acceleration. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportacceleration.html">Transport Acceleration Options</a> in the <a href="../../Config/index.html">UM Configuration Guide</a> for more information.</p>
<dl class="section note"><dt>Note</dt><dd>The Unicast Topic Resolution Daemon (lbmrd) can not run on the OpenVMS platform. If unicast topic resolution is needed with OpenVMS, the lbmrd must be run on an alternate platform (e.g. Linux or Windows).</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="sourcesadvertise"></a>
Sources Advertise</h3>
<p>Ultra Messaging sources help Ultra Messaging receivers discover transport information in the following ways:</p>
<dl class="section user"><dt><b>Advertise</b> <b>Active</b> <b>Topics</b> </dt><dd>Each source advertises its active topic first upon its creation and subsequently according to the resolver_advertisement_*_interval configuration options for the Initial and Sustaining Phases. Sources advertise by sending a Topic Information Record (TIR). (You can prevent a source from sending an advertisement upon creation with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolversendinitialadvertisementsource">resolver_send_initial_advertisement (source)</a>.)</dd></dl>
<dl class="section user"><dt><b>Respond</b> <b>to</b> <b>Topic</b> <b>Queries</b> </dt><dd>Each source responds immediately to queries from receivers about its topic.</dd></dl>
<p>Both a topic advertisement and a query response contain the topic's transport session information. Based on the transport type, a receiver can join the appropriate multicast group (for LBT-RM), send a connection request (for LBT-RU), connect to the source (for TCP) or access a shared memory area (for LBT-IPC and SMX). A TIR may contain the following address and port information:</p>
<ul>
<li>
For a TCP transport, the source address, TCP port and Session ID. </li>
<li>
For an LBT-RM transport, the multicast group address, LBT-RM Session ID and the unicast UDP port (to which NAKs are sent) and the UDP destination port. </li>
<li>
For an LBT-RU transport, the source address, UDP port and Session ID. </li>
<li>
For an LBT-IPC transport, the Host ID, LBT-IPC Session ID and Transport ID. </li>
<li>
For an LBT-SMX transport, the Host ID, LBT-SMX Session ID and Transport ID. </li>
<li>
For an LBT-RDMA transport, the source address, RDMA port and Session ID. </li>
</ul>
<p>See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html">Resolver Operation Options</a> in the <a href="../../../Config/index.html">UM Configuration Guide</a> for more information.</p>
<p>With the UMP/UMQ products, any Persistent sources you configure to send to Persistent Stores by setting the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpultramessagingpersistence.html#umestoresource">ume_store (source)</a> configuration option, also include a Persistence flag in their advertisements. This indicates that the receiver should request the source to send a Source Registration Information (SRI) record, which identifies the store or stores the receiver should register with. See Source and Receiver Registration with the Store in the <a href="../../UME/UM_Guide_for_Persistence=en.pdf">UM Guide for Persistence</a> for more information.</p>
<p><br />
 </p>
<h3><a class="anchor" id="receiversquery"></a>
Receivers Query</h3>
<p>Receivers can discover transport information in the following ways.</p>
<ul>
<li>
Search advertisements collected in the resolver cache maintained by the UM context. </li>
<li>
Listen for source advertisements on the resolver_multicast_address:port. </li>
<li>
Send a topic query (TQR). </li>
</ul>
<p>A new receiver queries for its topic according to the resolver_query_*_interval configuration options for the Initial and Sustaining Phases.</p>
<p>Note that the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverqueryminimuminitialintervalreceiver">resolver_query_minimum_initial_interval (receiver)</a> actually begins after you call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a3de8a6a659896f76475c453683db4e18">lbm_rcv_topic_lookup()</a> prior to creating the receiver. If you have disabled the Initial Phase for the topic's resolution, the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolveradvertisementsustainintervalsource">resolver_advertisement_sustain_interval (source)</a> begins after you call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a3de8a6a659896f76475c453683db4e18">lbm_rcv_topic_lookup()</a>.</p>
<p>A Topic Query Record (TQR) consists primarily of the topic string. Receivers continue querying on a topic until they discover the number of sources configured by <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolutionnumberofsourcesquerythresholdreceiver">resolution_number_of_sources_query_threshold (receiver)</a>. However the large default of this configuration option (10,000,000) allows a receiver to continue to query until both the initial and sustaining phase of topic resolution complete.</p>
<p>See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html">Resolver Operation Options</a> in the <a href="../../../Config/index.html">UM Configuration Guide</a> for more information.</p>
<p><br />
 </p>
<h3><a class="anchor" id="wildcardreceivertopicresolution"></a>
Wildcard Receiver Topic Resolution</h3>
<p><a class="el" href="index.html#umwildcardreceivers">UM Wildcard Receivers</a> can discover transport information in the following ways:</p>
<ul>
<li>
Search advertisements collected in the resolver cache maintained by the UM context. </li>
<li>
Listen for source advertisements on the resolver_multicast_address:port. </li>
<li>
Send a wildcard receiver topic query (WC-TQR). </li>
</ul>
<p>UM implements only one phase of wildcard receiver queries, sending wildcard receiver queries according to wildcard receiver resolver_query_*_interval configuration options until the topic pattern has been queried for the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpwildcardreceiver.html#resolverqueryminimumdurationwildcardreceiver">resolver_query_minimum_duration (wildcard_receiver)</a>. The wildcard receiver topic query (WC-TQR) contains the topic pattern and the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpwildcardreceiver.html#patterntypewildcardreceiver">pattern_type (wildcard_receiver)</a>.</p>
<p>See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpwildcardreceiver.html">Wildcard Receiver Options</a> in the <a href="../../../Config/index.html">UM Configuration Guide</a> for more information.</p>
<p><br />
 </p>
<h3><a class="anchor" id="initialphase"></a>
Initial Phase</h3>
<p>The initial topic resolution phase for a topic is an aggressive phase that can be used to resolve all topics before sending any messages. During the initial phase, network traffic and CPU utilization might actually be higher. You can completely disable this phase, if desired. See Disabling Aspects of Topic Resolution in the <a href="../../Config/index.html">UM Configuration Guide</a>.</p>
<p><b>Advertising in the Initial Phase</b></p>
<p>For the initial phase default settings, the resolver issues the first advertisement as soon as the scheduler can process it. The resolver issues the second advertisement 10 ms later, or at the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolveradvertisementminimuminitialintervalsource">resolver_advertisement_minimum_initial_interval (source)</a>. For each subsequent advertisement, UM doubles the interval between advertisements. The source sends an advertisement at 20 ms, 40 ms, 80 ms, 160 ms, 320 ms and finally at 500 ms, or the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolveradvertisementmaximuminitialintervalsource">resolver_advertisement_maximum_initial_interval (source)</a>. These 8 advertisements require a total of 1130 ms. The interval between advertisements remains at the maximum 500 ms, resulting in 7 more advertisements before the total duration of the initial phase reaches 5000 ms, or the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolveradvertisementminimuminitialdurationsource">resolver_advertisement_minimum_initial_duration (source)</a>. This concludes the initial advertisement phase for the topic.</p>
<div class="image">
<img src="Resolver_Initial_Phase_TIR.png" alt="Resolver_Initial_Phase_TIR.png"/>
</div>
 <p>The initial phase for a topic can take longer than the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolveradvertisementminimuminitialdurationsource">resolver_advertisement_minimum_initial_duration (source)</a> if many topics are in resolution at the same time. The configuration options, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverinitialadvertisementspersecondcontext">resolver_initial_advertisements_per_second (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverinitialadvertisementbpscontext">resolver_initial_advertisement_bps (context)</a> enforce a rate limit on topic advertisements for the entire UM context. A large number of topics in resolution - in any phase - or long topic names may exceed these limits.</p>
<p>If a source advertising in the initial phase receives a topic query, it responds with a topic advertisement. UM recalculates the next advertisement interval from that point forward as if the advertisement was sent at the nearest interval.</p>
<p><b>Querying in the Initial Phase</b></p>
<p>Querying activity by receivers in the initial phase operates in similar fashion to advertising activity, although with different interval defaults. The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverqueryminimuminitialintervalreceiver">resolver_query_minimum_initial_interval (receiver)</a> default is 20 ms. Subsequent intervals double in length until the interval reaches 200 ms, or the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverquerymaximuminitialintervalreceiver">resolver_query_maximum_initial_interval (receiver)</a>. The query interval remains at 200 ms until the initial querying phase reaches 5000 ms, or the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverqueryminimuminitialdurationreceiver">resolver_query_minimum_initial_duration (receiver)</a>.</p>
<div class="image">
<img src="Resolver_Initial_Phase_TQR.png" alt="Resolver_Initial_Phase_TQR.png"/>
</div>
 <p>The initial query phase completes when it reaches the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverqueryminimuminitialdurationreceiver">resolver_query_minimum_initial_duration (receiver)</a>. The initial query phase also has UM context-wide rate limit controls (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverinitialqueriespersecondcontext">resolver_initial_queries_per_second (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverinitialquerybpscontext">resolver_initial_query_bps (context)</a>) that can result in the extension of a phase's duration in the case of a large number of topics or long topic names.</p>
<p><br />
 </p>
<h3><a class="anchor" id="sustainingphase"></a>
Sustaining Phase</h3>
<p>The sustaining topic resolution phase follows the initial phase and can be a less active phase in which a new receiver resolves its topic. It can also act as the sole topic resolution phase if you disable the initial phase. The sustaining phase defaults use less network resources than the initial phase and can also be modified or disabled completely. See Disabling Aspects of Topic Resolution in the UM Configuration Guide.</p>
<p><b>Advertising in the Sustaining Phase</b></p>
<p>For the sustaining phase defaults, a source sends an advertisement every second (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolveradvertisementsustainintervalsource">resolver_advertisement_sustain_interval (source)</a>) for 1 minute (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolveradvertisementminimumsustaindurationsource">resolver_advertisement_minimum_sustain_duration (source)</a>). When this duration expires, the sustaining phase of advertisement for a topic ends. If a source receives a topic query, the sustaining phase resumes for the topic and the source completes another duration of advertisements.</p>
<div class="image">
<img src="Resolver_Sustain_Phase_TIR.png" alt="Resolver_Sustain_Phase_TIR.png"/>
</div>
 <p>The sustaining advertisement phase has UM context-wide rate limit controls (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolversustainadvertisementspersecondcontext">resolver_sustain_advertisements_per_second (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolversustainadvertisementbpscontext">resolver_sustain_advertisement_bps (context)</a>) that can result in the extension of a phase's duration in the case of a large number of topics or long topic names.</p>
<p><b>Querying in the Sustaining Phase</b></p>
<p>Default sustaining phase querying operates the same as advertising. Unresolved receivers query every second (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverquerysustainintervalreceiver">resolver_query_sustain_interval (receiver)</a>) for 1 minute (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverqueryminimumsustaindurationreceiver">resolver_query_minimum_sustain_duration (receiver)</a>). When this duration expires, the sustaining phase of querying for a topic ends.</p>
<div class="image">
<img src="Resolver_Sustain_Phase_TQR.png" alt="Resolver_Sustain_Phase_TQR.png"/>
</div>
 <p>Sustaining phase queries stop when one of the following events occurs:</p>
<ul>
<li>
The receiver discovers multiple sources that equal <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolutionnumberofsourcesquerythresholdreceiver">resolution_number_of_sources_query_threshold (receiver)</a>. </li>
<li>
The sustaining query phase reaches the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverqueryminimumsustaindurationreceiver">resolver_query_minimum_sustain_duration (receiver)</a>. </li>
</ul>
<p>The sustaining query phase also has UM context-wide rate limit controls (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolversustainqueriespersecondcontext">resolver_sustain_queries_per_second (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolversustainquerybpscontext">resolver_sustain_query_bps (context)</a>) that can result in the extension of a phase's duration in the case of a large number of topics or long topic names.</p>
<p><br />
 </p>
<h3><a class="anchor" id="quiescentphase"></a>
Quiescent Phase</h3>
<p>This phase is the absence of topic resolution activity for a given topic. It is possible that some topics may be in the quiescent phase at the same time other topics are in initial or sustaining phases of topic resolution.</p>
<p>This phase ends if either of the following occurs.</p>
<ul>
<li>
A new receiver sends a query. </li>
<li>
Your application calls <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ae6dd7c56acf916ef66658cc1ebc7a525">lbm_context_topic_resolution_request()</a> that provokes the sending of topic queries for any receiver or wildcard receiver in this state. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="storecontextnameresolution"></a>
Store (context) Name Resolution</h3>
<p>With the UMP/UMQ products, topic resolution facilitates the resolution of Persistent Store names to a DomainID:IPAddress:Port.</p>
<p>Topic Resolution resolves store (or context) names by sending context name queries and context name advertisements over the topic resolution channel. A store name resolves to the store's DomainID:IPAddress:Port. You configure the store's name and IPAddress:Port in the store's XML configuration file. See Identifying Persistent Stores in the <a href="../../UME/UM_Guide_for_Persistence=en.pdf">UM Guide for Persistence</a> for more information.</p>
<p>If you do not use UM Routers, the DomainID is zero. Otherwise, the DomainID represents the Topic Resolution Domain where the store resides. Stores can learn their DomainID by listening to Topic Resolution traffic. See the UM Router Guide for more information about Topic Resolution Domains.</p>
<p>Via the Topic Resolution channel, sources query for store names and stores respond with an advertisement when they see a query for their own store name. The advertisement contains the store's DomainID:IPAddress:Port.</p>
<p>For a new source configured to use a store names (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpultramessagingpersistence.html#umestorenamesource">ume_store_name (source)</a>), the resolver issues the first context name query as soon as the scheduler can process it. The resolver issues the second advertisement 100 ms later, or at the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolvercontextnamequeryminimumintervalcontext">resolver_context_name_query_minimum_interval (context)</a>. For each subsequent query, UM doubles the interval between queries. The source sends a query at 200 ms, 400 ms, 800 ms and finally at 1000 ms, or the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolvercontextnamequerymaximumintervalcontext">resolver_context_name_query_maximum_interval (context)</a>. The interval between queries remains at the maximum 1000 ms until the total time querying for a store (context) name equals <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolvercontextnamequerydurationcontext">resolver_context_name_query_duration (context)</a>. The default for this duration is 0 (zero) which means the resolver continues to send queries until the name resolves. After a store name resolves, the resolver stops sending queries.</p>
<p>If a source sees advertisements from multiple stores with the same name, or a store sees an advertisement that matches its own store name, the source issues a warning log message. The source also issues an informational log message whenever it detects that a resolved store (context) name changes to a different DomainID:IPAddress:Port.</p>
<p><br />
 </p>
<h3><a class="anchor" id="topicresolutionconfigurationoptions"></a>
Topic Resolution Configuration Options</h3>
<p>See the following sections in <a href="../../../Config/index.html">UM Configuration Guide</a> for more information"</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html">Resolver Operation Options</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastresolvernetwork.html">Multicast Resolver Network Options</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpunicastresolvernetwork.html">Unicast Resolver Network Options</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpwildcardreceiver.html">Wildcard Receiver Options</a> </li>
</ul>
<p><b>Assigning Different Configuration Options to Individual Topics</b></p>
<p>You can assign different configuration option values to individual topics by accessing the topic attribute table (lbm_*_topic_attr_t_stct) before creating the source, receiver or wildcard receiver.</p>
<p>Creating a Source with Different Topic Resolution Options:</p>
<ol>
<li>
Call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a96ea052dce2e6376684cbf2003407cbf">lbm_src_topic_attr_setopt()</a> to set new option value </li>
<li>
Call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a1ba60407fa2bde0997aab6d5a5d2da1a">lbm_src_topic_alloc()</a> </li>
<li>
Call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab8dd76271bf9df7a5f88476d431f523e">lbm_src_create()</a> </li>
</ol>
<p>Creating a Receiver with Different Topic Resolution Options:</p>
<ol>
<li>
Call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a1afc75f0fb3601d072b3463e7acf16a6">lbm_rcv_topic_attr_setopt()</a> to set new option value </li>
<li>
Call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a3de8a6a659896f76475c453683db4e18">lbm_rcv_topic_lookup()</a> </li>
<li>
Call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aa7491c50fefbc2b70f8035fce7ac1477">lbm_rcv_create()</a> </li>
</ol>
<p>Creating a Wildcard Receiver with Different Topic Resolution Options:</p>
<ol>
<li>
Call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#acec52fdb461e1f903b319e086d1d3e10">lbm_wildcard_rcv_attr_setopt()</a> to set new wildcard receiver option value </li>
<li>
Call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a5b5d52f6b87499213757b73b09bc8160">lbm_wildcard_rcv_create()</a> </li>
</ol>
<p><b>Multicast Network Options</b></p>
<p>Essentially, the _incoming and _outgoing versions of resolver_multicast_address/port provide more fine-grained control of topic resolution. By default, the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastresolvernetwork.html#resolvermulticastaddresscontext">resolver_multicast_address (context)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastresolvernetwork.html#resolvermulticastportcontext">resolver_multicast_port (context)</a> and the _incoming and _outgoing address and port are set to the same value. If you want your context to listen to a particular multicast address/port and send on another address/port, then you can set the _incoming and _outgoing configuration options to different values.</p>
<p>See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html">Resolver Operation Options</a> in the <a href="../../../Config/index.html">UM Configuration Guide</a> for more information.</p>
<p><br />
 </p>
<h3><a class="anchor" id="unicasttopicresolution"></a>
Unicast Topic Resolution</h3>
<p>By default UM expects multicast connectivity between all sources and receivers. When only unicast connectivity is available, you may configure all sources and receivers to use unicast topic resolution. This requires that you run one or more instances of the UM unicast topic resolution daemon (lbmrd), which perform the same topic resolution activities as multicast topic resolution. You configure your applications to use the lbmrd daemons with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpunicastresolvernetwork.html#resolverunicastdaemoncontext">resolver_unicast_daemon (context)</a>.</p>
<p>See <a class="el" href="index.html#manpageforlbmrd">Manpage for lbmrd</a> for details on running the lbmrd daemon.</p>
<p>The lbmrd can run on any machine, including the source or receiver. Of course, sources will also have to select a transport protocol that uses unicast addressing (e.g. TCP, TCP-LB, or LBT-RU). The lbmrd maintains a table of clients (address and port pairs) from which it has received a topic resolution message, which can be any of the following:</p>
<ul>
<li>
Topic Information Records (TIR) - also known as topic advertisements </li>
<li>
Topic Query Records (TQR) </li>
<li>
keepalive messages, which are only used in unicast topic resolution </li>
</ul>
<p>After lbmrd receives a TQR or TIR, it forwards it to all known clients. If a client (i.e. source or receiver) is not sending either TIRs or TQRs, it sends a keepalive message to lbmrd according to the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverunicastkeepaliveintervalcontext">resolver_unicast_keepalive_interval (context)</a>. This registration with the lbmrd allows the client to receive advertisements or queries from lbmrd. lbmrd maintains no state about topics, only about clients.</p>
<dl class="section note"><dt>Note</dt><dd>The Unicast Topic Resolution Daemon (lbmrd) can not run on the OpenVMS platform. If unicast topic resolution is needed with OpenVMS, the lbmrd must be run on an alternate platform (e.g. Linux or Windows).</dd></dl>
<p><b>LBMRD with the UM Router Best Practice</b></p>
<p>If you're using the lbmrd for topic resolution across UM Routers, you may want all of your domains discovered and all routes to be known before creating any topics. If so, change the UM configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresolveroperation.html#resolverunicastforcealivecontext">resolver_unicast_force_alive (context)</a>, from the default setting to 1 so your contexts start sending keepalives to lbmrd immediately. This makes your startup process cleaner by allowing your contexts to discover the other Topic Resolution Domains and establish the best routes. The trade off is a little more network traffic every 5 seconds.</p>
<p><b>Unicast Topic Information Records</b></p>
<p>Of all topic resolution messages, only the TIR contains address and port information. This tells a receiver how it can get the data being published. Based on the transport type, a receiver can join the appropriate multicast group (for LBT-RM), send a connection request (for LBT-RU), or connect to the source (for TCP).</p>
<p>The address and port information potentially contained within a TIR includes:</p>
<ul>
<li>
For a TCP transport, the source address and TCP port. </li>
<li>
For an LBT-RM transport, the unicast UDP port (to which NAKs are sent) and the UDP destination port. </li>
<li>
For an LBT-RU transport, the source address and UDP port. </li>
</ul>
<p>For unicast-based transports (TCP and LBT-RU), the TIR source address is 0.0.0.0, not the actual source address.</p>
<p>Topic resolution messages (whether received by the application via multicast, or by the unicast topic resolution daemon via unicast) are always UDP datagrams. They are received via a recvfrom() call, which also obtains the address and port from which the datagrams were received. If the address 0.0.0.0 (INADDR_ANY) appears for one of the addresses, lbmrd replaces it with the address from which the datagram is received. The net effect is as if the actual source address had originally been put into the TIR.</p>
<p><b>Unicast Topic Resolution Resilience</b></p>
<p>Running multiple instances of lbmrd allows your applications to continue operation in the face of a lbmrd failure. Your applications' sources and receivers send topic resolution messages as usual, however, rather than sending every message to each lbmrd instance, UM directs messages to lbmrd instances in a round-robin fashion. Since the lbmrd does not maintain any resolver state, as long as one lbmrd instance is running, UM continues to forward LBMR packets to all connected clients. UM switches to the next active lbmrd instance every 250-750 ms.</p>
<p><br />
 </p>
<h3><a class="anchor" id="networkaddresstranslationnat"></a>
Network Address Translation (NAT)</h3>
<p>If your network architecture includes LANs that are bridged with Network Address Translation (NAT), UM receivers will not be able to connect directly to UM sources across the NAT. Sources send Topic Resolution advertisements containing their local IP addresses and ports, but receivers on the other side of the NAT cannot access those sources using those local addresses/ports. They must use alternate addresses/ports, which the NAT forwards according to the NAT's configuration.</p>
<p>The recommended method of establishing UM connectivity across a NAT is to run a pair of UM Routers connected with a single TCP peer link. In this usage, the LANs on each side of the NAT are distinct Topic Resolution Domains.</p>
<p>Alternatively, if the NAT can be configured to allow two-way UDP traffic between the networks, the lbmrd can be configured to modify Topic Resolution advertisements according to a set of rules defined in an XML configuration file. Those rules allow a source's advertisements forwarded to local receivers to be sent as-is, while advertisements forwarded to remote receivers are modified with the IP addresses and ports that the NAT expects. In this usage, the LANs on each side of the NAT are combined into a single Topic Resolution domain.</p>
<dl class="section warning"><dt>Warning</dt><dd>Using an lbmrd NAT configuration severely limits the UM features that can be used across the NAT. Normal source-to-receiver traffic is supported, but the following more-advanced UM features are not supported: <ul>
<li>
<a class="el" href="index.html#persistence">Persistence</a> </li>
<li>
<a class="el" href="index.html#queuing">Queuing</a> </li>
<li>
<a class="el" href="index.html#requestresponse">Request/Response</a> </li>
<li>
<a class="el" href="index.html#latejoin">Late Join</a> </li>
<li>
<a class="el" href="index.html#offtransportrecoveryotr">Off-Transport Recovery (OTR)</a> </li>
<li>
<a class="el" href="index.html#sendingtosources">Sending to Sources</a> </li>
</ul>
Late Join, sending to sources, and OTR can be made to work if applications are configured to use the default value (0.0.0.0) for <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpinterfacecontext">request_tcp_interface (context)</a>. This means that you cannot use <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#defaultinterfacecontext">default_interface (context)</a>. Be aware that the UM Router requires a valid interface be specified for <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpinterfacecontext">request_tcp_interface (context)</a>. Thus, <b>lbmrd NAT support for Late Join, Request/Response, and OTR is not compatible with UM topologies that contain the UM Router</b>.</dd></dl>
<p><b>Example NAT configuration</b></p>
<p>In this example, there are two networks, A and B, that are interconnected via a NAT firewall. Network A has IP addresses in the 10.1.0.0/16 range, and B has IP addresses in the 192.168.1/24 range. The NAT is configured such that hosts in network B have no visibility into network A, and can send TCP and UDP packets to only a single host in A (10.1.1.50) via the NAT's external IP address 192.168.1.1, ports 12000 and 12001. I.e. packets sent from B to 192.168.1.1:12000 are forwarded to 10.1.1.50:12000, and packets from B to 192.168.1.1:12001 are forwarded to 10.1.1.50:12001. Hosts in network A have full visibility of network B and can send TCP and UDP packets to hosts in B by their local 192 addresses and ports. Those packets have their source addresses changed to 192.168.1.1.</p>
<p>Since hosts in network A have full visibility into network B, receivers in network A should be able to use source advertisements from network B without any changes. However, receivers in network B will not be able to use source advertisements from network A unless those advertisements' IP addresses are transformed.</p>
<p>The lbmrd is configured for NAT using its XML configuration file:</p>
<pre class="fragment">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
&lt;lbmrd version="1.0"&gt;
  &lt;daemon&gt;
    &lt;interface&gt;10.1.1.50&lt;/interface&gt;
    &lt;port&gt;12000&lt;/port&gt;
  &lt;/daemon&gt;
  &lt;domains&gt;
    &lt;domain name="DomainA"&gt;
      &lt;network&gt;10.1.0.0/16&lt;/network&gt;
    &lt;/domain&gt;
    &lt;domain name="DomainB"&gt;
      &lt;network&gt;192.168.1/24&lt;/network&gt;
    &lt;/domain&gt;
  &lt;/domains&gt;
  &lt;transformations&gt;
    &lt;transform source="DomainA" destination="DomainB"&gt;
      &lt;rule&gt;
        &lt;match address="10.1.1.50" port="*"/&gt;
        &lt;replace address="192.168.1.1" port="*"/&gt;
      &lt;/rule&gt;
    &lt;/transform&gt;
  &lt;/transformations&gt;
&lt;/lbmrd&gt;
</pre><p>The lbmrd must be run on 10.1.1.50.</p>
<p>The application on 10.1.1.50 should be configured with:</p>
<pre class="fragment">context resolver_unicast_daemon 10.1.1.50:12000
source transport_tcp_port 12001
</pre><p>The applications in the 192 network should be configured with:</p>
<pre class="fragment">context resolver_unicast_daemon 192.168.1.1:12000
source transport_tcp_port 12100
</pre><p>With this, the application on 10.1.1.50 is able to create sources and receivers that communicate with applications in the 192 network.</p>
<p>See <a class="el" href="index.html#lbmrdconfigurationfile">lbmrd Configuration File</a> for full details of the XML configuration file.</p>
<p><br />
 </p>
<h2><a class="anchor" id="messagebatching"></a>
Message Batching</h2>
<p>Batching many small messages into fewer network packets decreases the per-message CPU load, thereby increasing throughput. Let's say it costs 2 microseconds of CPU to fully process a message. If you process 10 messages per second, you won't notice the load. If you process half a million messages per second, you saturate the CPU. So to achieve high message rates, you have to reduce the per-message CPU cost with some form of message batching. These per-message costs apply to both the sender and the receiver. However, the implementation of batching is almost exclusively the realm of the sender.</p>
<p>Many people are under the impression that while batching improves CPU load, it increases message latency. While it is true that there are circumstances where this can happen, it is also true that careful use of batching can result in small latency increases or none at all. In fact, there are circumstances where batching can actually reduce latency.</p>
<p>With the UMQ product, you cannot use these message batching features with Brokered Queuing.</p>
<p><br />
 </p>
<h3><a class="anchor" id="implicitbatching"></a>
Implicit Batching</h3>
<p>UM automatically batches smaller messages into transport session datagrams. The implicit batching configuration options, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingintervalsource">implicit_batching_interval (source)</a> (default = 200 milliseconds) and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a> (default = 2048 bytes) govern UM implicit message batching. Although these are source options, they actually apply to the transport session to which the source was assigned.</p>
<p>See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html">Implicit Batching Options</a>.</p>
<p>See also <a class="el" href="index.html#sourceconfigurationandtransportsessions">Source Configuration and Transport Sessions</a>.</p>
<p>UM establishes the implicit batching parameters when it creates the transport session. Any sources assigned to that transport session use the implicit batching limits set for that transport session, and the limits apply to any and all sources subsequently assigned to that transport session. This means that batched transport datagrams can contain messages on multiple topics.</p>
<p><b>Implicit Batching Operation</b></p>
<p>Implicit Batching buffers messages until:</p>
<ul>
<li>
the buffer size exceeds the configured <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a> or </li>
<li>
the oldest message in the buffer has been in the buffer for <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingintervalsource">implicit_batching_interval (source)</a> milliseconds. When either condition is met, UM flushes the buffer, pushing the messages onto the network. </li>
</ul>
<p>It may appear this design introduces significant latencies for low-rate topics. However, remember that Implicit Batching operates on a transport session basis. Typically many low-rate topics map to the same transport session, providing a high aggregate rate. The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingintervalsource">implicit_batching_interval (source)</a> option is a last resort to prevent messages from becoming stuck in the Implicit Batching buffer. If your UM deployment frequently uses the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingintervalsource">implicit_batching_interval (source)</a> to push out the data (i.e. if the entire transport session has periods of inactivity longer than the value of <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingintervalsource">implicit_batching_interval (source)</a> (defaults to 200 ms), then either the implicit batching options need to be fine-tuned (reducing one or both), or you should consider an alternate form of batching. See <a class="el" href="index.html#intelligentbatching">Intelligent Batching</a>.</p>
<p>The minimum value for the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingintervalsource">implicit_batching_interval (source)</a> is 3 milliseconds. The actual minimum amount of time that data stays in the buffer depends on your Operating System and its scheduling clock interval. For example, on a Solaris 8 machine, the actual time is can be as much as 20 milliseconds. On older Microsoft Windows machines, the time can be as much as 16 milliseconds. On a Linux 2.6 kernel, the actual time is 3 milliseconds (+/- 1).</p>
<p><b>Implicit Batching Example</b></p>
<p>The following example demonstrates how the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a> is actually a trigger or floor, for sending batched messages. It is sometimes misconstrued as a ceiling or upper limit.</p>
<pre class="fragment">implicit_batching_minimum_length = 2000
</pre><ol>
<li>
The first send by your application puts 1900 bytes into the batching buffer, which is below the minimum, so UM holds it. </li>
<li>
The second send fills the batching buffer to 3800 bytes, well over the minimum. UM sends it down to the transport layer, which builds a 3800-byte (plus overhead) datagram and sends it. </li>
<li>
The Operating System fragments the datagram into packets independently of UM and reassembles them on the receiving end. </li>
<li>
UM reads the datagram from the socket at the receiver. </li>
<li>
UM parses out the two messages and delivers them to the appropriate topic levels, which deliver the data. </li>
</ol>
<p>The proper setting of the implicit batching parameters often represents a trade off between latency and efficiency, where efficiency affects the highest throughput attainable. In general, a large minimum length setting increases efficiency and allows a higher peak message rate, but at low message rates a large minimum length can increase latency. A small minimum length can lower latency at low message rates, but does not allow the message rate to reach the same peak levels due to inefficiency. An intelligent use of implicit batching and application-level flushing can be used to implement an adaptive form of batching known as <a class="el" href="index.html#intelligentbatching">Intelligent Batching</a> which can provide low latency and high throughput with a single setting.</p>
<p><br />
 </p>
<h3><a class="anchor" id="intelligentbatching"></a>
Intelligent Batching</h3>
<p>Intelligent Batching uses Implicit Batching along with your application's knowledge of the messages it must send. It is a form of dynamic adaptive batching that automatically adjusts for different message rates. Intelligent Batching can provide significant savings of CPU resources without adding any noticeable latency.</p>
<p>For example, your application might receive input events in a batch, and therefore know that it must produce a corresponding batch of output messages. Or the message producer works off of an input queue, and it can detect messages in the queue. In any case, if the application knows that it has more messages to send without going to sleep, it simply does normal sends to UM, letting Implicit Batching send only when the buffer meets the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a> threshold.</p>
<p>However, when the application detects that it has no more messages to send after it sends the current message, it sets the FLUSH flag (LBM_MSG_FLUSH) when sending the message which instructs UM to flush the implicit batching buffer immediately by sending all messages to the transport layer. Refer to <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a> in the UM API documentation (UM C API, UM Java API, or UM .NET API) for all the available send flags.</p>
<p>When using Intelligent Batching, it is usually advisable to increase the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a> option to 10 times the size of the average message, to a maximum value of 8196. This tends to strike a good balance between batching length and flushing frequency, giving you low latencies across a wide variation of message rates.</p>
<p><br />
 </p>
<h3><a class="anchor" id="applicationbatching"></a>
Application Batching</h3>
<p>In all of the above situations, your application sends individual messages to UM and lets UM decide when to push the data onto the wire (often with application help). With application batching, your application buffers messages itself and sends a group of messages to UM with a single send. Thus, UM treats the send as a single message. On the receiving side, your application needs to know how to dissect the UM message into individual application messages.</p>
<p>This approach is most useful for Java or .NET applications where there is a higher per-message cost in delivering an UM message to the application. It can also be helpful when using an event queue to deliver received messages. This imposes a thread switch cost for each UM message. At low message rates, this extra overhead is not noticeable. However, at high message rates, application batching can significantly reduce CPU overhead.</p>
<p><br />
 </p>
<h3><a class="anchor" id="explicitbatching"></a>
Explicit Batching</h3>
<p>UM allows you to group messages for a particular topic with explicit batching. The purpose of grouping messages with explicit batching is to allow the receiving application to detect the first and last messages of a group without needing to examine the message contents.</p>
<dl class="section note"><dt>Note</dt><dd>Explicit Batching does not guarantee that all the messages of a group will be sent in a single datagram.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Explicit Batching does not provide any kind of transactional guarantee. It is possible to receive some messages of a group while others are unrecoverably lost. If the first and/or last messages of a group are unrecoverably lost, then the receiving application will not have an indication of start and/or end of the group.</dd></dl>
<p>When your application sends a message (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a>) it may flag the message as being the start of a batch (LBM_MSG_START_BATCH) or the end of a batch (LBM_MSG_END_BATCH). All messages sent between the start and end are grouped together. The flag used to indicate the end of a batch also signals UM to send the message immediately to the implicit batching buffer. At this point, <a class="el" href="index.html#implicitbatching">Implicit Batching</a> completes the batching operation. UM includes the start and end flags in the message so receivers can process the batched messages effectively.</p>
<p>Unlike Intelligent Batching which allows intermediate messages to trigger flushing according to the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a> option, explicit batching holds all messages until the batch is completed. This feature is useful if you configure a relatively small <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a> and your application has a batch of messages to send that exceeds the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a>. By releasing all the messages at once, Implicit Batching maximizes the size of the network datagrams.</p>
<p><b>Explicit Batching Example</b></p>
<p>The following example demonstrates explicit batching.</p>
<pre class="fragment">implicit_batching_minimum_length = 8000
</pre><ol>
<li>
Your application performs 10 sends of 100 bytes each as a single explicit batch. </li>
<li>
At the 10th send (which completes the batch), UM delivers the 1000 bytes of messages to the implicit batch buffer. </li>
<li>
Let's assume that the buffer already has 7899 bytes of data in it from other topics on the same transport session </li>
<li>
UM adds the first 100-byte message to the buffer, bringing it to 7999. </li>
<li>
UM adds the second 100-byte message, bringing it up to 8099 bytes, which exceeds </li>
<li>
licit_batching_minimum_length but is below the 8192 maximum datagram size. </li>
<li>
UM sends the 8099 bytes (plus overhead) datagram. </li>
<li>
UM adds the third through tenth messages to the implicit batch buffer. These messages will be sent when either <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingminimumlengthsource">implicit_batching_minimum_length (source)</a> is again exceeded, or the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpimplicitbatching.html#implicitbatchingintervalsource">implicit_batching_interval (source)</a> is met, or a message arrives in the buffer with the flush flag (LBM_MSG_FLUSH) set. </li>
</ol>
<p><br />
 </p>
<h3><a class="anchor" id="adaptivebatching"></a>
Adaptive Batching</h3>
<p>The adaptive batching feature is deprecated and will be removed from the product in a future release.</p>
<p><br />
 </p>
<h2><a class="anchor" id="ordereddelivery"></a>
Ordered Delivery</h2>
<p>With the Ordered Delivery feature, a receiver's delivery controller can deliver messages to your application in sequence number order or arrival order. This feature can also reassemble fragmented messages or leave reassembly to the application. You can set Ordered Delivery via UM configuration option to one of three modes:</p>
<ul>
<li>
Sequence Number Order, Fragments Reassembled </li>
<li>
Arrival Order, Fragments Reassembled </li>
<li>
Arrival Order, Fragments Not Reassembled </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="sequencenumberorderfragmentsreassembleddefaultmode"></a>
Sequence Number Order, Fragments Reassembled (Default Mode)</h3>
<p>In this mode, a receiver's delivery controller delivers messages in sequence number order (the same order in which they are sent). This feature also guarantees reassembly of fragmented large messages. To enable sequence number ordered delivery, set the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a> configuration option as shown:</p>
<pre class="fragment">receiver ordered_delivery 1
</pre><p>Please note that ordered delivery can introduce latency when packets are lost (new messages are buffered waiting for retransmission of lost packets).</p>
<p><br />
 </p>
<h3><a class="anchor" id="arrivalorderfragmentsreassembled"></a>
Arrival Order, Fragments Reassembled</h3>
<p>This mode delivers messages immediately upon reception, in the order the datagrams are received, except for fragmented messages, which UM holds and reassembles before delivering to your application. Be aware that messages can be delivered out of order, either because of message loss and retransmission, or because the networking hardware re-orders UDP packets. Your application can then use the sequence_number field of lbm_msg_t objects to order or discard messages.</p>
<p>To enable this arrival-order-with-reassembly mode, set the following configuration option as shown:</p>
<pre class="fragment">receiver ordered_delivery -1
</pre><p><br />
 </p>
<h3><a class="anchor" id="arrivalorderfragmentsnotreassembled"></a>
Arrival Order, Fragments Not Reassembled</h3>
<p>This mode allows messages to be delivered to the application immediately upon reception, in the order the datagrams are received. If a message is lost, UM will retransmit the message. In the meantime, any subsequent messages received are delivered immediately to the application, followed by the dropped packet when its retransmission is received. This mode guarantees the lowest latency.</p>
<p>With this mode, the receiver delivers messages larger than the transport's maximum datagram size as individual fragments. (See transport_*_datagram_max_size in the <a href="../../Config/index.html">UM Configuration Guide</a>.) The C API function, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#afa760960c21f502a8cb4c5ec5d97f91b">lbm_msg_retrieve_fragment_info()</a> returns fragmentation information for the message you pass to it, and can be used to reassemble large messages. (In Java and .NET, LBMMessage provides methods to return the same fragment information.) Note that reassembly is not required for small messages.</p>
<p>To enable this no-reassemble arrival-order mode, set the following configuration option as shown:</p>
<pre class="fragment">receiver ordered_delivery 0
</pre><p>When developing message reassembly code, consider the following:</p>
<ul>
<li>
Message fragments don't necessarily arrive in sequence number order. </li>
<li>
Some message fragments may never arrive (unrecoverable loss), so you must time out partial messages. </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="lossdetectionusingtsnis"></a>
Loss Detection Using TSNIs</h2>
<p>When a source enters a period during which it has no data traffic to send, that source issues timed Topic Sequence Number Info (TSNI) messages. The TSNI lets receivers know that the source is still active and also reminds receivers of the sequence number of the last message. This helps receivers become aware of any lost messages between TSNIs.</p>
<p>Sources send TSNIs over the same transport and on the same topic as normal data messages. You can set a time value of the TSNI interval with configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#transporttopicsequencenumberinfointervalsource">transport_topic_sequence_number_info_interval (source)</a>. You can also set a time value for the duration that the source sends contiguous TSNIs with configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#transporttopicsequencenumberinfoactivethresholdsource">transport_topic_sequence_number_info_active_threshold (source)</a>, after which time the source stops issuing TSNIs.</p>
<p><br />
 </p>
<h2><a class="anchor" id="receiverkeepaliveusingsesssionmessages"></a>
Receiver Keepalive Using Session Messages</h2>
<p>When an LBT-RM, LBT-RU, or LBT-IPC transport session enters a period during which it has no data traffic to send, UM issues timed Session Messages (SMs). For example, suppose all topics in a session stop sending data. One by one, they then send TSNIs, and if there is still no data to send, their TSNI periods eventually expire. After the last quiescent topic's TSNIs stop, UM begins transmitting SMs.</p>
<p>You can set time values for SM interval and duration with configuration options specific to their transport type.</p>
<div class="image">
<img src="SMs.png" alt="SMs.png"/>
</div>
 <p><br />
 </p>
<h1><a class="anchor" id="umfeatures"></a>
UM Features</h1>
<p>Except where otherwise indicated, the features described in this section are available in the UMS, UMP, and UMQ products.</p>
<p><br />
 </p>
<h2><a class="anchor" id="transportservicesproviderxsp"></a>
Transport Services Provider (XSP)</h2>
<p>As of UM version 6.11, a new receive-side object is available to the user: the <a class="el" href="index.html#transportservicesproviderobject">Transport Services Provider Object</a>.</p>
<p>The earlier feature, <a class="el" href="index.html#multitransportthreads">Multi-Transport Threads</a>, is deprecated in favor of XSP.</p>
<p>By default, a UM context combines all network data reception into a single <em>context thread</em>. This thread is responsible for reception and processing of application messages, topic resolution, and immediate message traffic (UIM and MIM). The context thread is also used for processing timers. This single-threaded model conserves CPU core resources, and can simplify application design. However, it can also introduce significant latency outliers (jitter) if a time-sensitive user message is waiting behind, say, a topic resolution message, or a timer callback.</p>
<p>Using an XSP object, an application can reassign the processing of a subscribed transport session to an independent thread. This allows concurrent processing of received messages with topic resolution and timers, and even allows different groups transport sessions to be processed concurrently with each other.</p>
<p>By default, when an XSP object is created, UM creates a new thread associated with the XSP. Alternatively, the XSP can be created with operational mode "sequential", which gives the responsibility of thread creation to the application. Either way, the XSP uses its independent thread to read data from the sockets associated with one or more subscribed transport sessions. That thread then delivers received messages to the application via a normal receive application callback function.</p>
<p>Creation of an XSP does not by itself cause any receiver transport sessions to be assigned to it. Central to the use of XSPs is an application-supplied mapping callback function which tells UM which XSP to associate with subscribed transport sessions as they are discovered and joined. This callback allows the application to examine the newly-joined transport session, if desired. Then the callback returns, informing UM which XSP, if any, to assign the receiver transport session to.</p>
<p><br />
 </p>
<h3><a class="anchor" id="xsphandlestransportsessionsnottopics"></a>
XSP Handles Transport Sessions, Not Topics</h3>
<p>Conceptually, an application designer might want to assign the reception and processing of received data to XSPs on a topic basis. This is not always possible. The XSP thread must process received data on a socket basis, and sockets map to <em>transport sessions</em>. As mentioned in <a class="el" href="index.html#umtransports">UM Transports</a>, a publishing application maps one or more topic-based sources to a transport session.</p>
<p>Consider the following example:</p>
<div class="image">
<img src="xsp_1.png" alt="xsp_1.png"/>
</div>
 <p>Publisher A and B are two separate application instances, both of which create a source for topic "X". A subscriber application might create two XSPs and assign one transport session to each. In this case, you have two independent threads delivering messages to the subscriber's receiver callback, which may not be what the developer wanted. If the developer wants topic X to be serialized, a single XSP should be created and mapped to both transport sessions:</p>
<div class="image">
<img src="xsp_2.png" alt="xsp_2.png"/>
</div>
 <p>Now let's introduce a second topic. The developer might want to create two XSPs so that each topic will be handled by an independent thread. However, this is not possible, given the way that the topics are mapped to transport sessions in the following example:</p>
<div class="image">
<img src="xsp_3.png" alt="xsp_3.png"/>
</div>
 <p>In this case, XSP 1 is delivering both topics X and Y from Publisher A, and XSP 2 is delivering topics X and Y from Publisher B. Once again, the receiver callback for topic X will be called by two independent threads, which is not desired.</p>
<p>The only way to achieve independent processing of topics is to design the publishers to map their topics to transport sessions carefully. For example:</p>
<div class="image">
<img src="xsp_4.png" alt="xsp_4.png"/>
</div>
 <p><br />
 </p>
<h3><a class="anchor" id="xspthreadingconsiderations"></a>
XSP Threading Considerations</h3>
<p>When contexts are used single-threaded, the application programmer can assume serialization of event delivery to the application callbacks. This can greatly simplify the design of applications, at the cost of added latency outliers (jitter).</p>
<p>When XSPs are used to provide multi-threaded receivers, care must be taken in application design to account for potential concurrent calls to application callbacks. This is especially true if multiple subscribed transport sessions are assigned different XSPs, as demonstrated in <a class="el" href="index.html#xsphandlestransportsessionsnottopics">XSP Handles Transport Sessions, Not Topics</a>.</p>
<p>Even in the most simple case, where a single XSP is created and used for all subscribed transport sessions, there are still events generated by the main context thread which can be called concurrently with XSP callbacks. Reception of MIM or UIM messages, scheduled timers, and some topic resolution-related callbacks all come from the main context thread, and can all be invoked concurrently with XSP callbacks.</p>
<p><b>Threading Example: Message Timeout</b></p>
<p>Consider as an example a common timer use case: message timeout. Application A expects to receive messages for topic "X" every 5 seconds. If 10 seconds pass without a message, the application assumes that the publisher for "X" has exited, so it cleans up internal state and deletes the UM receiver object. Each time a message is received, the current timer is cancelled and re-created for 10 seconds.</p>
<p>Without XSPs, this can be easily coded since message reception and timer expiration events are serialized. The timer callback can clean up and delete the receiver, confident that no receiver events might get delivered while this is in progress.</p>
<p>However, if the transport session carrying topic "X" is assigned to an independent XSP thread, message reception and timer expiration events are no longer serialized. Publisher of "X" might send it's message on-time, but a temporary network outage could delay its delivery, introducing a race condition between message delivery and timer expiration. Consider the case where the timer expiration is a little ahead of the message callback. The timer callback might clean up application state which the message callback will attempt to use. This could lead to unexpected behavior, possibly including segmentation faults.</p>
<p>In this case, proper sequencing of operations is critical. The timer should delete the receiver first. While inside the receiver delete API, the XSP might deliver messages to the application. However, once the receiver delete API returns, it is guaranteed that the XSP is finished making receiver callbacks.</p>
<p>Note that in this example case, if the message receive callback attempts to cancel the timer, the cancel API will return an error. This is because the timer has already expired and the execution of the callback has begun, and is inside the receiver delete API. The message receive callback needs to be able to handle this sequence, presumably by not re-scheduling the timer.</p>
<p><br />
 </p>
<h3><a class="anchor" id="xspusage"></a>
XSP Usage</h3>
<p>This section provides simplified C code fragments that demonstrate some of the XSP-related API calls. For full examples of XSP usage, see <a href="../../example/lbmrcvxsp.c">lbmrcvxsp.c</a> (for C) and <a href="../../java_example/lbmrcvxsp.java">lbmrcvxsp.java</a> (for Java).</p>
<dl class="section note"><dt>Note</dt><dd>Each XSP thread has its own Unicast Listener (request) port. You may need to expand the range <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpportlowcontext">request_tcp_port_low (context)</a> - <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpporthighcontext">request_tcp_port_high (context)</a>.</dd></dl>
<p>The common sequence of operations during application initialization is minimally shown below. In the code fragments below, error detection and handling are omitted for clarity.</p>
<ol>
<li>
<p class="startli">Create a context attribute object and set the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#transportmappingfunctioncontext">transport_mapping_function (context)</a> option to point at the application's XSP mapping callback function using the structure <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a90dde1ea00f12038cff7195c76d47a46">lbm_transport_mapping_func_t</a>.</p>
<pre class="fragment">  lbm_context_attr_t *ctx_attr;
  err = lbm_context_attr_create(&amp;ctx_attr);

  lbm_transport_mapping_func_t mapping_func;
  mapping_func.mapping_func = app_xsp_mapper_callback;
  mapping_func.clientd = NULL;             /* Can include app state pointer. */

  err = lbm_context_attr_setopt(ctx_attr, "transport_mapping_function",
          &amp;mapping_func, sizeof(mapping_func));
</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Create the context.</p>
<pre class="fragment">  err = lbm_context_create(&amp;ctx, ctx_attr, NULL, NULL);
  err = lbm_context_attr_delete(ctx_attr);  /* No longer needed. */
</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Create XSPs using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ae38035c6036a84f07f9ba7cee1747dbf">lbm_xsp_create()</a>. In this example, only a single XSP is created.</p>
<pre class="fragment">  lbm_xsp_t *xsp;  /* app_xsp_mapper_callback() needs this; see below. */
  err = lbm_xsp_create(&amp;xsp, ctx, NULL, NULL);
</pre><p>Note that the application can optionally pass in a context attribute object and an XSP attribute object. The context attribute is because XSP is implemented as a sort of reduced-function sub-context, and so it is possible to modify context options for the XSP. However, this is rarely needed since the default action is for the XSP to inherit all the configuration of the main context.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Create a receiver for topic "X".</p>
<pre class="fragment">  lbm_topic_t *topic;
  err = lbm_rcv_topic_lookup(&amp;topic, ctx, "X", NULL);

  lbm_rcv_t *rcv;
  err = lbm_rcv_create(&amp;rcv, ctx, topic, app_rcv_callback, NULL, NULL);
</pre><p>Event queues may also be used with XSP-assigned transport sessions.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">At this point, when the main context discovers a source for topic "X", it will proceed to join the transport session. It will call the application's app_xsp_mapper_callback() function, which is minimally this:</p>
<pre class="fragment">lbm_xsp_t *app_xsp_mapper_callback(lbm_context_t *ctx,
        lbm_new_transport_info_t *transp_info, void *clientd)
{
  /* Retrieve the XSP object created in step 3. */
  return xsp;
}
</pre><p>This minimal callback simply returns the XSP that was created during initialization (the "clientd" can be helpful for that). By assigning all receiver transport sessions to the same XSP, you have effectively separated message processing from UM housekeeping tasks, like processing of topic resolution and timers. This can greatly reduce latency outliers.</p>
<p class="endli">As described in <a class="el" href="index.html#xsphandlestransportsessionsnottopics">XSP Handles Transport Sessions, Not Topics</a>, some users want to have multiple XSPs and assign the transport sessions to XSPs according to application logic. Note that the passed-in <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac611697e7263b4b5ea5a3b35eb26dc99">lbm_new_transport_info_t</a> structure contains information about the transport session, such as the IP address of the sender. However, this structure does not contain topic information. Applications can use the resolver's source notification callback via the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#resolversourcenotificationfunctioncontext">resolver_source_notification_function (context)</a> attribute option to associate topics with source strings. </p>
</li>
</ol>
<dl class="section note"><dt>Note</dt><dd>Most of the time, the application mapping callback will be invoked each time a transport session is joined. However, there is one exception to this rule. If a context is already joined to a transport session carried on a multicast group and destination port, joining another transport session on the same multicast group and destination port does not invoke the mapping callback again. This is because the same socket is used for all transport sessions that use the same group:port.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="otherxspoperations"></a>
Other XSP Operations</h3>
<p>When an XSP object is created, an XSP attribute object can be supplied to set XSP options. The XSP options are: </p><ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#operationalmodexsp">operational_mode (xsp)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#zerotransportsfunctionxsp">zero_transports_function (xsp)</a> </li>
</ul>
<p>To create and manipulate an XSP attribute object, see: </p><ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a9ab709766b50d510266901f961341a00">lbm_xsp_attr_create()</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ae52cbac6a22b495a3b48a70bf23fc118">lbm_xsp_attr_setopt()</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a62363973a939a8555eac38846492dbb2">lbm_xsp_attr_getopt()</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#adfc416faf8fbc79cfd16a1485341f469">lbm_xsp_attr_delete()</a> </li>
</ul>
<p>To delete an XSP, all receivers associated with transport sessions handled by that XSP must first be deleted. Then the XSP can be deleted using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac61812a1c86eb9d240054f9d3ba32ac5">lbm_xsp_delete()</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="xsplimitations"></a>
XSP Limitations</h3>
<p>There are some restrictions and limitations on the XSP feature.</p>
<ul>
<li>
<p class="startli">The only transport types currently supported are LBT-RM, LBT-RU, and TCP. IPC, SMX, DBL, and BROKER are not supported with XSPs at this time.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Persistent receivers are not currently supported. Support for persistence will be added in a future version.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">The ULB feature is not currently supported.</p>
<p class="endli"></p>
</li>
<li>
The use of XSP is not currently compatible with <a class="el" href="index.html#hotfailoverhf">Hot Failover (HF)</a>. If you desire to use Hot Failover with XSP, contact Support. </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="usinglatejoin"></a>
Using Late Join</h2>
<p>This section introduces the use of Ultra Messaging Late Join in default and specialized configurations. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html">Late Join Options</a> in the <a href="../../../Config/index.html">UM Configuration Guide</a> for more information.</p>
<dl class="section note"><dt>Note</dt><dd>If your application is running within a Ultra Messaging context with configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpbindrequestportcontext">request_tcp_bind_request_port (context)</a> set to zero, then request port binding has been turned off, which also disables the Late Join feature.</dd>
<dd>
With the UMQ product, you cannot use Late Join with Queuing.</dd></dl>
<p>The Late Join feature enables newly created receivers to receive previously transmitted messages. Sources configured for Late Join maintain a retention buffer (not to be confused with a transport retransmission window), which holds transmitted messages for late-joining receivers.</p>
<p>A Late Join operation follows the following sequence:</p>
<ol>
<li>
A new receiver configured for Late Join with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#uselatejoinreceiver">use_late_join (receiver)</a> completes topic resolution. Topic advertisements from the source contain a flag that indicates the source is configured for Late Join with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#latejoinsource">late_join (source)</a>. </li>
<li>
The new receiver sends a Late Join Information Request (LJIR) to request a previously transmitted messages. The receiver configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestoutstandingmaximumreceiver">retransmit_request_outstanding_maximum (receiver)</a>, determines the number of messages the receiver requests. </li>
<li>
The source responds with a Late Join Information (LJI) message containing the sequence numbers for the retained messages that are available for retransmission. </li>
<li>
The source unicasts the messages. </li>
<li>
When <a class="el" href="index.html#configuringlatejoinforlargenumbersofmessages">Configuring Late Join for Large Numbers of Messages</a>, the receiver issues additional requests, and the source retransmits these additional groups of older messages, oldest first. </li>
</ol>
<div class="image">
<img src="LateJoin.png" alt="LateJoin.png"/>
</div>
 <p>The source's retention buffer's is not pre-allocated and occupies an increasing amount of memory as the source sends messages and adds them to the buffer. If a retention buffer grows to a size equal to the value of the source configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a>, the source deletes older messages as it adds new ones. The source configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#retransmitretentionagethresholdsource">retransmit_retention_age_threshold (source)</a>, controls message deletion based on message age.</p>
<p>UM uses control-structure overhead memory on a per-message basis for messages held in the retention buffer, in addition to the retention buffer's memory. Such memory usage can become significantly higher when retained messages are smaller in size, since more of them can then fit in the retention buffer.</p>
<dl class="section note"><dt>Note</dt><dd>If you set the receiver configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a> to 1, the receiver must deliver messages to your application in sequence number order. The receiver holds out-of-order messages in an ordered list cache until messages arrive to fill the sequence number gaps. If an out-of-order message arrives with a sequence number that creates a message gap greater than the value of <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a>, the receiver creates a burst loss event and terminates the Late Join recovery operation. You can increase the value of the proximity option and restart the receiver, but a burst loss is a significant event and you should investigate your network and message system components for failures.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="latejoinwithump"></a>
Late Join With Persistence</h3>
<p>With the UMP/UMQ products, late Join can be implemented in conjunction with the Persistent Store, however in this configuration, it functions somewhat differently from Streaming. After a late-Join-enabled receiver has been created, resolved a topic, and become registered with a store, it may then request older messages. The store unicasts the retransmission messages. If the store does not have these messages, it requests them of the source (assuming option retransmission-request-forwarding is enabled), thus initiating Late Join.</p>
<p><br />
 </p>
<h3><a class="anchor" id="latejoinoptionssummary"></a>
Late Join Options Summary</h3>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#latejoinsource">late_join (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#retransmitretentionagethresholdsource">retransmit_retention_age_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizelimitsource">retransmit_retention_size_limit (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#uselatejoinreceiver">use_late_join (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitinitialsequencenumberrequestreceiver">retransmit_initial_sequence_number_request (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestmessagetimeoutreceiver">retransmit_request_message_timeout (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestintervalreceiver">retransmit_request_interval (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestmaximumreceiver">retransmit_request_maximum (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestoutstandingmaximumreceiver">retransmit_request_outstanding_maximum (receiver)</a> </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="usingdefaultlatejoinoptions"></a>
Using Default Late Join Options</h3>
<p>To implement Late Join with default options, set the Late Join configuration options to activate the feature on both a source and receiver in the following manner.</p>
<ol>
<li>
<p class="startli">Create a configuration file with source and receiver Late Join activation options set to 1. For example, file cfg1.cfg containing the two lines:</p>
<pre class="fragment">source late_join 1
receiver use_late_join 1
</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Run an application that starts a Late-Join-enabled source. For example:</p>
<pre class="fragment">lbmsrc -c cfg1.cfg -P 1000 topicName
</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Wait a few seconds, then run an application that starts a Late-Join-enabled receiver. For example:</p>
<pre class="fragment">lbmrcv -c cfg1.cfg -v topicName
</pre> </li>
</ol>
<p>The output for each should closely resemble the following:</p>
<p><b>LBMSRC</b></p>
<pre class="fragment">$ lbmsrc -c cfg1.cfg -P 1000 topicName
LOG Level 5: NOTICE: Source "topicName" has no retention settings (1 message retained max)
Sending 10000000 messages of size 25 bytes to topic [topicName]
Receiver connect [TCP:10.29.3.77:34200]
</pre><p><b>LBMRCV</b></p>
<pre class="fragment">$ lbmrcv -c cfg1.cfg -v topicName
Immediate messaging target: TCP:10.29.3.77:4391
[topicName][TCP:10.29.3.76:4371][2]-RX-, 25 bytes
1.001 secs. 0.0009988 Kmsgs/sec. 0.1998 Kbps
[topicName][TCP:10.29.3.76:4371][3], 25 bytes
1.002 secs. 0.0009982 Kmsgs/sec. 0.1996 Kbps
[topicName][TCP:10.29.3.76:4371][4], 25 bytes
1.003 secs. 0.0009972 Kmsgs/sec. 0.1994 Kbps
[topicName][TCP:10.29.3.76:4371][5], 25 bytes
1.003 secs. 0.0009972 Kmsgs/sec. 0.1994 Kbps
...
</pre><p>Note that the source only retained 1 Late Join message (due to default retention settings) and that this message appears as a retransmit (-RX-). Also note that it is possible to sometimes receive 2 RX messages in this scenario (see <a class="el" href="index.html#retransmittingonlyrecentmessages">Retransmitting Only Recent Messages</a>.)</p>
<p><br />
 </p>
<h3><a class="anchor" id="specifyingarangeofmessagestoretransmit"></a>
Specifying a Range of Messages to Retransmit</h3>
<p>To receive more than one or two Late Join messages, increase the source's <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a> from its default value of 0. Once the buffer exceeds this threshold, the source allows the next new message entering the retention buffer to bump out the oldest one. Note that this threshold's units are bytes (which includes a small overhead per message).</p>
<p>While the retention threshold endeavors to keep the buffer size close to its value, it does not set hard upper limit for retention buffer size. For this, the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizelimitsource">retransmit_retention_size_limit (source)</a> configuration option (also in bytes) sets this boundary.</p>
<p>Follow the steps below to demonstrate how a source can retain about 50MB of messages, but no more than 60MB:</p>
<ol>
<li>
<p class="startli">Create a second configuration file (cfg2.cfg) with the following options:</p>
<pre class="fragment">source late_join 1
source retransmit_retention_size_threshold 50000000
source retransmit_retention_size_limit 60000000
receiver use_late_join 1
</pre> </li>
<li>
Run lbmsrc -c cfg2.cfg -P 1000 topicName. </li>
<li>
Wait a few seconds and run <code>lbmrcv -c cfg2.cfg -v topicName</code>. The output for each should closely resemble the following: </li>
</ol>
<p><b>LBMSRC</b></p>
<pre class="fragment">$ lbmsrc -c cfg2.cfg -P 1000 topicName
Sending 10000000 messages of size 25 bytes to topic [topicName]
Receiver connect [TCP:10.29.3.76:34444]
</pre><p><b>LBMRCV</b></p>
<pre class="fragment">$ lbmrcv -c cfg2.cfg -v topicName
Immediate messaging target: TCP:10.29.3.76:4391
[topicName][TCP:10.29.3.77:4371][0]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][1]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][2]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][3]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][4]-RX-, 25 bytes
1.002 secs. 0.004991 Kmsgs/sec. 0.9981 Kbps
[topicName][TCP:10.29.3.77:4371][5], 25 bytes
1.002 secs. 0.0009984 Kmsgs/sec. 0.1997 Kbps
[topicName][TCP:10.29.3.77:4371][6], 25 bytes
1.002 secs. 0.0009983 Kmsgs/sec. 0.1997 Kbps
[topicName][TCP:10.29.3.77:4371][7], 25 bytes
...
</pre><p>Note that lbmrcv received live messages with sequence numbers 7, 6, and 5, and RX messages going from 4 all the way back to Sequence Number 0.</p>
<p><br />
 </p>
<h3><a class="anchor" id="retransmittingonlyrecentmessages"></a>
Retransmitting Only Recent Messages</h3>
<p>Thus far we have worked with only source late join settings, but suppose that you want to receive only the last 10 messages. To do this, configure the receiver option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestmaximumreceiver">retransmit_request_maximum (receiver)</a> to set how many messages to request backwards from the latest message.</p>
<p>Follow the steps below to set this option to 10.</p>
<ol>
<li>
<p class="startli">Add the following line to cfg2.cfg and rename it cfg3.cfg:</p>
<pre class="fragment">receiver retransmitrequestmaximumreceiver 10
</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Run:</p>
<pre class="fragment">lbmsrc -c cfg3.cfg -P 1000 topicName
</pre><p class="endli"></p>
</li>
<li>
Wait a few seconds and run <code>lbmrcv -c cfg3.cfg -v topicName</code>. The output for each should closely resemble the following. </li>
</ol>
<p><b>LBMSRC</b></p>
<pre class="fragment">$ lbmsrc -c cfg3.cfg -P 1000 topicName
Sending 10000000 messages of size 25 bytes to topic [topicName]
Receiver connect [TCP:10.29.3.76:34448]
</pre><p><b>LBMRCV</b></p>
<pre class="fragment">$ lbmrcv -c cfg3.cfg -v topicName
Immediate messaging target: TCP:10.29.3.76:4391
[topicName][TCP:10.29.3.77:4371][13]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][14]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][15]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][16]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][17]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][18]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][19]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][20]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][21]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][22]-RX-, 25 bytes
[topicName][TCP:10.29.3.77:4371][23]-RX-, 25 bytes
1.002 secs. 0.01097 Kmsgs/sec. 2.195 Kbps
[topicName][TCP:10.29.3.77:4371][24], 25 bytes
1.002 secs. 0.0009984 Kmsgs/sec. 0.1997 Kbps
[topicName][TCP:10.29.3.77:4371][25], 25 bytes
1.002 secs. 0.0009984 Kmsgs/sec. 0.1997 Kbps
[topicName][TCP:10.29.3.77:4371][26], 25 bytes
...
</pre><p>Note that 11, not 10, retransmits were actually received. This can happen because network and timing circumstances may have one RX already in transit while the specific RX amount is being processed. (Hence, it is not possible to guarantee one and only one RX message for every possible Late Join recovery.)</p>
<p><br />
 </p>
<h3><a class="anchor" id="configuringlatejoinforlargenumbersofmessages"></a>
Configuring Late Join for Large Numbers of Messages</h3>
<p>Suppose you have a receiver that comes up at midday and must gracefully catch up on the large number of messages it has missed. The following discussion explains the relevant Late Join options and how to use them.</p>
<p><b>Option:</b> <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestoutstandingmaximumreceiver">retransmit_request_outstanding_maximum (receiver)</a></p>
<p>When a receiver comes up and begins requesting Late Join messages, it does not simply request messages starting at Sequence Number 0 through 1000000. Rather, it requests the messages a little at a time, depending upon how option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitrequestoutstandingmaximumreceiver">retransmit_request_outstanding_maximum (receiver)</a> is set. For example, when set to the default of 200, the receiver sends requests the first 200 messages (Sequence Number 0 - 199). Upon receiving Sequence Number 0, it then requests the next message (200), and so on, limiting the number of outstanding unfulfilled requests to 200.</p>
<p>Note that in some environments, the default of 200 messages may be too high and overwhelm receivers with RXs, which can cause loss in a live LBT-RM stream. However, in other situations higher values can increase the rate of RXs received.</p>
<p><b>Option:</b> <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a></p>
<p>When sequence number delivery order is used, long recoveries of active sources can create receiver memory cache problems due to the processing of both new and retransmitted messages. This option provides a method to control caching and cache size during recovery.</p>
<p>It does this by comparing the option value (default 2147483647) to the difference between the newest (live) received sequence number and the latest received RX sequence number. If the difference is less than the option's value, the receiver caches incoming live new messages. Otherwise, new messages are dropped and not cached (with the assumption that they can be requested later as retransmissions).</p>
<p>For example, as shown in the diagram below, a receiver may be receiving both live streaming messages (latest, #200) and catch-up retransmissions (latest, #100). The difference here is 100. If <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a> is 75, the receiver caches the live messages and will deliver them when it is all caught up with the retransmissions. However, if this option is 150, streamed messages are dropped and later picked up again as a retransmission.</p>
<div class="image">
<img src="proximity_option.png" alt="proximity_option.png"/>
</div>
 <p>The default value of this option is high enough to still encourage caching most of the time, and should be optimal for most receivers.</p>
<p>If your source streams faster than it retransmits, caching is beneficial, as it ensures new data are received only once, thus reducing recovery time. If the source retransmits faster than it streams, which is the optimal condition, you can lower the value of this option to use less memory during recovery, with little performance impact.</p>
<p><br />
 </p>
<h2><a class="anchor" id="offtransportrecoveryotr"></a>
Off-Transport Recovery (OTR)</h2>
<p>Off-Transport Recovery (OTR) is a lost-message-recovery feature that provides a level of hedging against the possibility of brief and incidental unrecoverable loss at the transport level or from a UM Router. This section describes the OTR feature.</p>
<dl class="section note"><dt>Note</dt><dd>With the UMQ product, you cannot use OTR with Brokered Queuing.</dd></dl>
<p>When a transport cannot recover lost messages, OTR engages and looks to the source for message recovery. It does this by accessing the source's retention buffer (used also by the Late Join feature) to re-request messages that no longer exist in a transport's transmission window, or other places such as a Persistent Store or redundant source.</p>
<p>OTR functions in a manner very similar to that of Late Join, but differs mainly in that it activates in message loss situations rather than following the creation of a receiver, and shares only the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#latejoinsource">late_join (source)</a> option setting.</p>
<p>Upon detecting loss, a receiver initiates OTR by sending repeated, spaced, OTR requests to the source, until it recovers lost messages or a timeout period elapses.</p>
<p>OTR operates independently from transport-level recovery mechanisms such as NAKs for LBT-RU or LBT-RM. When you enable OTR for a receiver with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#useotrreceiver">use_otr (receiver)</a>, the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestinitialdelayreceiver">otr_request_initial_delay (receiver)</a> period starts as soon as the delivery controller detects a sequence gap. If the gap is not resolved by the end of the delay interval, OTR recovery initiates. OTR recovery can occur before, during or after transport-level recovery attempts.</p>
<p>When a receiver initiates OTR, the intervals between OTR requests increases twofold after each request, until the maximum interval is reached (assuming the receiver is still waiting to receive the retransmission). You use configuration options <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestminimumintervalreceiver">otr_request_minimum_interval (receiver)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestmaximumintervalreceiver">otr_request_maximum_interval (receiver)</a> to set the initial (minimum) and maximum intervals, respectively.</p>
<p>The source retransmits lost messages to the recovered receiver via unicast.</p>
<p><br />
 </p>
<h3><a class="anchor" id="otrwithsequencenumberordereddelivery"></a>
OTR with Sequence Number Ordered Delivery</h3>
<p>When sequence number delivery order is used and a gap of missing messages occurs, a receiver buffers the new incoming messages while it attempts to recover the earlier missing ones. Long recoveries of actively streaming sources can cause excessive receiver cache memory growth due to the processing of both new and retransmitted messages. You can control caching and cache size during recovery with options <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrmessagecachingthresholdreceiver">otr_message_caching_threshold (receiver)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a>.</p>
<p>The option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrmessagecachingthresholdreceiver">otr_message_caching_threshold (receiver)</a> sets the maximum number of messages a receiver can buffer. When the number of cached messages hits this threshold, new streamed messages are dropped and not cached, with the assumption that they can be requested later as retransmissions.</p>
<p>The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a>, which is also used by Late Join (see <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a>), turns off this caching if there are too many messages to buffer between the last delivered message and the currently streaming messages.</p>
<p>Both of these option thresholds must be satisfied before caching resumes.</p>
<p><br />
 </p>
<h3><a class="anchor" id="otrwithump"></a>
OTR With Persistence</h3>
<p>With the UMP/UMQ products, you can implement OTR in conjunction with the Persistent Store, however in this configuration, it functions somewhat differently from Streaming. If an OTR-enabled receiver registered with a store detects a sequence gap in the live stream and that gap is not resolved by other means within the next <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestinitialdelayreceiver">otr_request_initial_delay (receiver)</a> period, the receiver requests those messages from the store(s). If the store does not have some of the requested messages, the receiver requests them from the source. Regardless of whether the messages are recovered from a store or from the source, OTR delivers all recovered messages with the LBM_MSG_OTR flag, unlike Late Join, which uses the LBM_MSG_RETRANSMIT flag.</p>
<p><br />
 </p>
<h3><a class="anchor" id="otroptionssummary"></a>
OTR Options Summary</h3>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#latejoinsource">late_join (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#retransmitretentionagethresholdsource">retransmit_retention_age_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizelimitsource">retransmit_retention_size_limit (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#useotrreceiver">use_otr (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestmessagetimeoutreceiver">otr_request_message_timeout (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestinitialdelayreceiver">otr_request_initial_delay (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestlogalertcooldownreceiver">otr_request_log_alert_cooldown (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestmaximumintervalreceiver">otr_request_maximum_interval (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestminimumintervalreceiver">otr_request_minimum_interval (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrrequestoutstandingmaximumreceiver">otr_request_outstanding_maximum (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpofftransportrecovery.html#otrmessagecachingthresholdreceiver">otr_message_caching_threshold (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a> </li>
</ul>
<dl class="section note"><dt>Note</dt><dd>With <a class="el" href="index.html#smartsources">Smart Sources</a>, the following configuration options have limited or no support: <ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grplatejoin.html#retransmitretentionsizelimitsource">retransmit_retention_size_limit (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeprecated.html#retransmitretentionagethresholdsource">retransmit_retention_age_threshold (source)</a> </li>
</ul>
</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="smartsources"></a>
Smart Sources</h2>
<p>The normal <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a> function (and its Java and .NET equivalents) are very flexible and support the full range of UM's rich feature set. To provide this level of capability, it is necessary to make use of dynamic (malloc/free) memory, and critical section locking (mutex) in the send path. While modern memory managers and thread locks are very efficient, they do introduce some degree of variability of execution time, leading to latency outliers potentially in the millisecond range.</p>
<p>For applications which require even higher speed and very consistent timing, and are able to run within certain constraints, UM has an alternate send feature called Smart Source. This is a highly-optimized send path with no dynamic memory operations or locking; all allocations are done at source creation time, and lockless algorithms are used throughout. To achieve these improvements, this software version's Smart Source imposes a number of restrictions (see <a class="el" href="index.html#smartsourcerestrictions">Smart Sources Restrictions</a>).</p>
<dl class="section note"><dt>Note</dt><dd>the Smart Source feature is <em>not</em> the same thing as the <a class="el" href="index.html#zerocopysendapi">Zero-Copy Send API</a> feature; see <a class="el" href="index.html#comparisonofzerocopyandsmartsources">Comparison of Zero Copy and Smart Sources</a>.</dd></dl>
<p>To use Smart Sources, a user application typically performs the following steps:</p>
<ol>
<li>
Create a context with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8058947690bd0995bc2c59d4a61b462f">lbm_context_create()</a>, as normal. </li>
<li>
Create the topic object and the Smart Source with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a1ba60407fa2bde0997aab6d5a5d2da1a">lbm_src_topic_alloc()</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a9a8d169a8c2a90b8442d4eb3e3711c9c">lbm_ssrc_create()</a>, respectively. Use <a class="el" href="index.html#smartsourceconfiguration">Smart Sources Configuration</a> to pre-allocate the desired number of buffers. </li>
<li>
Get the desired number of messages buffers with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a98c5450e9fb93f30bd80fa33a2380dfc">lbm_ssrc_buff_get()</a> and initialize them if desired. The application typically constructs outgoing messages directly in these buffers for transmission. </li>
<li>
Send messages with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2f50f56536778332e9f5712b06546425">lbm_ssrc_send_ex()</a>. The buffers gotten in the previous step must be used. </li>
<li>
While most applications manage the message buffers internally, it is also possible to give the buffers back to UM with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab57120414bf92bd2f44de7aea97e3f1b">lbm_ssrc_buff_put()</a>, and then getting them again for subsequent sends. Getting and putting messages buffers can simplify application design at the expense of extra overhead. </li>
<li>
To clean up, delete the Smart Source with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a9cd9dfee7a9c268059084a3c327f65f9">lbm_ssrc_delete()</a>. It is not necessary to "put" the message buffers back to UM; they will be freed automatically when the Smart Source is deleted. </li>
</ol>
<p>For details, see the example applications <a href="../../example/lbmssrc.c">lbmssrc.c</a> or <a href="../../java_example/lbmssrc.java">lbmssrc.java</a>.</p>
<dl class="section warning"><dt>Warning</dt><dd>To avoid the overhead of locking, the Smart Source API functions are not thread-safe. Applications must be written to avoid concurrent calls. In particular, the application is restricted to sending messages on a given transport session with one thread. If <a class="el" href="index.html#smartsourcedefensivechecks">Smart Source Defensive Checks</a> are enabled, the first call to send a message on a newly-created transport session captures the ID of the calling thread. Subsequently, only that thread is allowed to call send for Smart Sources on that transport session. For applications which have multiple sending threads, Smart Source topics must be mapped to transport sessions carefully such that all of the topics on a given transport session are managed by the same sending thread.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>There are no special requirements on the receive side when using Smart Sources. Normal receiving code is used.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="smartsourcesandmemorymanagement"></a>
Smart Sources and Memory Management</h3>
<p>As of UM 6.11, there are new C APIs that give the application greater control over the allocation of memory when Smart Sources are being created. Since creation of a Smart Source pre-allocates buffers used for application message data as well as internal retransmission buffers, an application can override the stock malloc/free to ensure, for example, that memory is local to the CPU core that will be sending messages.</p>
<p>When the application is ready to create the Smart Source, it should set up the configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#memmgtcallbackssource">mem_mgt_callbacks (source)</a>, which uses the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aae7c35eda2692944970e73d93217239b">lbm_mem_mgt_callbacks_t</a> structure to specify application callback functions.</p>
<p><br />
 </p>
<h3><a class="anchor" id="smartsourceconfiguration"></a>
Smart Sources Configuration</h3>
<p>The following configuration options are used to control the creation and operation of Smart Sources:</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcmaxmessagelengthsource">smart_src_max_message_length (source)</a> - should be set to the maximum expected size for messages sent to on the source. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcuserbuffercountsource">smart_src_user_buffer_count (source)</a> - number of buffers to be pre-created at Smart Source create time. Deleting a Smart Source also frees these buffers, so applications must not access these buffers after their corresponding Smart Source is deleted. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcretentionbuffercountsource">smart_src_retention_buffer_count (source)</a> - enables <a class="el" href="index.html#latejoin">Late Join</a> and <a class="el" href="index.html#offtransportrecoveryotr">Off-Transport Recovery (OTR)</a> functionality. Takes the place of the normal late join / OTR options "retransmit_retention_*". (On the receive side, the normal late join options apply.) </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#transportlbtrmsmartsrctransmissionwindowbuffercountsource">transport_lbtrm_smart_src_transmission_window_buffer_count (source)</a> - size of the LBT-RM transmission window. Takes the place of the normal window options "transport_lbtrm_transmission_window_*". </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#transportlbtrusmartsrctransmissionwindowbuffercountsource">transport_lbtru_smart_src_transmission_window_buffer_count (source)</a> - size of the LBT-RU transmission window. Takes the place of the normal window options "transport_lbtru_transmission_window_*". </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcenablespectrumchannelsource">smart_src_enable_spectrum_channel (source)</a> - should be set if <a class="el" href="index.html#spectrum">Spectrum</a> channels will be used. <br />
 See <a class="el" href="index.html#smartsourcesandspectrum">Smart Sources and Spectrum</a>. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcmessagepropertyintcountsource">smart_src_message_property_int_count (source)</a> - should be set if <a class="el" href="index.html#messageproperties">Message Properties</a> will be used. <br />
 See <a class="el" href="index.html#smartsourcesandmessageproperties">Smart Sources and Message Properties</a>. </li>
</ul>
<p>The option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcmaxmessagelengthsource">smart_src_max_message_length (source)</a> is used to size the window transmission buffers. This means that the first Smart Source created on the session defines the maximum possible size of user messages for all Smart Sources on the transport session. It is not legal to create a subsequent Smart Source on the same transport session that has a larger <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcmaxmessagelengthsource">smart_src_max_message_length (source)</a>, although smaller values are permissible.</p>
<p><br />
 </p>
<h3><a class="anchor" id="smartsourcedefensivechecks"></a>
Smart Source Defensive Checks</h3>
<p>Ultra Messaging generally includes defensive checks in API functions to verify validity of input parameters. In support of faster operation, deep defensive checks for Smart Sources are optional, and are disabled by default. Users should enable them during application development, and can leave them disabled for production.</p>
<p>To enable deep Smart Source defensive checks, set the environment variable <b>LBM_SMART_SOURCE_CHECK</b> to the numeric sum of desired values. Hexadecimal values may be supplied with the "0x" prefix. Each value enables a class of defensive checking:</p>
<center> <table class="doxtable">
<tr>
<th>Numeric Value</th><th>Deep Check </th></tr>
<tr>
<td><b>1</b></td><td>Send argument checking </td></tr>
<tr>
<td><b>2</b></td><td>Thread checking </td></tr>
<tr>
<td><b>4</b></td><td>User buffer pointer checking </td></tr>
<tr>
<td><b>8</b></td><td>User buffer structure checking </td></tr>
<tr>
<td><b>16, 0x10</b></td><td>user message length checking </td></tr>
<tr>
<td><b>32, 0x20</b></td><td>application header checking, including <a class="el" href="index.html#spectrum">Spectrum</a> and <a class="el" href="index.html#messageproperties">Message Properties</a>. </td></tr>
</table>
</center><p>To enable all checking, set the environment variable <b>LBM_SMART_SOURCE_CHECK</b> to "0xffffffff".</p>
<p><br />
 </p>
<h3><a class="anchor" id="smartsourcerestrictions"></a>
Smart Sources Restrictions</h3>
<dl class="section user"><dt><b>Linux</b> <b>and</b> <b>Windows</b> <b>64-bit</b> </dt><dd>Smart Sources is only supported on the 64-bit Linux and 64-bit Windows platforms, C and Java APIs.</dd></dl>
<dl class="section user"><dt><b>LBT-RM</b> <b>And</b> <b>LBT-RU</b> <b>Sources</b> </dt><dd>Smart Sources can only be created with the LBT-RM and LBT-RU transport types. Non-source-based sends are not supported (<a class="el" href="index.html#multicastimmediatemessaging">MIM</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a497d77b133cea1547c3346fcba99872a">UIM</a>, <a class="el" href="index.html#requestresponse">responses</a>).</dd></dl>
<dl class="section user"><dt><b>Persistence</b> </dt><dd>As of UM 6.11, Smart Sources support Persistence, but with some restrictions. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/ume.tag:../../UME/" href="../../UME/enablingpersistence.html#smartsourcesandpersistence">Smart Sources and Persistence</a> for details.</dd></dl>
<dl class="section user"><dt><b>Spectrum</b> </dt><dd>As of UM 6.11, Smart Sources support <a class="el" href="index.html#spectrum">Spectrum</a>, but with some API changes. See <a class="el" href="index.html#smartsourcesandspectrum">Smart Sources and Spectrum</a> for details.</dd></dl>
<dl class="section user"><dt><b>Single-threaded</b> </dt><dd>It is the application's responsibility to serialize calls to Smart Source APIs for a given transport session. Concurrent sends to different transport sessions are permitted.</dd></dl>
<dl class="section user"><dt><b>Single-datagram</b> </dt><dd>Application messages are limited in size to a single datagram. That size is configurable by <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmdatagrammaxsizecontext">transport_lbtrm_datagram_max_size (context)</a>, which defaults to 8K. (Applications must define the maximum size of messages they intend to send; see the configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcmaxmessagelengthsource">smart_src_max_message_length (source)</a>. This setting must be less than or equal to the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmdatagrammaxsizecontext">transport_lbtrm_datagram_max_size (context)</a> minus 44 bytes of overhead.)</dd></dl>
<dl class="section user"><dt><b>No</b> <b>Application</b> <b>Headers</b> </dt><dd>Application messages may not include <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a40a3fe706dc6cf4a6bd23ebe721ce636">application headers</a>.</dd></dl>
<dl class="section user"><dt><b>Limited</b> <b>Message</b> <b>Properties</b> </dt><dd>Message Properties may be included, but their use has restrictions. See <a class="el" href="index.html#smartsourcemessagepropertiesusage">Smart Source Message Properties Usage</a>.</dd></dl>
<dl class="section user"><dt><b>Queuing</b> </dt><dd>Queuing is not currently supported, although support for ULB is a possibility in the future.</dd></dl>
<dl class="section user"><dt><b>Request</b> </dt><dd>Sending UM <a class="el" href="index.html#requestresponse">Requests</a> are not currently supported.</dd></dl>
<dl class="section user"><dt><b>Data</b> <b>Rate</b> <b>Limit</b> </dt><dd>Smart Source data messages are not <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmdataratelimitcontext">rate limited</a>, although retransmissions are <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmretransmitratelimitcontext">rate limited</a>. Care must be taken in designing and provisioning systems to prevent overloading network and host equipment, and overrunning receivers.</dd></dl>
<dl class="section user"><dt><b>Hot</b> <b>Failover</b> </dt><dd>The <a class="el" href="index.html#hotfailoverhf">Hot Failover</a> feature is not supported by Smart Sources.</dd></dl>
<dl class="section user"><dt><b>Batching</b> </dt><dd>Neither <a class="el" href="index.html#implicitbatching">Implicit Batching</a> nor <a class="el" href="index.html#explicitbatching">Explicit Batching</a> are supported by Smart Sources.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>It is not permitted to mix Smart Source API calls with standard source API calls for a given transport session.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="zerocopysendapi"></a>
Zero-Copy Send API</h2>
<p>This section introduces the use of the zero-copy send API for LBT-RM.</p>
<dl class="section note"><dt>Note</dt><dd>the Zero-Copy Send API feature is <em>not</em> the same thing as the <a class="el" href="index.html#smartsources">Smart Sources</a> feature; see <a class="el" href="index.html#comparisonofzerocopyandsmartsources">Comparison of Zero Copy and Smart Sources</a>.</dd></dl>
<p>The zero-copy send API modifies the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a> function for sending messages such that the UM library does not copy the user's message data before handing the datagram to the socket layer. These changes reduce CPU overhead and provide a minor reduction in latency. The effects are more pronounced for larger user messages, within the restrictions outlined below.</p>
<p>Application code using the zero-copy send API must call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#adf24bf7c4b07549d6a2f89d56e6c913a">lbm_src_alloc_msg_buff()</a> to request a message buffer into which it will build its outgoing message. That function returns a message buffer pointer and also a separate buffer handle. When the application is ready to send the message, it must call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a>, passing the buffer handle as the message (not the message buffer) and specify the LBM_MSG_BUFF_ALLOC send flag.</p>
<p>Once the message is sent, UM will process the buffer asynchronously. Therefore, the application must not make any further reference to either the buffer or the handle.</p>
<p><br />
 </p>
<h3><a class="anchor" id="zerocopysendcompatibility"></a>
Zero-Copy Send Compatibility</h3>
<p>The zero-copy send API is compatible with the following UM features:</p>
<ul>
<li>
C language, Streaming, source-based publishing applications using LBT-RM. </li>
<li>
Messages sent with the zero-copy API can be received by any UM product or daemon. No special restrictions apply to receivers of messages sent with the zero-copy send API. </li>
<li>
Compatible with implicit batching and message flushing. </li>
<li>
Compatible with non-blocking sends and wakeup source event handling. </li>
<li>
Compatible with hardware timestamps (see section <a class="el" href="index.html#highresolutiontimestamps">High-resolution Timestamps</a> ). </li>
<li>
Compatible with UD Acceleration. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="zerocopyrestrictions"></a>
Zero-Copy Restrictions</h3>
<p>Due to the specialized nature of this feature, there are several restrictions in its use:</p>
<ol>
<li>
<b>Languages</b>: Java and .NET are not supported at this time. </li>
<li>
<b>Transport</b>: Sourced-based LBT-RM (multicast) only. Not supported for immediate messages or non-LBT-RM transport types. Note that an application that uses zero-copy sends for certain sources may also have other sources configured for other transport types. </li>
<li>
<b>Application only</b>: UM daemons (e.g. UM Router, Stored, etc.) cannot be configured to use the zero-copy API. </li>
<li>
<b>Streaming only</b>: Persistence and queuing not supported. Note that an application that uses zero-copy sends for certain sources may also have other sources mapped to Persistence and/or queuing. </li>
<li>
<b><a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a> only</b>: send APIs not supported: <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#af28189e64ef0ee10d3444e418443aaa9">lbm_src_sendv()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a091b5806bf18d10ebd0d9117e0c70229">lbm_src_send_ex()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a4d883eaaa22baf81abf21d495f471c8b">lbm_src_sendv_ex()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aeff48e558306b4bd869af2d99dcf5f4c">lbm_hf_src_send()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a713c05423f7bf1767a29727c07aa4447">lbm_hf_src_sendv()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac515c1425d9b3f04f1e2cea5d66d3005">lbm_hf_src_send_ex()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#acb6f42a8811cb998b4b19748b190f39b">lbm_hf_src_sendv_ex()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ad4d06f66b8404684e191ca178e0cc09b">lbm_send_request()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aabcfb44e7f5188a47d8d56540e783fa7">lbm_send_request_ex()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a0bbc01b600ccc2ae874474e35955eb85">lbm_send_response()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a24e5bff3a70e571bb12024af67b47cbb">lbm_multicast_immediate_message()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a54f3933e4dd154a9c7bb72598d0d9ef1">lbm_multicast_immediate_request()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a497d77b133cea1547c3346fcba99872a">lbm_unicast_immediate_message()</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ae011c7a66e1db1f012d7f9633dbd321d">lbm_unicast_immediate_request()</a>. Applications may still use these APIs, but not with the zero-copy send feature. </li>
<li>
<b>Send order</b>: It is recommended that zero-copy buffers be sent in the same order that they are allocated. A future version may require this. </li>
<li>
<b>Late join</b>: not supported. Note that an application that uses zero-copy sends on certain sources may also use late join on other sources. </li>
<li>
<b>Request/response</b>: not supported. </li>
<li>
<b>Metadata</b>: message properties and application headers are not supported. Note that an application that uses zero-copy sends for messages without metadata may also send messages with metadata using other send APIs, even to the same source. </li>
<li>
<b>Hot failover</b>: not supported. Note that an application that uses zero-copy sends for certain sources may use hot failover for other sources. </li>
<li>
<b>Explicit batching</b>: not supported. Note that implicit batching is supported. Also note that an application that uses zero-copy sends for certain sources may use explicit batching for other sources. </li>
<li>
<b>UM Fragmentation</b>: Not supported. Messages sent zero-copy must fit within a single datagram, as defined by the LBT-RM maximum datagram size. No special restrictions apply to IP fragmentation. Note that an application that uses zero-copy sends for single-datagram messages may also send multi-datagram messages using other send APIs, even to the same source. </li>
</ol>
<p><br />
 </p>
<h2><a class="anchor" id="comparisonofzerocopyandsmartsources"></a>
Comparison of Zero Copy and Smart Sources</h2>
<p>There are two UM features that are intended to reduce latency and jitter when sending messages: </p><ul>
<li>
<a class="el" href="index.html#smartsources">Smart Sources</a> </li>
<li>
<a class="el" href="index.html#zerocopysendapi">Zero-Copy Send API</a> </li>
</ul>
<p>These two features use different approaches to latency and jitter reduction, and are incompatible with each other. There are trade offs explained below, and customers seeking latency and/or jitter reduction will sometimes need to try both and empirically measure which is better for their use case.</p>
<p>The zero-copy send API removes a copy of the user's data buffer, as compared to a normal send. For small messages of a few hundred bytes, a malloc and a data copy represent a very small amount of time, so unless your messages are large, the absolute latency reduction is minimal.</p>
<p>The Smart Source has the advantage of eliminating all mallocs and frees from the send path. In addition, all thread locking is eliminated. This essentially removes all sources of jitter from the UM send path. However, because of the approach taken, sending to a Smart Source is more restrictive than sending with the zero-copy API.</p>
<p>In general, Informatica recommends Smart Sources to achieve the maximum reduction in jitter. For example, the zero-copy send API supports the use of batching to combine multiple messages into a single network datagram. Batching can be essential to achieve high throughputs. Some application designers may determine that the throughput advantages of zero-copy with batching outweigh the jitter advantages of Smart Sources.</p>
<p>See the sections <a class="el" href="index.html#zerocopysendapi">Zero-Copy Send API</a> and <a class="el" href="index.html#smartsources">Smart Sources</a> for details of their restrictions.</p>
<p><br />
 </p>
<h2><a class="anchor" id="encryptedtcp"></a>
Encrypted TCP</h2>
<p>This section introduces the use of Transport Layer Security (TLS), sometimes known by its older designation Secure Sockets Layer (SSL).</p>
<p>The goal of the Ultra Messaging (UM) TLS feature is to provide encrypted transport of application data. TLS supports authentication (through certificates), data confidentiality (through encryption), and data integrity (ensuring data are not changed, removed, or added-to). UM can be configured to apply TLS security measures to all Streaming and/or Persisted TCP communication, including UM Router peer links. Non-TCP communication is not encrypted (e.g. topic resolution).</p>
<p>TLS is a family of standard protocols and algorithms for securing TCP communication between a client and a server. It is sometimes referred as "SSL", which technically is the name of an older (less secure) version of the protocol. Over the years, security researchers (and hackers) have discovered flaws in SSL/TLS. However, the vast majority of the widely publicized security vulnerabilities have been flaws in the implementations of TLS, not in the recent TLS protocols or algorithms themselves. As of the release of UM 6.9, there are no known security weaknesses in TLS version 1.2, the version used by UM.</p>
<p>TLS is generally implemented by several different software packages. UM makes use of OpenSSL, a widely deployed and actively maintained open-source project.</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsauthentication"></a>
TLS Authentication</h3>
<p>TLS authentication uses X.509 digital certificates. Certificate creation and management is the responsibility of the user. Ultra Messaging's usage of OpenSSL expects PEM encoded certificates. There are a variety of generally available tools for converting certificates between different encodings. Since user infrastructures vary widely, the UM package does not include tools for creation, formatting, or management of certificates.</p>
<p>Although UM is designed as a peer-to-peer messaging system, TLS has the concept of client and server. The client initiates the TCP connection and the server accepts it. In the case of a TCP source, the receiver initiates and is therefore the client, with the source (sender of data) being the server. However, with unicast immediate messages, the sender of data is the client, and the recipient is the server. Due to the fact that unicast immediate messages are used by UM for internal control and coordination, it is typically not possible to constrain a given application to only operate as a pure client or pure server. For this reason, UM requires all applications participating in encryption to have a certificate. Server-only authentication (i.e. anonymous client, as is used by web browsers) is not supported. It is permissible for groups of processes, or even all processes, to share the same certificate.</p>
<p>A detailed discussion of certificate usage is beyond the scope of the Ultra Messaging documentation.</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsbackwardscompatibility"></a>
TLS Backwards Compatibility</h3>
<p>The TLS protocol was designed to allow for a high degree of backwards compatibility. During the connection establishment phase, the client and server perform a negotiation handshake in which they identify the highest common versions of various security options. For example, an old web browser might pre-date the introduction of TLS and only support the older SSL protocol. OpenSSL is often configured to allow clients and servers to "negotiate down" to those older, less-secure protocols or algorithms.</p>
<p>Ultra Messaging has the advantage of not needing to communicate with old versions of SSL or TLS. UM's default configuration directs OpenSSL to require both the client and the server to use protocols and algorithms which were highly regarded, as of UM's release date. If vulnerabilities are discovered in the future, the user can override UM's defaults and chose other protocols or algorithms.</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsefficiency"></a>
TLS Efficiency</h3>
<p>When a TLS connection is initiated, a handshake takes place prior to application data encryption. Once the handshake is completed, the CPU effort required to encrypt and decrypt application data is minimal. However, the handshake phase involves the use of much less efficient algorithms.</p>
<p>There are two factors under the user's control, which greatly affect the handshake efficiency: the choice of cipher suite and the key length. We have seen an RSA key of 8192 bits take 4 seconds of CPU time on a 1.3GHz SparcV9 processor just to complete the handshake for a single TLS connection.</p>
<p>Users should make their choices with an understanding of the threat profiles they are protecting against. For example, it is estimated that a 1024-bit RSA key can be broken in about a year by brute force using specialized hardware (see <a href="http://www.tau.ac.il/~tromer/papers/cbtwirl.pdf">http://www.tau.ac.il/~tromer/papers/cbtwirl.pdf</a>). This may be beyond the means of the average hacker, but well within the means of a large government. RSA keys of 2048 bits are generally considered secure for the foreseeable future.</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsconfiguration"></a>
TLS Configuration</h3>
<p>TLS is enabled on a context basis. When enabled, all Streaming and Persistence related TCP-based communication into or out of the context is encrypted by TLS. A context with TLS enabled will not accept source creation with transports other than TCP.</p>
<p>Subscribers will only successfully receive data if the receiver's context and the source's context share the same encryption settings. A receiver created in an encrypted enabled context will ignore topic resolution source advertisements for non-encrypted sources, and will therefore not subscribe. Similarly, a receiver created in a non-encrypted context will ignore topic resolution source advertisements for encrypted sources. Topic resolution queries are also ignored by mis-matched contexts. No warning will be logged when these topic resolution datagrams are ignored, but each time this happens, the context-level statistic tr_dgrams_dropped_type is incremented.</p>
<p>TLS is applied to unicast immediate messages as well, as invoked either directly by the user, or internally by functions like late join, request/response, and Persistence-related communication between sources, receivers, and stores.</p>
<p>Brokered Queuing using AMQP does not use the UM TLS feature. A UM brokered context does not allow TLS to be enabled.</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsoptionssummary"></a>
TLS Options Summary</h3>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#usetlscontext">use_tls (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlsciphersuitescontext">tls_cipher_suites (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlscertificatecontext">tls_certificate (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlscertificatekeycontext">tls_certificate_key (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlscertificatekeypasswordcontext">tls_certificate_key_password (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlstrustedcertificatescontext">tls_trusted_certificates (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlscompressionnegotiationtimeoutcontext">tls_compression_negotiation_timeout (context)</a> </li>
</ul>
<p>The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlsciphersuitescontext">tls_cipher_suites (context)</a> configuration option defines the list of one or more (comma separated) cipher suites that are acceptable to this context. If more than one is supplied, they should be in descending order of preference. When a remote context negotiates encrypted TCP, the two sides must find a cipher suite in common, otherwise the connection will be canceled.</p>
<p>OpenSSL uses the cipher suite to define the algorithms and key lengths for encrypting the data stream. The choice of cipher suite is critical for ensuring the security of the connection. To achieve a high degree of backwards compatibility, OpenSSL supports old cipher suites which are no longer considered secure. The user is advised to use UM's default suite.</p>
<p>OpenSSL follows its own naming convention for cipher suites. See <a href="https://www.openssl.org/docs/manmaster/apps/ciphers.html#TLS-v1.2-cipher-suites">https://www.openssl.org/docs/manmaster/apps/ciphers.html#TLS-v1.2-cipher-suites</a> for a list of valid suite names (the ones with dashes) and the equivalent IANA names (with underscores). The UM configuration should use the OpenSSL-style names (with dashes).</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsandpersistence"></a>
TLS and Persistence</h3>
<p>TLS is designed to encrypt a TCP connection, and works with TCP-based persisted data transport sessions and control traffic. However, TLS is not intended to encrypt data at rest. When a Persistent Store is used with the UM TLS feature, the user messages are written to disk in plaintext form, not encrypted.</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsandqueuing"></a>
TLS and Queuing</h3>
<p>The UM TLS feature does not apply to the AMQP connection to the brokered queue. UM does not currently support security on the AMQP connection.</p>
<p>However, the ULB form of queuing does not use a broker. For ULB sources that are configured for TCP, the UM TLS feature will encrypt the application data.</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsandthedynamicroutingoptiondro"></a>
TLS and the Dynamic Routing Option (DRO)</h3>
<p>When a UM Router is used to route messages across topic resolution domains (TRDs), be aware that the TLS session is terminated at the UM Router's proxy receiver/source. Because each endpoint portal on a UM Router is implemented with its own context, care must be taken to ensure end-to-end security. It is possible to have a TLS source publishing in one TRD, received by a UM Router (via an endpoint portal also configured for TLS), and re-published to a different TRD via an endpoint portal configured with a non-encrypted context. This would allow a non-encrypted receiver to access messages that the source intended to be encrypted. As a message is forwarded through a UM Router network, it does not propagate the security settings of the originator, so each portal needs to be appropriately encrypted. The user is strongly encouraged to configure ALL portals on an interconnected network of UM Routers with the same encryption settings.</p>
<p>The encryption feature is extended to UM Router peer links, however peer links are not context-based and are not configured the same way. The following XML elements are used by the UM Router to configure a peer link:</p>
<ul>
<li>
'<b>&lt;tls&gt;</b>' </li>
<li>
'<b>&lt;cipher-suites&gt;</b>' </li>
<li>
'<b>&lt;certificate&gt;</b>' </li>
<li>
'<b>&lt;certificate-key&gt;</b>' </li>
<li>
'<b>&lt;certificate-key-password&gt;</b>' </li>
<li>
'<b>&lt;trusted-certificates&gt;</b>' </li>
</ul>
<p>As with sources and receivers, the portals on both sides of a peer link must be configured for compatible encryption settings.</p>
<p>Notice that there is no element corresponding to the context option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlscompressionnegotiationtimeoutcontext">tls_compression_negotiation_timeout (context)</a>. The UM Router peer link's negotiation timeout is hard-coded to 5 seconds.</p>
<p>See the UM Router configuration DTD for details.</p>
<p><br />
 </p>
<h3><a class="anchor" id="tlsandcompression"></a>
TLS and Compression</h3>
<p>Many users have advanced network equipment (switches/routers), which transparently compress packets as they traverse the network. This compression is especially valued to conserve bandwidth over long-haul WAN links. However, when packets are encrypted, the network compressors are typically not able to reduce the size of the data. If the user desires UM messages to be compressed and encrypted, the data needs to be compressed before it is encrypted.</p>
<p>The UM compression feature (see <a class="el" href="index.html#compressedtcp">Compressed TCP</a>) accomplishes this. When both TLS and compression are enabled, the compression is applied to user data first, then encryption.</p>
<p>Be aware that there can be information leakage when compression is applied and an attacker is able to inject data of known content over a compressed and encrypted session. For example, this leakage is exploited by the <a href="https://en.wikipedia.org/wiki/CRIME">CRIME</a> attack, albeit primarily for web browsers. Users must weigh the benefits of compression against the potential risk of information leakage.</p>
<p><b>Version Interoperability</b></p>
<p>It is not recommended to mix pre-6.9 contexts with encrypted contexts on topics of shared interest. If a process with a pre-6.9 version of UM creates a receiver, and another process with UM 6.9 or beyond creates a TLS source, the pre-6.9 receiver will attempt to join the TLS source. After a timeout, the handshake will fail and the source will disconnect. The pre-6.9 receiver will retry the connection, leading to flapping.</p>
<p>Note that in the reverse situation, a 6.9 TLS receiver will simply ignore a pre-6.9 source. I.e. no attempt will be made to join, and no flapping will occur.</p>
<p><br />
 </p>
<h2><a class="anchor" id="compressedtcp"></a>
Compressed TCP</h2>
<p>This section introduces the use of Compression with TCP connections.</p>
<p>The goal of the Ultra Messaging (UM) compression feature is to decrease the size of transmitted application data. UM can be configured to apply compression to all Streaming and/or Persisted TCP communication.</p>
<p>Non-TCP communication is not compressed (e.g. topic resolution).</p>
<p>Compression is generally implemented by any of several different software packages. UM makes use of LZ4, a widely deployed open-source project.</p>
<p>While the UM compression feature is usable for TCP-based sources and receivers, it is possibly most useful when applied to UM Router peer links.</p>
<p><br />
 </p>
<h3><a class="anchor" id="compressionconfiguration"></a>
Compression Configuration</h3>
<p>Compression is enabled on a context basis. When enabled, all Streaming and Persistence related TCP-based communication into or out of the context is compressed by LZ4. A context with compression enabled will not accept source creation with transports other than TCP.</p>
<p>Subscribers will only successfully receive data if the receiver's context and the source's context share the same compression settings. A receiver created in a compression-enabled context will ignore topic resolution source advertisements for non-compressed sources, and will therefore not subscribe. Similarly, a receiver created in an non-compressed context will ignore topic resolution source advertisements for compressed sources. Topic resolution queries are also ignored by mis-matched contexts. No warning will be logged when these topic resolution datagrams are ignored, but each time this happens, the context-level statistic tr_dgrams_dropped_type is incremented.</p>
<p>Compression is applied to unicast immediate messages as well, as invoked either directly by the user, or internally by functions like late join, request/response, and Persistence-related communication between sources, receivers, and stores.</p>
<p>Brokered Queuing using AMQP does not use the UM compression feature. A UM brokered context does not allow compression to be enabled.</p>
<p>The compression-related configuration options used by the Ultra Messaging library are:</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpcompressedtcp.html#compressioncontext">compression (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlscompressionnegotiationtimeoutcontext">tls_compression_negotiation_timeout (context)</a> </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="compressionandpersistence"></a>
Compression and Persistence</h3>
<p>Compression is designed to compress a data transport session. It is not intended to compress data at rest. When a Persistent Store is used with the UM compression feature, the user messages are written to disk in uncompressed form.</p>
<p><br />
 </p>
<h3><a class="anchor" id="compressionandqueuing"></a>
Compression and Queuing</h3>
<p>The UM compression feature does not apply to the AMQP connection to the brokered queue. UM does not currently support compression on the AMQP connection.</p>
<p>However, the ULB form of queuing does not use a broker. For ULB sources that are configured for TCP, the UM compression feature will compress the application data.</p>
<p><br />
 </p>
<h3><a class="anchor" id="compressionandthedynamicroutingoptiondro"></a>
Compression and the Dynamic Routing Option (DRO)</h3>
<p>When a UM Router is used to route messages across topic resolution domains (TRDs), be aware that the compression session is terminated at the UM Router's proxy receiver/source. Because each endpoint portal on a UM Router is implemented with its own context, care must be taken to ensure end-to-end compression (if desired). As a message is forwarded through a UM Router network, it does not propagate the compression setting of the originator, so each portal needs to be appropriately compressed.</p>
<p>Possibly the most-useful application of the UM compression feature is not TCP sources, but rather UM Router peer links. The compression feature is extended to UM Router peer links, however peer links are not context-based and are not configured the same way. The following XML elements are used by the UM Router to configure a peer link:</p>
<ul>
<li>
'<b>&lt;compression&gt;</b>' </li>
</ul>
<p>As with sources and receivers, the portals on both sides of a peer link must be configured for the same compression setting.</p>
<p>Notice that there is no element corresponding to the context option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpencryptedtcp.html#tlscompressionnegotiationtimeoutcontext">tls_compression_negotiation_timeout (context)</a>. The UM Router peer link's negotiation timeout is hard-coded to 5 seconds.</p>
<p>See the UM Router configuration DTD for details.</p>
<p><br />
 </p>
<h3><a class="anchor" id="compressionandencryption"></a>
Compression and Encryption</h3>
<p>See <a class="el" href="index.html#tlsandcompression">TLS and Compression</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="versioninteroperability"></a>
Version Interoperability</h3>
<p>It is not recommended to mix pre-6.9 contexts with compressed contexts on topics of shared interest. As mentioned above, if a compressed and an uncompressed context connect via TCP, the connection will fail and retry, resulting in flapping.</p>
<p><br />
 </p>
<h2><a class="anchor" id="highresolutiontimestamps"></a>
High-resolution Timestamps</h2>
<p>This section introduces the use of high-resolution timestamps with LBT-RM.</p>
<p>The Ultra Messaging (UM) high-resolution message timestamp feature leverages the hardware timestamping function of certain Solarflare network interface cards (NICs) to measure sub-microsecond times that packets are transmitted and received. Solarflare's NICs and Onload kernel-bypass driver implement PTP to synchronize timestamps across the network, allowing very accurate one-way latency measurements. The UM timestamp feature requires Solarflare OpenOnload version 201509 or later.</p>
<p>For subscribers, each message's receive timestamp is delivered in the message's header structure (for C programs, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aaa7a945411e63884f12918417e8d117c">lbm_msg_t</a> field <b>hr_timestamp</b>, of type <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a60ce419ca9bccc4d2b61b9acb70fe30e">lbm_timespec_t</a>). Each timestamp is a structure of 32 bits worth of seconds and 32 bits worth of nanoseconds. When both values are zero, the timestamp is not available.</p>
<p>For publishers, each message's transmit timestamp is delivered via the source event callback (for C programs, event type LBM_SRC_EVENT_TIMESTAMP). The same timestamp structure as above is delivered with the event, as well as the message's sequence number. Sending applications can be informed of the outgoing sequence number range of each message by using the extended form of the send function and supplying the LBM_SRC_SEND_EX_FLAG_SEQUENCE_NUMBER_INFO flag. This causes the LBM_SRC_EVENT_SEQUENCE_NUMBER_INFO event to be delivered to the source event handler.</p>
<p><br />
 </p>
<h3><a class="anchor" id="timestamprestrictions"></a>
Timestamp Restrictions</h3>
<p>Due to the specialized nature of this feature, there are several restrictions in its use.</p>
<ol>
<li>
<b>Operating system</b>: Linux only. No timestamps will be delivered on other operating systems. Also, since the feature makes use of the rcvmmsg() function, no timestamps will be delivered on Linux kernels prior to 2.6.33 and glibc libraries prior to 2.12 (which was released in 2010). </li>
<li>
<b>Languages</b>: C and Java only. </li>
<li>
<b>Transport</b>: Source-based LBT-RM (multicast) transport sessions only. No timestamps will be delivered for MIM or other transport types. </li>
<li>
<b>Queuing</b>: Timestamps are not supported for broker-based queuing. If a ULB source is configured for LBT-RM, send-side timestamps are not supported and will not be delivered if one or more receivers are registered. However, on the receive side, ULB messages are time stamped. </li>
<li>
<b>Loss</b>: If packet loss triggers LBT-RM's NAK/retransmit sequence, the send side will have multiple timestamps delivered, one for each multicast transmission. On the receive side, the timestamp of the first successfully received multicast datagram will be delivered. </li>
<li>
<b>Recovery</b>: For missed messages which are recovered via Late Join, Off-Transport Recovery (OTR), or the Persistent Store, no timestamp will be delivered, either on the send side or the receive side. </li>
<li>
<b>Implicit batching</b>: If implicit batching is being used, only the first message in a batch will have a send-side timestamp delivered. When implicit batching is used, the sender must be prepared for some messages to not have timestamps delivered. On the receive side, all messages in a batch will have the same timestamp. </li>
<li>
<b>UM Fragmentation, send-side</b>: If user messages are too large to be contained in a single datagram, UM will fragment the message into multiple datagrams. On the send side, each datagram will trigger delivery of a timestamp. <ul>
<li>
UM Fragmentation, receive-side with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a> set to 0 (arrival): Arrival-order delivery will result in each fragment being delivered separately, as it is received. Each fragment's message header will contain a timestamp. Arrival order delivery provides an accurate timestamp of when the complete message is received (although, as mentioned above, any fragment recovered via OTR or the Persistent Store will not have a timestamp). </li>
<li>
UM Fragmentation, receive-side with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a> set to 1 or -1, (reassembly): Delivery with reassembly results in a single timestamp included in the message header. That timestamp corresponds to the arrival of the last fragment of the message (although, as mentioned above, any fragment recovered via OTR or the Persistent Store will not have a timestamp). Note that this is not necessarily the last fragment received; if an intermediate datagram is lost and subsequently re-transmitted after a delay, that intermediate datagram will be the last one received, but its timestamp will not be used for the message. For example, if a three-fragment message is received in the order of F0, F2, F1, the timestamp for the message will correspond to F2, the last fragment of the message. If fragmented messages are being sent, and an accurate time of message completion is needed, arrival order delivery must be used. </li>
</ul>
</li>
<li>
<b>UM Fragmentation plus implicit batching</b>: If user messages vary widely in size, some requiring fragmentation, and implicit batching is used be aware that a full fragment does not completely fill a datagram. For example, if a small message (less than 300 bytes) is sent followed by a large message requiring fragmentation, the first fragment of the large message will fit in the same datagram as the small message. In that case, on the send side, a timestamp will not be delivered for that first fragment. However, a timestamp will be delivered for the second fragment. On the receive side, the same restrictions apply as described with UM fragmentation. </li>
<li>
<b>Local loopback</b>: If an LBT-RM source and receiver share the same physical machine, the receive side will not have timestamps delivered. </li>
</ol>
<p><br />
 </p>
<h3><a class="anchor" id="timestampconfigurationsummary"></a>
Timestamp Configuration Summary</h3>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmsourcetimestampcontext">transport_lbtrm_source_timestamp (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html#transportlbtrmreceivertimestampcontext">transport_lbtrm_receiver_timestamp (context)</a> </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="receivemultipledatagrams"></a>
Receive Multiple Datagrams</h2>
<p>A UM receiver for UDP-based protocols normally retrieves a single UDP datagram from the socket with each socket read. Setting <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#multiplereceivemaximumdatagramscontext">multiple_receive_maximum_datagrams (context)</a> to a value greater than zero directs UM to retrieve up to that many datagrams with each socket read. When receive socket buffers accumulate multiple messages, this feature improves CPU efficiency, which reduces the probability of loss, and also reduces total latency for those buffered datagrams. Note that UM does not need to wait for that many datagrams to be received before processing them; if fewer datagrams are in the socket's receive buffer, only the available datagrams retrieved.</p>
<p>In addition to increasing efficiency, setting <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#multiplereceivemaximumdatagramscontext">multiple_receive_maximum_datagrams (context)</a> greater than zero can produce changes in the dynamic behavior across multiple sockets. For example, let's say that a receiver is subscribed to two transport sessions, A and B. Let's further say that transport session A is sending message relatively quickly and has built up several datagrams in its socket buffer. Further, B is sending slowly. If <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#multiplereceivemaximumdatagramscontext">multiple_receive_maximum_datagrams (context)</a> is zero, the two sockets will compete equally for UM's attention. I.e. B's socket will still have a chance to be read after each A datagram is read and processed. However, if <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#multiplereceivemaximumdatagramscontext">multiple_receive_maximum_datagrams (context)</a> is 10, then UM can process up to 10 of A's messages before giving B a chance to be read. This is desirable if low message latency is equally important across all transport sessions; the efficiency improvement derived by retrieving multiple datagrams with each read operation results in lower overall latency. However, if it is more important to minimize latency of the slower transport session's messages, then it would be better to set <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#multiplereceivemaximumdatagramscontext">multiple_receive_maximum_datagrams (context)</a> close to or equal to zero.</p>
<p>The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#multiplereceivemaximumdatagramscontext">multiple_receive_maximum_datagrams (context)</a> configuration option defaults to 0 so as to retain previous behavior, but users are encouraged to set this to a value between 2 and 10. Having too large a value during a period of overload can lead to starvation of low-rate transport sessions by high-rate transport sessions.</p>
<p><br />
 </p>
<h3><a class="anchor" id="receivemultipledatagramscompatibility"></a>
Receive Multiple Datagrams Compatibility</h3>
<p>The Receive Multiple Datagrams feature is compatible with the following UM features:</p>
<ul>
<li>
UDP-based transport protocols LBT-RM and LBT-RU. </li>
<li>
MIM (Multicast Immediate Message). </li>
<li>
UDP-based Topic Resolution protocol, both multicast and unicast. </li>
<li>
All language bindings (C, Java, .NET). </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="receivemultipledatagramsrestrictions"></a>
Receive Multiple Datagrams Restrictions</h3>
<p>The Receive Multiple Datagrams feature is not compatible with the following UM features:</p>
<ul>
<li>
Non-UDP Transport Protocols (TCP, IPC, SMX). </li>
<li>
Other TCP-based features (Unicast Immediate Message, Late Join, Persistent Store Recovery, UM Response messages). </li>
<li>
Non-Linux. The recvmmsg() function was introduced into the Linux kernel in version 2.6.33, and support for it was added to glibc in version 2.12. </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="messageproperties"></a>
Message Properties</h2>
<p>The message property object <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a9155c3d6d70b67c426089d53b3eacaac">lbm_msg_properties_t</a> allows your application to insert named, typed metadata to topic messages and implement functionality that depends on the message properties. UM allows eight property types: boolean, byte, short, int, long, float, double, and string.</p>
<p>To use message properties, create a message properties object with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#abda1a4224f1c3e94b10b74051be3dd53">lbm_msg_properties_create()</a>. Then set the desired message properties using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#acec18484fc06996fe3b61e76a593d5fb">lbm_msg_properties_set()</a>. Then send topic messages with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a091b5806bf18d10ebd0d9117e0c70229">lbm_src_send_ex()</a> (or LBMSource.send() in the Java API or .NET API) passing the message properties object through <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a21504de56612c7c6e4be655402b47a37">lbm_src_send_ex_info_t</a> object. Set the LBM_SRC_SEND_EX_FLAG_PROPERTIES flag on the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a21504de56612c7c6e4be655402b47a37">lbm_src_send_ex_info_t</a> object to indicate that it includes properties.</p>
<p>Upon a receipt of a message with properties, your application can access the properties directly through the messages properties field, which is null if no properties are present. Individual property values can be retrieved directly by name, or you can iterate over the collection of properties to determine which properties are present at runtime. For an example on how to iterate received message properties, see <a href="../../example/lbmrcv.c">lbmrcv.c</a>.</p>
<p>To mitigate any performance impacts in the C API, reuse properties objects, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a21504de56612c7c6e4be655402b47a37">lbm_src_send_ex_info_t</a> objects and iterators whenever possible. Also limit the number of properties associated with a message. (UM sends the property name and additional indexing information with every message.) In the Java API or .NET API, also make use of the ZOD feature by calling Dispose() on each message before returning from the application callback. This allows property objects to be reused as well.</p>
<dl class="section note"><dt>Note</dt><dd>The Message Properties Object does not support receivers using the arrival order without reassembly setting (option value = 0) of <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a>.</dd></dl>
<p>With the UMQ product, the UM message property object supports the standard JMS message properties specification.</p>
<p><br />
 </p>
<h3><a class="anchor" id="smartsourcesandmessageproperties"></a>
Smart Sources and Message Properties</h3>
<p><a class="el" href="index.html#smartsources">Smart Sources</a> support a limited form of message properties. Only 32-bit integer property types are allowed with Smart Sources. Also, property names are limited to 7 ASCII characters. Finally, the normal message properties object <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a9155c3d6d70b67c426089d53b3eacaac">lbm_msg_properties_t</a> and its APIs <em>are not used</em> on the sending side. Rather a streamlined method of specifying message properties for sending is used.</p>
<p>As with most of Smart Source's internal design, the message header for message properties must be pre-allocated with the maximum number of desired message properties. This is done at creation time for the Smart Source using the configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcmessagepropertyintcountsource">smart_src_message_property_int_count (source)</a>.</p>
<p>Sending messages with message properties must be done using the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2f50f56536778332e9f5712b06546425">lbm_ssrc_send_ex()</a> API, passing it the desired properties. The first call to send with message properties will parse the supplied properties and encode them into the pre-allocated message header.</p>
<p>Subsequent calls to send with message properties will ignore the passed-in properties and simply re-send the previously-parsed header. If it is desired to change the message properties after that initial send, it is necessary to pass an "update property values" flag, which will trigger a re-parse of the passed-in properties.</p>
<p>Once the message property header is parsed, it is also possible to send messages without the properties attached. This does not require the "update property values" flag, and does not involve re-parsing the header. See next section for details.</p>
<dl class="section note"><dt>Note</dt><dd>If using both message properties and <a class="el" href="index.html#spectrum">Spectrum</a> with a single Smart Source, there is an added restriction: it is not possible to send a message omitting only one of those features. I.e. if both are enabled when the Smart Source is created, it is not possible to send a message with a message property and not a channel, and it is not possible to send a message with a channel and not a property. This is because the message header is defined at Smart Source creation, and the header either must contain both or neither.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="smartsourcemessagepropertiesusage"></a>
Smart Source Message Properties Usage</h3>
<p>For a full example of message property usage with Smart Source, see <a href="../../example/lbmssrc.c">lbmssrc.c</a> or <a href="../../java_example/lbmssrc.java">lbmssrc.java</a>.</p>
<p>The first message with a message property sent to a Smart Source follows a specific sequence:</p>
<ol>
<li>
<p class="startli">Create the topic object with the configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcmessagepropertyintcountsource">smart_src_message_property_int_count (source)</a> set to the maximum number of properties desired on a message.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Create the Smart Source with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a9a8d169a8c2a90b8442d4eb3e3711c9c">lbm_ssrc_create()</a>.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Optionally, one or more messages can be sent without message properties.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">When preparing the first message with message properties to be sent, define the properties using a <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a33886eeac2e67170effea009d2dc3a35">lbm_ssrc_send_ex_info_t</a> structure: </p><pre class="fragment">  char *prop_name_array[3]; /* Array of property names. */
  prop_name_array[0] = "abc"; /* 7 ascii characters or less. */
  prop_name_array[1] = "XYZ";
  prop_name_array[2] = "123";

  lbm_int32_t prop_value_array[3]; /* Array of property values. */
  prop_value_array[0] = 29;
  prop_value_array[1] = -300;
  prop_value_array[2] = 0;

  lbm_ssrc_send_ex_info_t ss_send_info;
  memset((char *)&amp;ss_send_info, 0, sizeof(ss_send_info));
  ss_send_info.mprop_int_cnt = 3;
  ss_send_info.mprop_int_keys = prop_name_array;
  ss_send_info.mprop_int_vals = prop_value_array;
</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Send the message using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2f50f56536778332e9f5712b06546425">lbm_ssrc_send_ex()</a> and the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#af00465b8e9c560959351ec92f62a190e">LBM_SSRC_SEND_EX_FLAG_PROPERTIES</a> flag: </p><pre class="fragment">  /* If this flag had been cleared previously, must set it. */
  ss_send_info.flags |= LBM_SSRC_SEND_EX_FLAG_PROPERTIES;/*set*/
  /* If this flag had been set previously, must clear it. */
  ss_send_info.flags &amp;= ~ LBM_SSRC_SEND_EX_FLAG_UPDATE_PROPERTY_VALUES;/*clr*/
  err = lbm_ssrc_send_ex(ss, msg_buff, msg_size, 0, &amp;ss_send_info);
</pre><p class="endli">Since this is the first send with message properties, UM will parse the properties and set up the message header. It is not valid to set the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a40748fccf40f69c2029d68c16f923704">LBM_SSRC_SEND_EX_FLAG_UPDATE_PROPERTY_VALUES</a> flag on this first send with message properties. </p>
</li>
</ol>
<p>For subsequent sends, there are three choices: </p><ol>
<li>
<p class="startli">Send the message with the same properties and values. You can re-use the same <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a33886eeac2e67170effea009d2dc3a35">lbm_ssrc_send_ex_info_t</a> object: </p><pre class="fragment">  /* If this flag had been cleared previously, must set it. */
  ss_send_info.flags |= LBM_SSRC_SEND_EX_FLAG_PROPERTIES;/*set*/
  /* If this flag had been set previously, must clear it. */
  ss_send_info.flags &amp;= ~ LBM_SSRC_SEND_EX_FLAG_UPDATE_PROPERTY_VALUES;/*clr*/
  err = lbm_ssrc_send_ex(ss, msg_buff, msg_size, 0, &amp;ss_send_info);
</pre><p> Note that even though the lbm_ssrc_send_ex_info_t object is passed in and the message properties will be sent with the message, this call to <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2f50f56536778332e9f5712b06546425">lbm_ssrc_send_ex()</a> will <em>not</em> re-parse the application's message properties, so any changes made to the properties or their values in the lbm_ssrc_send_ex_info_t object will be ignored (see next item).</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Send a with message properties after having made changes to the properties and/or their values by setting the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a40748fccf40f69c2029d68c16f923704">LBM_SSRC_SEND_EX_FLAG_UPDATE_PROPERTY_VALUES</a> flag: </p><pre class="fragment">  /* If either of these flags had been cleared previously, must set it. */
  ss_send_info.flags |= LBM_SSRC_SEND_EX_FLAG_PROPERTIES;/*set*/
  ss_send_info.flags |= LBM_SSRC_SEND_EX_FLAG_UPDATE_PROPERTY_VALUES;/*set*/
  err = lbm_ssrc_send_ex(ss, msg_buff, msg_size, 0, &amp;ss_send_info);
</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Send a message without any message properties by clearing the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#af00465b8e9c560959351ec92f62a190e">LBM_SSRC_SEND_EX_FLAG_PROPERTIES</a> flag: </p><pre class="fragment">  /* If either of these flags had been set previously, must clear it. */
  ss_send_info.flags &amp;= ~ LBM_SSRC_SEND_EX_FLAG_PROPERTIES;/*clr*/
  ss_send_info.flags &amp;= ~ LBM_SSRC_SEND_EX_FLAG_UPDATE_PROPERTY_VALUES;/*clr*/
  err = lbm_ssrc_send_ex(ss, msg_buff, msg_size, 0, &amp;ss_send_info);
</pre><p class="endli">Alternatively, you can simply not supply a <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a33886eeac2e67170effea009d2dc3a35">lbm_ssrc_send_ex_info_t</a> object by passing NULL for the <code>info</code> parameter. This suppresses all features enabled by that structure. </p>
</li>
</ol>
<p><br />
 </p>
<h2><a class="anchor" id="requestresponsemodel"></a>
Request/Response Model</h2>
<p>Request/response is a very common messaging model whereby a client sends a "request" message to a server and expects a response. The server processes the request and return a response message to the originating client.</p>
<p>The UM request/response feature simplifies implementation of this model in the following ways: </p><ul>
<li>
Handling the request's "return address", eliminating the need for the client to create an artificial guaranteed-unique topic for the response. </li>
<li>
Establishing a linkage between a request and its response(s), allowing multiple requests to be outstanding, and associating each response message with its corresponding request message. </li>
<li>
Supporting multiple responses per request, both by allowing multiple servers to receive the request and each one responding, and by allowing a given server to respond with multiple messages. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="requestmessage"></a>
Request Message</h3>
<p>UM provides three ways to send a request message.</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ad4d06f66b8404684e191ca178e0cc09b">lbm_send_request()</a> to send a request to a topic via a source object. Uses the standard source-based transports (TCP, LBT-RM, LBT-RU). </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a54f3933e4dd154a9c7bb72598d0d9ef1">lbm_multicast_immediate_request()</a> to send a request to a topic as a multicast immediate message. See <a class="el" href="index.html#multicastimmediatemessaging">Multicast Immediate Messaging</a>. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ae011c7a66e1db1f012d7f9633dbd321d">lbm_unicast_immediate_request()</a> to send a request to a topic as a unicast immediate message. </li>
</ul>
<p>When the client application sends a request message, it references an application callback function for responses and a client data pointer for application state. The send call returns a "request object". As one or more responses are returned, the callback is invoked to deliver the response messages, associated with the request's client data pointer. The requesting application decides when its request is satisfied (perhaps by completeness of a response, or by timeout), and it calls <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a0abaa1c2ba62bba7a5eaf1f7f2abbac0">lbm_request_delete()</a> to delete the request object. Even if the server chooses to send additional responses, they will not be delivered to the requesting application after it has deleted the corresponding request object.</p>
<p><br />
 </p>
<h3><a class="anchor" id="responsemessage"></a>
Response Message</h3>
<p>The server application receives a request via the normal message receive mechanism, but the message is identified as type "request". Contained within that request message's header is a response object, which serves as a return address to the requester. The server application responds to an UM request message by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a0bbc01b600ccc2ae874474e35955eb85">lbm_send_response()</a>. The response message is sent unicast via a dynamic TCP connection managed by UM.</p>
<dl class="section warning"><dt>Warning</dt><dd>The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a0bbc01b600ccc2ae874474e35955eb85">lbm_send_response()</a> function may not be called from a context thread callback. If the application needs to send the response from the receiver callback, it must associate that receiver callback with an event queue.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>Since the response object is part of the message header, it is normally deleted at the same time that the message is deleted, which typically happens automatically when the receiver callback returns. However, there are times when the application needs the scope of the response object to extend beyond the execution of the receiver callback. One method of extending the lifetime of the response object is to "retain" the request message, using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2b7788ff58f9e78bc89ea890dad0cccf">lbm_msg_retain()</a>. </dd></dl>
<dl class="section user"><dt></dt><dd>However, there are times when the size of the request message makes retention of the entire message undesirable. In those cases, the response object itself can be extracted and retained separately by saving a copy of the response object pointer and setting the message header's response pointer to NULL (to prevent UM from deleting the response object when the message is deleted). </dd></dl>
<dl class="section user"><dt></dt><dd>There are even occasions when an application needs to transfer the responsibility of responding to a request message to a different process entirely. I.e. the server which receives the request is not itself able to respond, and needs to send a message (not necessarily the original request message) to a different server. In that case, the first server which receives the request must serialize the response object to type <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a54cfbb23ab41a8d22968f68df015e246">lbm_serialized_response_t</a> by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a7595677bf01cb9397d1fd174bd095e9f">lbm_serialize_response()</a>. It includes the serialized response object in the message forwarded to the second server. That server de-serializes the response object by calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ad74f47a1e021b2422b80c0bf8d03f7a9">lbm_deserialize_response()</a>, allowing it to send a response message to the original requesting client.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="tcpmanagement"></a>
TCP Management</h3>
<p>UM creates and manages the special TCP connections for responses, maintaining a list of active response connections. When an application sends a response, UM scans that list for an active connection to the destination. If it doesn't find a connection for the response, it creates a new connection and adds it to the list. After the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a0bbc01b600ccc2ae874474e35955eb85">lbm_send_response()</a> function returns, UM schedules the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresponseoperation.html#responsetcpdeletiontimeoutcontext">response_tcp_deletion_timeout (context)</a>, which defaults to 2 seconds. If a second request comes in from the same application before the timer expires, the responding application simply uses the existing connection and restarts the deletion timer.</p>
<p>It is conceivable that a very large response could take more than the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresponseoperation.html#responsetcpdeletiontimeoutcontext">response_tcp_deletion_timeout (context)</a> default (2 seconds) to send to a slow-running receiver. In this case, UM automatically increases the deletion timer as needed to ensure the last message completes.</p>
<p><br />
 </p>
<h3><a class="anchor" id="requestresponseconfiguration"></a>
Request/Response Configuration</h3>
<p>See the <a href="../../Config/index.html">UM Configuration Guide</a> for the descriptions of the Request/Response configuration options.</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html">Request Network Options</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestoperation.html">Request Operation Options</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpresponseoperation.html">Response Operation Options</a> </li>
</ul>
<dl class="section note"><dt>Note</dt><dd>If your application is running within an UM context where the configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grprequestnetwork.html#requesttcpbindrequestportcontext">request_tcp_bind_request_port (context)</a> has been set to zero, request port binding has been turned off, which also disables the Request/Response feature.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="requestresponseexampleapplications"></a>
Request/Response Example Applications</h3>
<p>UM includes two example applications that illustrate Request/Response.</p>
<ul>
<li>
<a href="../../example/lbmreq.c">lbmreq.c</a> - application that sends requests on a given topic (single source) and waits for responses. See also the Java example, <a href="../../java_example/lbmreq.java">lbmreq.java</a> and the .NET example, <a href="../../dotnet_example/lbmreq.cs">lbmreq.cs</a>. </li>
<li>
<a href="../../example/lbmresp.c">lbmresp.c</a> - application that waits for requests and sends responses back on a given topic (single receiver). See also the Java example, <a href="../../java_example/lbmresp.java">lbmresp.java</a> and the .NET example, <a href="../../dotnet_example/lbmresp.cs">lbmresp.cs</a>. </li>
</ul>
<p>We can demonstrate a series of 5 requests and responses with the following procedure:</p>
<ul>
<li>
Run <b>lbmresp -v topicname</b> </li>
<li>
Run <b>lbmreq -R 5 -v topicname</b> </li>
</ul>
<p><b>LBMREQ</b></p>
<p>Output for lbmreq should resemble the following:</p>
<pre class="fragment">$ lbmreq -R 5 -q topicname
Event queue in use
Using TCP port 4392 for responses
Delaying requests for 1000 milliseconds
Sending request 0
Starting event pump for 5 seconds.
Receiver connect [TCP:10.29.1.78:4958]
Done waiting for responses. 1 responses (25 bytes) received. Deleting request. Sending request 1
Starting event pump for 5 seconds.
Done waiting for responses. 1 responses (25 bytes) received. Deleting request. Sending request 2
Starting event pump for 5 seconds.
Done waiting for responses. 1 responses (25 bytes) received. Deleting request. Sending request 3
Starting event pump for 5 seconds.
Done waiting for responses. 1 responses (25 bytes) received. Deleting request. Sending request 4
Starting event pump for 5 seconds.
Done waiting for responses. 1 responses (25 bytes) received. Deleting request.
Quitting...
</pre><p><b>LBMRESP</b></p>
<p>Output for lbmresp should resemble the following:</p>
<pre class="fragment">$ lbmresp -v topicname
Request [topicname][TCP:10.29.1.78:14371][0], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
Request [topicname][TCP:10.29.1.78:14371][1], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
Request [topicname][TCP:10.29.1.78:14371][2], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
Request [topicname][TCP:10.29.1.78:14371][3], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
Request [topicname][TCP:10.29.1.78:14371][4], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
[topicname][TCP:10.29.1.78:14371], End of Transport Session
</pre><p><br />
 </p>
<h2><a class="anchor" id="selfdescribingmessaging"></a>
Self Describing Messaging</h2>
<p>The UM Self-Describing Messaging (SDM) feature provides an API that simplifies the creation and use of messages by your applications. An SDM message contains one or more fields and each field consists of the following:</p>
<ul>
<li>
A name </li>
<li>
A type </li>
<li>
A value </li>
</ul>
<p>Each named field may appear only once in a message. If multiple fields of the same name and type are needed, array fields are available. A field in a nested message may have the same name as a field in the outer message.</p>
<p>SDM is particularly helpful for creating messages sent across platforms by simplifying the creation of data formats. SDM automatically performs platform-specific data translations, eliminating endian conflicts.</p>
<p>Using SDM also simplifies message maintenance because the message format or structure can be independent of the source and receiver applications. For example, if your receivers query SDM messages for particular fields and ignore the order of the fields within the message, a source can change the field order if necessary with no modification of the receivers needed.</p>
<p>See the C, Java, and .NET API guides for details.</p>
<p><br />
 </p>
<h2><a class="anchor" id="predefinedmessages"></a>
Pre-Defined Messages</h2>
<p>The UM Pre-Defined Messages (PDM) feature provides an API similar to the SDM API, but allows you to define messages once and then use the definition to create messages that may contain self-describing data. Eliminating the need to repeatedly send a message definition increases the speed of PDM over SDM. The ability to use arrays created in a different programming language also improves performance.</p>
<p>The PDM library lets you create, serialize, and deserialize messages using pre-defined knowledge about the possible fields that may be used. You can create a definition that a) describes the fields to be sent and received in a message, b) creates the corresponding message, and c) adds field values to the message. This approach offers several performance advantages over SDM, as the definition is known in advance. However, the usage pattern is slightly different than the SDM library, where fields are added directly to a message without any type of definition.</p>
<p>A PDM message contains one or more fields and each field consists of the following:</p>
<ul>
<li>
A name </li>
<li>
A type </li>
<li>
A value </li>
</ul>
<p>Each named field may appear only once in a message. If multiple fields of the same name and type are needed, array fields are available. A field in a nested message may have the same name as a field in the outer message.</p>
<p>See the C, Java, and .NET Application Programmer's Interfaces for complete references of PDM functions, field types and message field operations. The C API also has information and code samples about how to create definitions and messages, set field values in a message, set the value of array fields in a message, serialize, deserialize and dispose of messages, and fetch values from a message.</p>
<dl class="section note"><dt>Note</dt><dd>The Pre-Defined Messaging (PDM) feature is not supported on the OpenVMS® platform.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="typicalpdmusagepatterns"></a>
Typical PDM Usage Patterns</h3>
<p>The typical PDM usage patterns can usually be broken down into two categories: sources (which need to serialize a message for sending) and receivers (which need to deserialize a message to extract field values). However, for optimum performance for both sources and receivers, first set up the definition and a single instance of the message only once during a setup or initialization phase, as in the following example workflow:</p>
<ol>
<li>
Create a definition and set its id and version. </li>
<li>
Add field information to the definition to describe the types of fields to be in the message. </li>
<li>
Create a single instance of a message based on the definition. </li>
<li>
Set up a source to do the following: <ul>
<li>
Add field values to the message instance. </li>
<li>
Serialize the message so that it can be sent. </li>
</ul>
</li>
<li>
Likewise, set up a receiver to do the following: <ul>
<li>
Deserialize the received bytes into the message instance. </li>
<li>
Extract the field values from the message. </li>
</ul>
</li>
</ol>
<p><br />
 </p>
<h3><a class="anchor" id="gettingstartedwithpdm"></a>
Getting Started with PDM</h3>
<p>PDM APIs are provided in C, Java, and C#, however, the examples in this section are Java based.</p>
<p><b>PDM Code Example, Source</b></p>
<p>Translating the Typical PDM Usage Patterns to Java for a source produces the following:</p>
<pre class="fragment">private PDMDefinition defn;
private PDMMessage msg;
private PDMFieldInfo fldInfo100;
private PDMFieldInfo fldInfo101;
private PDMFieldInfo fldInfo102;

public void setupPDM() {
  //Create the definition with 3 fields and using int field names
  defn = new PDMDefinition(3, true);

  //Set the definition id and version
  defn.setId(1001);
  defn.setMsgVersMajor((byte)1);
  defn.setMsgVersMinor((byte)0);

  //Create information for a boolean, int32, and float fields (all required)
  fldInfo100 = defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
  fldInfo101 = defn.addFieldInfo(101, PDMFieldType.INT32, true);
  fldInfo102 = defn.addFieldInfo(102, PDMFieldType.FLOAT, true);

  //Finalize the definition and create the message defn.finalizeDef();
  msg = new PDMMessage(defn);
}

public void sourceUsePDM() {
  //Call the function to setup the definition and message
  setupPDM();

  //Example values for the message boolean
  fld100Val = true;
  int fld101Val = 7;
  float fld102Val = 3.14F;

  //Set each field value in the message
  msg.setFieldValue(fldInfo100, fld100Val);
  msg.setFieldValue(fldInfo101, fld101Val);
  msg.setFieldValue(fldInfo102, fld102Val);

  //Serialize the message to bytes
  byte[] buffer = msg.toBytes();
}
</pre><p><b>PDM Code Example, Receiver</b></p>
<p>Translating the Typical PDM Usage Patterns to Java for a receiver produces the following:</p>
<pre class="fragment">private PDMDefinition defn;
private PDMMessage msg;
private PDMFieldInfo fldInfo100;
private PDMFieldInfo fldInfo101;
private PDMFieldInfo fldInfo102;

public void setupPDM() {
  //Create the definition with 3 fields and using int field names
  defn = new PDMDefinition(3, true);

  //Set the definition id and version
  defn.setId(1001);
  defn.setMsgVersMajor((byte)1);
  defn.setMsgVersMinor((byte)0);

  //Create information for a boolean, int32, and float field (all required)
  fldInfo100 = defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
  fldInfo101 = defn.addFieldInfo(101, PDMFieldType.INT32, true);
  fldInfo102 = defn.addFieldInfo(102, PDMFieldType.FLOAT, true);

  //Finalize the definition and create the message
  defn.finalizeDef();
  msg = new PDMMessage(defn);
}

public void receiverUsePDM(byte[] buffer) {
  //Call the function to setup the definition and message
  setupPDM();

  //Values to be retrieved from the message
  boolean fld100Val;
  int fld101Val;
  float fld102Val;

  //Deserialize the bytes into a message
  msg.parse(buffer);

  //Get each field value from the message
  fld100Val = msg.getFieldValueAsBoolean(fldInfo100);
  fld101Val = msg.getFieldValueAsInt32(fldInfo101);
  fld102Val = msg.getFieldValueAsFloat(fldInfo102);
}
</pre><p><b>PDM Code Example Notes</b></p>
<p>In the examples above, the setupPDM() function is called once to set up the PDM definition and message. It is identical in both the source and receiver cases and simply sets up a definition that contains three required fields with integer names (100, 101, 102). Once finalized, it can create a message that leverages its pre-defined knowledge about these three required fields. The source example adds the three sample field values (a boolean, int32, and float) to the message, which is then serialized to a byte array. In the receiver example, the message parses a byte array into the message and then extracts the three field values.</p>
<p><br />
 </p>
<h3><a class="anchor" id="usingthepdmapi"></a>
Using the PDM API</h3>
<p>The following code snippets expand upon the previous examples to demonstrate the usage of additional PDM functionality (but use "..." to eliminate redundant code).</p>
<p><b>Reusing the Message Object</b></p>
<p>Although the examples use a single message object (which provides performance benefits due to reduced message creation and garbage collection), it is not explicitly required to reuse a single instance. However, multiple threads should not access a single message instance.</p>
<p><b>Number of Fields</b></p>
<p>Although the number of fields above is initially set to 3 in the PDMDefinition constructor, if you add more fields to the definition with the addFieldInfo method, the definition grows to accommodate each field. Once the definition is finalized, you cannot add additional field information because the definition is now locked and ready for use in a message.</p>
<p><b>String Field Names</b></p>
<p>The examples above use integer field names in the setupPDM() function when creating the definition. You can also use string field names when setting up the definition. However, you still must use a FieldInfo object to set or get a field value from a message, regardless of field name type. Notice that false is passed to the PDMDefinition constructor to indicate string field names should be used. Also, the overloaded addFieldInfo function uses string field names (.Field100.) instead of the integer field names.</p>
<pre class="fragment">...
public void setupPDM() {
  //Create the definition with 3 fields and using string field names
  defn = new PDMDefinition(3, false);
  ...
  //Create information for a boolean, int32, and float field (all required)
  fldInfo100 = defn.addFieldInfo("Field100", PDMFieldType.BOOLEAN, true);
  fldInfo101 = defn.addFieldInfo("Field101", PDMFieldType.INT32, true);
  fldInfo102 = defn.addFieldInfo("Field102", PDMFieldType.FLOAT, true);
  ...
}
...
</pre><p><b>Retrieving FieldInfo from the Definition</b></p>
<p>At times, it may be easier to lookup the FieldInfo from the definition using the integer name (or string name if used). This eliminates the need to store the reference to the FieldInfo when getting or setting a field value in a message, but it does incur a performance penalty due to the lookup in the definition to retrieve the FieldInfo. Notice that there are no longer FieldInfo objects being used when calling addFieldInfo and a lookup is being done for each call to msg.getFieldValueAs* to retrieve the FieldInfo by integer name.</p>
<pre class="fragment">private PDMDefinition defn;
private PDMMessage msg;

public void setupPDM() {
  ...
  //Create information for a boolean, int32, and float field (all required)
  defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
  defn.addFieldInfo(101, PDMFieldType.INT32, true);
  defn.addFieldInfo(102, PDMFieldType.FLOAT, true);
  ...
}

public void receiverUsePDM(byte[] buffer) {
  ...
  //Get each field value from the message
  fld100Val = msg.getFieldValueAsBoolean(defn.getFieldInfo(100));
  fld101Val = msg.getFieldValueAsInt32(defn.getFieldInfo(101));
  fld102Val = msg.getFieldValueAsFloat(defn.getFieldInfo(102));
}
</pre><p><b>Required and Optional Fields</b></p>
<p>When adding field information to a definition, you can indicate that the field is optional and may not be set for every message that uses the definition. Do this by passing false as the third parameter to the addFieldInfo function. Using required fields (fixed-required fields specifically) produces the best performance when serializing and deserializing messages, but causes an exception if all required fields are not set before serializing the message. Optional fields allow the concept of sending "null" as a value for a field by simply not setting that field value on the source side before serializing the message. However, after parsing a message, a receiver should check the isFieldValueSet function for an optional field before attempting to read the value from the field to avoid the exception mentioned above.</p>
<pre class="fragment">...
private PDMFieldInfo fldInfo103;
...
public void setupPDM() {
  ...
  //Create information for a boolean, int32, and float field (all required)
  // as well as an optional int8 field
  fldInfo100 = defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
  fldInfo101 = defn.addFieldInfo(101, PDMFieldType.INT32, true);
  fldInfo102 = defn.addFieldInfo(102, PDMFieldType.FLOAT, true);
  fldInfo103 = defn.addFieldInfo(103, PDMFieldType.INT8, false);
  ...
}

public void sourceUsePDM() {
  ...
  //Set each field value in the message
  // except do not set the optional field
  msg.setFieldValue(fldInfo100, fld100Val);
  msg.setFieldValue(fldInfo101, fld101Val);
  msg.setFieldValue(fldInfo102, fld102Val);
  ...
}

...
private PDMFieldInfo fldInfo103;
...
public void setupPDM() {
  ...
  //Create information for a boolean, int32, and float field (all required)
  // as well as an optional int8 field
  fldInfo103 = defn.addFieldInfo(103, PDMFieldType.INT8, false);
  ...
}

public void receiverUsePDM(byte[] buffer) {
  ...
  byte fld103Val;
  ...
  if(msg.isFieldValueSet(fldInfo103)) {
    fld103Val = msg.getFieldValueAsInt8(fldInfo103);
  }
}
</pre><p><b>Fixed String and Fixed Unicode Field Types</b></p>
<p>A variable length string typically does not have the performance optimizations of fixed-required fields. However, by indicating "required", as well as the field type FIX_STRING or FIX_UNICODE and specifying an integer number of fixed characters, PDM sets aside an appropriate fixed amount of space in the message for that field and treats it as an optimized fixed-required field. Strings of a smaller length can still be set as the value for the field, but the message allocates the specified fixed number of bytes for the string. Specify Unicode strings in the same manner (with FIX_UNICODE as the type) and in "UTF-8" format.</p>
<pre class="fragment">...
private PDMFieldInfo fldInfo104;
...
public void setupPDM() {
  ...
  fldInfo104 = defn.addFieldInfo(104, PDMFieldType.FIX_STRING, 12, true);
  ...
}

public void sourceUsePDM() {
  ...
  String fld104Val = "Hello World!";

  //Set each field value in the message
  // except do not set the optional field
  msg.setFieldValue(fldInfo100, fld100Val);
  msg.setFieldValue(fldInfo101, fld101Val);
  msg.setFieldValue(fldInfo102, fld102Val);
  msg.setFieldValue(fldInfo104, fld104Val);
  ...
}

...
private PDMFieldInfo fldInfo104;
...
public void setupPDM() {
  ...
  fldInfo104 = defn.addFieldInfo(104, PDMFieldType.FIX_STRING, 12, true);
  ...
}
public void receiverUsePDM(byte[] buffer) {
  ...
  String fld104Val;
  ...

  fld104Val = msg.getFieldValueAsString(fldInfo104);
}
</pre><p><b>Variable Field Types</b></p>
<p>The field types of STRING, UNICODE, BLOB, and MESSAGE are all variable length field types. They do not require a length to be specified when adding field info to the definition. You can use a BLOB field to store an arbitrary binary objects (in Java as an array of bytes) and a MESSAGE field to store a PDMMessage object,</p>
<p>which enables "nesting" PDMMessages inside other PDMMessages. Creating and using a variable length string field is nearly identical to the previous fixed string example.</p>
<pre class="fragment">...
private PDMFieldInfo fldInfo105;
...
public void setupPDM() {
  ...
  fldInfo105 = defn.addFieldInfo(105, PDMFieldType.STRING, true);
  ...
}

public void sourceUsePDM() {
  ...
  String fld105Val = "variable length value";
  ...
  msg.setFieldValue(fldInfo105, fld105Val);
  ...
}

...
private PDMFieldInfo fldInfo105;
...
public void setupPDM() {
  ...
  fldInfo105 = defn.addFieldInfo(105, PDMFieldType.STRING, true);
  ...
}
public void receiverUsePDM(byte[] buffer) {
  ...
  String fld105Val;
  ...

  fld105Val = msg.getFieldValueAsString(fldInfo105);
}
</pre><p>Retrieve the BLOB field values with the getFieldValueAsBlob function, and the MESSAGE field values with the getFieldValueAsMessage function.</p>
<p><b>Array Field Types</b></p>
<p>For each of the scalar field types (fixed and variable length), a corresponding array field type uses the convention *_ARR for the type name (ex: BOOLEAN_ARR, INT32_ARR, STRING_ARR, etc.). This lets you set and get Java values such as an int[] or string[] directly into a single field. In addition, all of the array field types can specify a fixed number of elements for the size of the array when they are defined, or if not specified, behave as variable size arrays. Do this by passing an extra parameter to the addFieldInfo function of the definition.</p>
<p>To be treated as a fixed-required field, an array type field must be required as well as be specified as a fixed size array of fixed length elements. For instance, a required BOOLEAN_ARR field defined with a size of 3 would be treated as a fixed-required field. Also, a required FIX_STRING_ARR field defined with a size of 5 and fixed string length of 7 would be treated as a fixed-required field. However, neither a STRING_ARR field nor a BLOB_ARR field are treated as a fixed length field even if the size of the array is specified, since each element of the array can be variable in length. In the example below, field 106 and field 108 are both treated as fixed-required fields, but field 107 is not because it is a variable size array field type.</p>
<pre class="fragment">...
private PDMFieldInfo fldInfo106;
private PDMFieldInfo fldInfo107;
private PDMFieldInfo fldInfo108;
...

public void setupPDM() {
  ...
  //Create information for a boolean, int32, and float field (all required)
  // as well as an optional int8 field
  ...
  //A required, fixed size array of 3 boolean elements
  fldInfo106 = defn.addFieldInfo(106, PDMFieldType.BOOLEAN_ARR, true, 3);
  //An optional, variable size array of int32 elements
  fldInfo107 = defn.addFieldInfo(107, PDMFieldType.INT32_ARR, false);
  //A required, fixed size array of 2 element which are each 5 character strings
  fldInfo108 = defn.addFieldInfo(108, PDMFieldType.FIX_STRING_ARR, 5, true, 2);
  ...
}

public void sourceUsePDM() {
  ...
  //Example values for the message
  ...
  boolean fld106Val[] = {true, false, true};
  int fld107Val[] = {1, 2, 3, 4, 5};
  String fld108Val[] = {"aaaaa", "bbbbb"};

  //Set each field value in the message
  ...
  msg.setFieldValue(fldInfo106, fld106Val);
  msg.setFieldValue(fldInfo107, fld107Val);
  msg.setFieldValue(fldInfo108, fld108Val);
  ...
}

...
private PDMFieldInfo fldInfo106;
private PDMFieldInfo fldInfo107;
private PDMFieldInfo fldInfo108;
...
public void setupPDM() {
  ...
  //Create information for a boolean, int32, and float field (all required)
  // as well as an optional int8 field
  ...
  //A required, fixed size array of 3 boolean elements
  fldInfo106 = defn.addFieldInfo(106, PDMFieldType.BOOLEAN_ARR, true, 3);
  //An optional, variable size array of int32 elements
  fldInfo107 = defn.addFieldInfo(107, PDMFieldType.INT32_ARR, false);
  //A required, fixed size array of 2 element which are each 5 character strings
  fldInfo108 = defn.addFieldInfo(108, PDMFieldType.FIX_STRING_ARR, 5, true, 2);
  ...
}

public void receiverUsePDM(byte[] buffer) {
  ...
  //Values to be retrieved from the message
  ...
  boolean fld106Val[];
  int fld107Val[];
  String fld108Val[];

  //Deserialize the bytes into a message
  msg.parse(buffer);

  //Get each field value from the message
  ...
  fld106Val = msg.getFieldValueAsBooleanArray(fldInfo106);
  if(msg.isFieldValueSet(fldInfo107)) {
    fld107Val = msg.getFieldValueAsInt32Array(fldInfo107);
  }

  fld108Val = msg.getFieldValueAsStringArray(fldInfo108);
}
</pre><p><b>Definition Included In Message</b></p>
<p>Optionally, a PDM message can also include the definition when it is serialized to bytes. This enables receivers to parse a PDM message without having pre-defined knowledge of the message, although including the definition with the message affects message size and performance of message deserialization. Notice that the setIncludeDefinition function is called with an argument of true for a source that serializes the definition as part of the message.</p>
<pre class="fragment">private PDMDefinition defn;
private PDMMessage msg;

public void setupPDM() {
  //Create the definition with 3 fields and using int field names
  defn = new PDMDefinition(3, true);
  ...

  //Finalize the definition and create the message
  defn.finalizeDef();
  msg = new PDMMessage(defn);

  //Set the flag to indicate that the definition should also be serialized
  msg.setIncludeDefinition(true);
}
...
</pre><p>For a receiver, the setupPDM function does not need to set any flags for the message but rather should define a message without a definition, since we assume the source provides the definition. If a definition is set for a message, it will attempt to use that definition instead of the definition on the incoming message (unless the ids are different).</p>
<pre class="fragment">private PDMDefinition defn;
private PDMMessage msg;

public void setupPDM() {
  //Don't define a definition

  //Create a message without a definition since the incoming message will have it
  msg = new PDMMessage();
}
...
</pre><p><b>The PDM Field Iterator</b></p>
<p>You can use the PDM Field Iterator to check all defined message fields to see if set, or to extract their values. You can extract a field value as an Object using this method, but due to the casting involved, we recommend you use the type specific get method to extract the exact value. Notice the use of field.isValueSet to check to see if the field value is set and the type specific get methods such as getBooleanValue and getFloatValue.</p>
<pre class="fragment">...

public void setupPDM() {
  //Create the definition with 3 fields and using int field names
  defn = new PDMDefinition(3, true);

  //Set the definition id and version
  defn.setId(1001);
  defn.setMsgVersMajor((byte)1);
  defn.setMsgVersMinor((byte)0);

  //Create information for a boolean, int32, and float field (all required)
  // as well as an optional int8 field
  fldInfo100 = defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
  fldInfo101 = defn.addFieldInfo(101, PDMFieldType.INT32, true);
  fldInfo102 = defn.addFieldInfo(102, PDMFieldType.FLOAT, true);
  fldInfo103 = defn.addFieldInfo(103, PDMFieldType.INT8, false);
  fldInfo104 = defn.addFieldInfo(104, PDMFieldType.FIX_STRING, 12, true);
  fldInfo105 = defn.addFieldInfo(105, PDMFieldType.STRING, true);
  //A required, fixed size array of 3 boolean elements
  fldInfo106 = defn.addFieldInfo(106, PDMFieldType.BOOLEAN_ARR, true, 3);
  //An optional, variable size array of int32 elements
  fldInfo107 = defn.addFieldInfo(107, PDMFieldType.INT32_ARR, false);
  //A required, fixed size array of 2 element which are each 5 character strings
  fldInfo108 = defn.addFieldInfo(108, PDMFieldType.FIX_STRING_ARR, 5, true, 2);

  //Finalize the definition and create the message
  defn.finalizeDef();
  msg = new PDMMessage(defn);
}

public void receiveAndIterateMessage(byte[] buffer) {
  msg.parse(buffer);
  PDMFieldIterator iterator = msg.createFieldIterator();
  PDMField field = null;
  while(iterator.hasNext()) {
    field = iterator.next();
    System.out.println("Field set? " +field.isValueSet());
    switch(field.getIntName()) {
      case 100:
        boolean val100 = field.getBooleanValue();
        System.out.println("Field 100's value is: " + val100);
        break;
      case 101:
        int val101 = field.getInt32Value();
        System.out.println("Field 101's value is: " + val101);
        break;
      case 102:
        float val102 = field.getFloatValue();
        System.out.println("Field 102's value is: " + val102);
        break;
      default:
        //Casting to object is possible but not recommended
        Object value = field.getValue();
        int name = field.getIntName();
        System.out.println("Field " + name + "'s value is: " + value);
        break;
    }
  }
}
</pre><p>Sample Output (106, 107, 108 are array objects as expected):</p>
<pre class="fragment">Field set? true
Field 100's value is: true
Field set? true
Field 101's value is: 7
Field set? true
Field 102's value is: 3.14
Field set? false
Field 103's value is: null
Field set? true
Field 104's value is: Hello World!
Field set? true
Field 105's value is: Variable
Field set? true
Field 106's value is: [Z@527736bd
Field set? true
Field 107's value is: [I@10aadc97
Field set? true
Field 108's value is: [Ljava.lang.String;@4178460d
</pre><p><b>Using the Definition Cache</b></p>
<p>The PDM Definition Cache assists with storing and looking up definitions by their id and version. In some scenarios, it may not be desirable to maintain the references to the message and the definition from a setup phase by the application. A source could optionally create the definition during the setup phase and store it in the definition cache. At a later point in time, it could retrieve the definition from the cache and use it to create the message without needing to maintain any references to the objects.</p>
<pre class="fragment">public void createAndStoreDefinition() {
  PDMDefinition myDefn = new PDMDefinition(3, true);
  //Set the definition id and version
  myDefn.setId(2001);
  myDefn.setMsgVersMajor((byte)1);
  myDefn.setMsgVersMinor((byte)0);

  //Create information for a boolean, int32, and float field (all required)
  myDefn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
  myDefn.addFieldInfo(101, PDMFieldType.INT32, true);
  myDefn.addFieldInfo(102, PDMFieldType.FLOAT, true);

  myDefn.finalizeDef();

  PDMDefinitionCache.getInstance().put(myDefn);
}

public void createMessageUsingCache() {
  PDMDefinition myFoundDefn = PDMDefinitionCache.getInstance().get(2001, 1, 0);
  if(myFoundDefn != null) {
    PDMMessage myMsg = new PDMMessage(myFoundDefn);
    //Get FieldInfo from defn and then set field values in myMsg
    //...
  }
}
</pre><p>A more advanced use of the PDM Definition Cache is by a receiver which may need to receive messages with different definitions and the definitions are not being included with the messages. The receiver can create the definitions in advance and then set a flag that allows automatic lookup into the definition cache when parsing a message (which is not on by default). Before receiving messages, the receiver should do something similar to createAndStoreDefinition (shown below) to set up definitions and put them in the definition cache. Then the flag to allow automatic lookup should be set as shown below in the call to setTryToLoadDefFromCache(true). This allows the PDMMessage to be created without a definition and still successfully parse a message by leveraging the definition cache.</p>
<pre class="fragment">public void createAndStoreDefinition() {
  PDMDefinition myDefn = new PDMDefinition(3, true);
  //Set the definition id and version
  myDefn.setId(2001);
  myDefn.setMsgVersMajor((byte)1);
  myDefn.setMsgVersMinor((byte)0);

  //Create information for a boolean, int32, and float field (all required)
  myDefn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
  myDefn.addFieldInfo(101, PDMFieldType.INT32, true);
  myDefn.addFieldInfo(102, PDMFieldType.FLOAT, true);

  myDefn.finalizeDef();
  PDMDefinitionCache.getInstance().put(myDefn);

  //Create and store other definitions
  //...
}

public void receiveKnownMessages(byte[] buffer) {
  PDMMessage myMsg = new PDMMessage();
  //Set the flag that enables messages to try
  // looking up the definition in the cache automatically
  // when parsing a byte buffer
  myMsg.setTryToLoadDefFromCache(true);
  myMsg.parse(buffer);

  if (myMsg.getDefinition().getId() == 2001
      &amp;&amp; myMsg.getDefinition().getMsgVersMajor() == 1
      &amp;&amp; myMsg.getDefinition().getMsgVersMinor() == 0) {
    PDMDefinition myDefn = PDMDefinitionCache.getInstance().get(2001, 1, 0);
    PDMFieldInfo fldInfo100 = myDefn.getFieldInfo(100);
    PDMFieldInfo fldInfo101 = myDefn.getFieldInfo(101);
    PDMFieldInfo fldInfo102 = myDefn.getFieldInfo(102);

    boolean fld100Val;
    int fld101Val;
    float fld102Val;

    //Get each field value from the message
    fld100Val = myMsg.getFieldValueAsBoolean(fldInfo100);
    fld101Val = myMsg.getFieldValueAsInt32(fldInfo101);
    fld102Val = myMsg.getFieldValueAsFloat(fldInfo102);

    System.out.println(fld100Val + " " + fld101Val + " " + fld102Val);
  }
}
</pre><p><br />
 </p>
<h3><a class="anchor" id="migratingfromsdm"></a>
Migrating from SDM</h3>
<p>Applications using SDM with a known set of message fields are good candidates for migrating from SDM to PDM. With SDM, the source typically adds fields to an SDM message without a definition. But, as shown above in the PDM examples, creating/adding a PDM definition before adding field values is fairly straightforward.</p>
<p>However, certain applications may be incapable of building a definition in advance due to the ad-hoc nature of their messaging needs, in which case a self-describing format like SDM may be preferred.</p>
<p><b>Simple Migration Example</b></p>
<p>The following source code shows a basic application that serializes and deserializes three fields using SDM and PDM. The setup method in both cases initializes the object instances so they can be reused by the source and receiver methods.</p>
<p>The goal of the sourceCreateMessageWith functions is to produce a byte array by setting field values in a message object. With SDM, actual Field classes are created, values are set, the Field classes are added to a</p>
<p>Fields class, and then the Fields class is added to the SDMessage. With PDM, FieldInfo objects are created during the setup phase and then used to set specific values in the PDMMessage.</p>
<p>The goal of the receiverParseMessageWith functions is to produce a message object by parsing the byte array and then extract the field values from the message. With SDM, the specific field is located and casted to the correct field class before getting the field value. With PDM, the appropriate getFieldValueAs function is called with the corresponding FieldInfo object created during the setup phase to extract the field value.</p>
<pre class="fragment">public class Migration {
  //SDM Variables
  private LBMSDMessage srcSDMMsg;
  private LBMSDMessage rcvSDMMsg;

  //PDM Variables
  private PDMDefinition defn;
  private PDMFieldInfo fldInfo100;
  private PDMFieldInfo fldInfo101;
  private PDMFieldInfo fldInfo102;
  private PDMMessage srcPDMMsg;
  private PDMMessage rcvPDMMsg;

  public static void main(String[] args) {
    Migration app = new Migration();
    System.out.println("Setting up PDM Definition and Message");
    app.setupPDM();
    System.out.println("Setting up SDM Messages");
    app.setupSDM();

    byte[] sdmBuffer;
    sdmBuffer = app.sourceCreateMessageWithSDM();
    app.receiverParseMessageWithSDM(sdmBuffer);

    byte[] pdmBuffer;
    pdmBuffer = app.sourceCreateMessageWithPDM();
    app.receiverParseMessageWithPDM(pdmBuffer);
  }

  public void setupSDM() {
    rcvSDMMsg = new LBMSDMessage();
    srcSDMMsg = new LBMSDMessage();
  }

  public void setupPDM() {
    //Create the definition with 3 fields and using int field names
    defn = new PDMDefinition(3, false);

    //Set the definition id and version
    defn.setId(1001);
    defn.setMsgVersMajor((byte)1);
    defn.setMsgVersMinor((byte)0);

    //Create information for a boolean, int32, and float field (all required)
    // as well as an optional int8 field
    fldInfo100 = defn.addFieldInfo("Field100", PDMFieldType.INT8, true);
    fldInfo101 = defn.addFieldInfo("Field101", PDMFieldType.INT16, true);
    fldInfo102 = defn.addFieldInfo("Field102", PDMFieldType.INT32, true);

    //Finalize the definition and create the message defn.finalizeDef();
    srcPDMMsg = new PDMMessage(defn);
    rcvPDMMsg = new PDMMessage(defn);
  }

  public byte[] sourceCreateMessageWithSDM() {
    byte[] buffer = null;

    LBMSDMField fld100 = new LBMSDMFieldInt8("Field100", (byte)0x42);
    LBMSDMField fld101 = new LBMSDMFieldInt16("Field101", (short)0x1ead);
    LBMSDMField fld102 = new LBMSDMFieldInt32("Field102", 12345);
    LBMSDMFields fset = new LBMSDMFields();

    try {
      fset.add(fld100);
      fset.add(fld101);
      fset.add(fld102);
    } catch (LBMSDMException e) {
      System.out.println ( e );
    }

    srcSDMMsg.set(fset);
    try {
      buffer = srcSDMMsg.data();
    } catch (IndexOutOfBoundsException e) {
      System.out.println ( "SDM Exception occurred during build of message:" );
      System.out.println ( e.toString() );
    } catch (LBMSDMException e) {
      System.out.println ( e.toString() );
    }
    return buffer;
  }

  public byte[] sourceCreateMessageWithPDM() {
    //Set each field value in the message
    srcPDMMsg.setFieldValue(fldInfo100, (byte)0x42);
    srcPDMMsg.setFieldValue(fldInfo101, (short)0x1ead);
    srcPDMMsg.setFieldValue(fldInfo102, 12345);

    //Serialize the message to bytes
    byte[] buffer = srcPDMMsg.toBytes();
    return buffer;
  }

  public void receiverParseMessageWithSDM(byte[] buffer) {
    //Values to be retrieved from the message byte fld100Val;
    short fld101Val;
    int fld102Val;

    //Deserialize the bytes into a message
    try {
      rcvSDMMsg.parse(buffer);
    } catch (LBMSDMException e) {
      System.out.println(e.toString());
    }

    LBMSDMField fld100 = rcvSDMMsg.locate("Field100");
    LBMSDMField fld101 = rcvSDMMsg.locate("Field101");
    LBMSDMField fld102 = rcvSDMMsg.locate("Field102");

    //Get each field value from the message
    fld100Val = ((LBMSDMFieldInt8)fld100).get();
    fld101Val = ((LBMSDMFieldInt16)fld101).get();
    fld102Val = ((LBMSDMFieldInt32)fld102).get();

    System.out.println("SDM Results: Field100=" + fld100Val +
                       ", Field101=" + fld101Val +
                       ", Field102=" + fld102Val);
  }

  public void receiverParseMessageWithPDM(byte[] buffer) {
    //Values to be retrieved from the message
    byte fld100Val;
    short fld101Val;
    int fld102Val;

    //Deserialize the bytes into a message
    rcvPDMMsg.parse(buffer);

    //Get each field value from the message
    fld100Val = rcvPDMMsg.getFieldValueAsInt8(fldInfo100);
    fld101Val = rcvPDMMsg.getFieldValueAsInt16(fldInfo101);
    fld102Val = rcvPDMMsg.getFieldValueAsInt32(fldInfo102);

    System.out.println("PDM Results: Field100=" + fld100Val +
                       ", Field101=" + fld101Val +
                       ", Field102=" + fld102Val);
  }
}
</pre><p>Notice that with sourceCreateMessageWithSDM function, the three fields (name and value) are created and added to the fset variable, which is then added to the SDM message. On the other hand, the sourceCreateMessageWithPDM function uses the FieldInfo object references to add the field values to the message for each of the three fields.</p>
<p>Also notice that the receiverParseMessageWithSDM requires a cast to the specific field class (like LBMSDMFieldInt8) once the field has been located. After the cast, calling the get method returns the expected value. On the other hand the receiverParseMessageWithPDM uses the FieldInfo object reference to directly retrieve the field value using the appropriate getFieldValueAs* method.</p>
<p><b>SDM Raw Classes</b></p>
<p>Several SDM classes with Raw in their name could be used as the value when creating an LBMSDMField. For example, an LBMSDMRawBlob instance could be created from a byte array and then that the LBMSDMRawBlob could be used as the value to a LBMSDMFieldBlob as shown in the following example.</p>
<pre class="fragment">byte[] blob = new byte[25];
LBMSDMRawBlob rawSDMBlob = new LBMSDMRawBlob(blob);
try {
  LBMSDMField fld103 = new LBMSDMFieldBlob("Field103",rawSDMBlob);
} catch (LBMSDMException e1) {
  System.out.println(e1);
}
</pre><p>The actual field named "Field103" is created in the try block using the rawSDMBlob variable which has been created to wrap the blob byte array. This field can be added to a LBMSDMFields object, which then uses it in a LBMSDMessage.</p>
<p>In PDM, there are no "Raw" classes that can be created. When setting the value for a field for a message, the appropriate variable type should be passed in as the value. For example, setting the field value for a BLOB field would mean simply passing the byte array directly in the setValue method as shown in the following code snippet since the field is defined as type BLOB.</p>
<pre class="fragment">private PDMFieldInfo fldInfo103;
public void setupPDM() {
  ...
  fldInfo103 = defn.addFieldInfo("Field103", PDMFieldType.BLOB, true);
  ...
  byte[] blob = new byte[25];

  srcPDMMsg.setFieldValue(fldInfo103, blob);
  ...
}
</pre><p>The PDM types of DECIMAL, TIMESTAMP, and MESSAGE expect a corresponding instance of PDMDecimal, PDMTimestamp, and PDMMessage as the field value when being set in the message so those types do require an instantiation instead of using a native Java type. For example, if "Field103" had been of type PDMFieldType.DECIMAL, the following code would be used to set the value.</p>
<pre class="fragment">PDMDecimal decimal = new PDMDecimal((long)2, (byte)32);
srcPDMMsg.setFieldValue(fldInfo103, decimal);
</pre><p><br />
 </p>
<h2><a class="anchor" id="sendingtosources"></a>
Sending to Sources</h2>
<p>There are many use cases where a subscriber application wants to send a message to a publisher application. For example, a client application which subscribes to market data may want to send a refresh request to the publishing feed handler. While this is possible to do with normal sources and receivers, UM supports a streamlined method of doing this.</p>
<p>As of UM version 6.10, a <a class="el" href="index.html#sourcestring">Source String</a> can be used as a destination for sending a unicast immediate message. The UM library will establish a TCP connection to the publisher's context via its <em>request port</em>. The publishing application can receive this message either from a normal <a class="el" href="index.html#receiverobject">Receiver Object</a>, or from a context immediate message callback via configuration options <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingoperation.html#immediatemessagetopicreceiverfunctioncontext">immediate_message_topic_receiver_function (context)</a> or <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingoperation.html#immediatemessagereceiverfunctioncontext">immediate_message_receiver_function (context)</a> (for topicless messages).</p>
<p><br />
 </p>
<h3><a class="anchor" id="sourcestringfromreceiveevent"></a>
Source String from Receive Event</h3>
<p>A receiving application's receiver callback function can obtain a source's source string from the message structure. However, that string is not suitable to being passed directly to the unicast immediate message send function.</p>
<p>Here's a code fragment in C for receiving a message from a source, and sending a message back to the originating source. For clarity, error detection and handling code is omitted.</p>
<pre class="fragment">int user_receiver_callback(lbm_rcv_t *rcv, lbm_msg_t *msg, void *clientd)
{
  ...
  switch (msg-&gt;type) {
    ...
  case LBM_MSG_DATA:
    /* user code which processes received message and sets up "msg_for_src" */
    ...
    /* A valid UIM destination is "SOURCE:" + source string. */
    char destination[LBM_MSG_MAX_SOURCE_LEN + 8];
    strcpy(destination, "SOURCE:");
    strcat(destination, msg-&gt;source);

    err = lbm_unicast_immediate_message(ctx, destination, NULL,   /* no topic */
                                       msg_for_src, sizeof(msg_for_src),
                                       LBM_SRC_NONBLOCK);  /* Called from context thread. */
    ...
  }  /* switch msg-&gt;type */
  ...
}  /* user_receiver_callback */
</pre><p>The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aaa7a945411e63884f12918417e8d117c">lbm_msg_t</a> structure supplies the source string, and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a497d77b133cea1547c3346fcba99872a">lbm_unicast_immediate_message()</a> is used to send a topicless immediate message to the source's context. Alternatively, a request message could be sent with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ae011c7a66e1db1f012d7f9633dbd321d">lbm_unicast_immediate_request()</a>. If the receive events are delivered without an event queue, then <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab8a470f02029480f179cc4872b7fa713">LBM_SRC_NONBLOCK</a> is needed.</p>
<p>The example above uses the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aa47eb604db7dc9fd53f9650ed940e058">LBM_MSG_DATA</a> message type. Most receiver event (message) types also contain a valid source string. Other likely candidates for this use case might be: <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab5489080adc7157549a9930b30c68425">LBM_MSG_BOS</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a88920e0a4188081f9a14fc8f76c18578">LBM_MSG_UNRECOVERABLE_LOSS</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a6629139aaf902976c8df9de3f37d10db">LBM_MSG_UNRECOVERABLE_LOSS_BURST</a>.</p>
<p>Note that in this example, a topicless message is sent. This requires the publishing application to use the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingoperation.html#immediatemessagereceiverfunctioncontext">immediate_message_receiver_function (context)</a> option to set up a callback for receipt of topicless immediate messages. Alternatively, a topic name can be supplied to the unicast immediate message function, in which case the publishing application would either create a normal <a class="el" href="index.html#receiverobject">Receiver Object</a> for that topic, or would configure a callback with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingoperation.html#immediatemessagetopicreceiverfunctioncontext">immediate_message_topic_receiver_function (context)</a>.</p>
<p>A Java program obtains the source string via <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/javaapi.tag:../../JavaAPI/" href="../../JavaAPI/classcom_1_1latencybusters_1_1lbm_1_1LBMMessage.html#a5691adf8b8b740c7813d2f8d605c394d">com::latencybusters::lbm::LBMMessage::source</a>, and sends topicless unicast immediate messages via <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/javaapi.tag:../../JavaAPI/" href="../../JavaAPI/classcom_1_1latencybusters_1_1lbm_1_1LBMContext.html#af565951d6e1b6b974c8ebd42bc0cfe16">com::latencybusters::lbm::LBMContext::sendTopicless</a>.</p>
<p>A .NET implementation is essentially the same as Java.</p>
<p><br />
 </p>
<h3><a class="anchor" id="sourcestringfromsourcenotificationfunction"></a>
Source String from Source Notification Function</h3>
<p>Some subscribing applications need to send a message to the publisher as soon as possible after the publisher is subscribed. Receiver events can sometimes take significant time to be delivered. The source string can be obtained via the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeliverycontrol.html#sourcenotificationfunctionreceiver">source_notification_function (receiver)</a> configuration option. This defines a callback function which is called at the start of the process of subscribing to a source.</p>
<p>Here's a code fragment in C for sending a message to a newly-discovered source. For clarity, error detection and handling code is omitted.</p>
<p>During initialization, when the receiver is defined, the callback must be configured using the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/structlbm__rcv__src__notification__func__t__stct.html">lbm_rcv_src_notification_func_t_stct</a> structure:</p>
<pre class="fragment">  lbm_rcv_src_notification_func_t src_notif_callback_info;
  src_notif_callback_info.create_func = src_notif_callback_create;  /* User function. */
  src_notif_callback_info.delete_func = src_notif_callback_delete;  /* User function. */
  src_notif_callback_info.clientd = NULL;   /* Can be user's receiver-specific state. */
  ...
  lbm_rcv_topic_attr_t *rcv_topic_attr;
  err = lbm_rcv_topic_attr_create(&amp;rcv_topic_attr);

  err = lbm_rcv_topic_attr_setopt(rcv_topic_attr, "source_notification_function",
                                 &amp;src_notif_callback_info, sizeof(src_notif_callback_info));

  lbm_topic_t *receiver_topic;
  err = lbm_rcv_topic_lookup(&amp;receiver_topic, ctx, receiver_topic_name, rcv_topic_attr);

  lbm_rcv_t *receiver;
  err = lbm_rcv_create(&amp;receiver, ctx, receiver_topic, ...);
</pre><p>This creates the <a class="el" href="index.html#receiverobject">Receiver Object</a> with the source notification callback configured. Note that the source notification callback has both a create and a delete function, to facilitate state management by the user.</p>
<pre class="fragment">void * src_notif_callback_create(const char *source_name, void *clientd)
{
  /* This function is called when the subscription is being set up. */

  /* user code which sets up "msg_for_src" */
  ...
  /* A valid UIM destination is "SOURCE:" + source string. */
  char destination[LBM_MSG_MAX_SOURCE_LEN + 8];
  strcpy(destination, "SOURCE:");
  strcat(destination, source_name);

  err = lbm_unicast_immediate_message(ctx, destination, NULL,   /* no topic */
                                     msg_for_src, sizeof(msg_for_src),
                                     LBM_SRC_NONBLOCK);  /* Called from context thread. */
  ...
  return NULL;  /* Can be per-source state. */
}  /* src_notif_callback_create */


int src_notif_callback_delete(const char *source_name, void *clientd, void *source_clientd) {
  /* This function not used for anything in this example, but could be used to
   * to clean up per-source state. */
  return 0;
}  /* src_notif_callback_delete */
</pre><p>A Java program configures the source notification callback via <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/javaapi.tag:../../JavaAPI/" href="../../JavaAPI/classcom_1_1latencybusters_1_1lbm_1_1LBMReceiverAttributes.html#ada8450c3e6c34d298256279418f026a4">com::latencybusters::lbm::LBMReceiverAttributes::setSourceNotificationCallbacks</a>.</p>
<p>A .NET implementation is essentially the same as Java.</p>
<p><br />
 </p>
<h3><a class="anchor" id="sendingtosourcereadiness"></a>
Sending to Source Readiness</h3>
<p>In most use cases for sending messages to a source, there is an implicit assumption that a subscribing receiver is fully set up and ready to receive messages from the publisher. However, due to the asynchronous nature of UM, there is no straight-forward way for a receiver to know the earliest point in time when messages sent by the source will be delivered to the receiver. For example, in a routed network (using the UM Router), a receiver might deliver BOS to the application, but that just means that the connection to the proper UM Router is complete. There could still be delays in the entire end-to-end path being able to deliver messages.</p>
<p>Also, be aware that although unicast immediate messages are delivered via TCP, these messages are not guaranteed. Especially in a routed network, there exists the possibility that a message will fail to reach the publisher.</p>
<p>In most cases, the immediate message is received by the publisher, and by the time the publisher reacts, the end-to-end source-to-receiver path is active. However, in the unlikely event that something goes wrong, a subscribing application should implement a timeout/retry mechanism. This advice is not specific to the "sending to source" use cases, and should be built into any kind of request/response-oriented use case.</p>
<p><br />
 </p>
<h2><a class="anchor" id="multicastimmediatemessaging"></a>
Multicast Immediate Messaging</h2>
<p>As an alternative to the normal, source-based UM messaging model, Multicast Immediate Messaging (MIM) offers advantages to short-lived topics and applications that cannot tolerate a delay between source creation and the sending of the first message. See the Knowledge Base article, Avoiding or Minimizing Delay Before Sending for background on this delay and other head-loss mitigation techniques.</p>
<p>Multicast Immediate Messaging avoids delay by eliminating the topic resolution process. MIM accomplishes this by:</p>
<ul>
<li>
Configuring transport information into sending and receiving applications. </li>
<li>
Including topic strings within each message. </li>
</ul>
<p>MIM is well-suited to applications where a small number of messages are sent to a topic. By eliminating topic resolution, MIM also reduces one of the causes of head-loss, defined as the loss of initial messages sent over a new transport session. Messages sent before topic resolution is complete will be lost.</p>
<p>MIM is typically not used for normal Streaming data because messages are somewhat less efficiently handled than source-based messages. Inefficiencies derive from larger message sizes due to the inclusion of the topic name, and on the receiving side, the MIM delivery controller hashing of topic names to find receivers, which consumes some extra CPU. If you have a high-message-rate stream, you should use a source-based method and not MIM. If head-loss is a concern and delay before sending is not feasible, then consider using late join (although this replaces head-loss with some head latency).</p>
<p>Note: Multicast Immediate Messaging can benefit from hardware acceleration. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportacceleration.html">Transport Acceleration Options</a> for more information</p>
<dl class="section note"><dt>Note</dt><dd>With the UMQ product, you cannot use MIM with Queuing.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="temporarytransportsession"></a>
Temporary Transport Session</h3>
<p>MIM uses the same reliable multicast algorithms as LBT-RM. When a sending application sends a message with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a24e5bff3a70e571bb12024af67b47cbb">lbm_multicast_immediate_message()</a>, MIM creates a temporary transport session. Note that no topic-level source object is created.</p>
<p>MIM automatically deletes the temporary transport session after a period of inactivity defined by <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingoperation.html#mimsrcdeletiontimeoutcontext">mim_src_deletion_timeout (context)</a> which defaults to 30 seconds. A subsequent send creates a new transport session. Due to the possibility of head-loss in the switch, it is recommended that sending applications use a long deletion timeout if they continue to use MIM after significant periods of inactivity.</p>
<p>MIM forces all topics across all sending applications to be concentrated onto a single multicast address to which ALL applications listen, even if they aren't interested in any of the topics. Thus, all topic filtering must happen in UM.</p>
<p>MIM can also be used to send an UM request message with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a54f3933e4dd154a9c7bb72598d0d9ef1">lbm_multicast_immediate_request()</a>. For example, an application can use MIM to request initialization information right when it starts up. MIM sends the response directly to the initializing application, avoiding the topic resolution delay inherent in the normal source-based <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ad4d06f66b8404684e191ca178e0cc09b">lbm_send_request()</a> function.</p>
<p><br />
 </p>
<h3><a class="anchor" id="mimnotifications"></a>
MIM Notifications</h3>
<p>MIM notifications differ in the following ways from normal UM source-based sending.</p>
<ul>
<li>
When a sending application's MIM transport session times out and is deleted, the receiving applications do not receive an EOS notification. </li>
<li>
Applications with a source notification callback are not informed of a MIM sender. Since source notification is basically a hook into the topic resolution system, this should not come as a surprise. </li>
<li>
MIM sending supports the non-blocking flag. However, it does not provide an LBM_SRC_EVENT_WAKEUP notification when the MIM session becomes writable again. </li>
<li>
MIM sends unrecoverable loss notifications to a context callback, not to a receiver callback. See <a class="el" href="index.html#losshandling">Loss Handling</a>. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="receivingimmediatemessages"></a>
Receiving Immediate Messages</h3>
<p>MIM does not require any special type of receiver. It uses the topic-based publish/subscribe model so an application must still create a receiver for a topic to receive MIM messages.</p>
<p>If needed, an application can send topic-less messages using MIM. A MIM sender passes in a NULL string instead of a topic name. The message goes out on the MIM multicast address and is received by all other receivers. A receiving application can use <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a374f135dddf7794130509f97b1e96cf8">lbm_context_rcv_immediate_msgs()</a> to set the callback procedure and delivery method for non-topic immediate messages.</p>
<p><br />
 </p>
<h3><a class="anchor" id="mimandwildcardreceivers"></a>
MIM and Wildcard Receivers</h3>
<p>When an application receives an immediate message, it's topic is hashed to see if there is at least one regular (non-wildcard) receiver object listening to the topic. If so, then MIM delivers the message data to the list of receivers.</p>
<p>However, if there are no regular receivers for that topic in the receive hash, MIM runs the message topic through all existing wildcard patterns and delivers matches to the appropriate wildcard receiver objects without creating sub-receivers. The next MIM message received for the same topic will again be run through all existing wildcard patterns. This can consume significant CPU resources since it is done on a per-message basis.</p>
<p><br />
 </p>
<h3><a class="anchor" id="losshandling"></a>
Loss Handling</h3>
<p>The receiving application can set up a context callback to be notified of MIM unrecoverable loss (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a7129f39b95974676e0ca74d88f58c498">lbm_mim_unrecloss_function_cb()</a>). It is not possible to do this notification on a topic basis because the receiving UM has no way of knowing which topics were affected by the loss.</p>
<p><br />
 </p>
<h3><a class="anchor" id="mimconfiguration"></a>
MIM Configuration</h3>
<p>As of UM 3.1, MIM supports ordered delivery. As of UM 3.3.2, the MIM configuration option, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingoperation.html#mimordereddeliverycontext">mim_ordered_delivery (context)</a> defaults to ordered delivery.</p>
<p>See the <a href="../../Config/index.html">UM Configuration Guide</a> for the descriptions of the MIM configuration options.</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingnetwork.html">Multicast Immediate Messaging Network Options</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingreliability.html">Multicast Immediate Messaging Reliability Options</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmulticastimmediatemessagingoperation.html">Multicast Immediate Messaging Operation Options</a> </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="mimexampleapplications"></a>
MIM Example Applications</h3>
<p>UM includes two example applications that illustrate MIM.</p>
<ul>
<li>
<p class="startli"><a href="../../example/lbmimsg.c">lbmimsg.c</a> - application that sends immediate messages as fast as it can to a given topic (single source). See also the Java example, <a href="../../java_example/lbmimsg.java">lbmimsg.java</a> and the .NET example, <a href="../../dotnet_example/lbmimsg.cs">lbmimsg.cs</a>.</p>
<p class="endli"></p>
</li>
<li>
<a href="../../example/lbmireq.c">lbmireq.c</a> - application that sends immediate requests to a given topic (single source) and waits for responses. </li>
</ul>
<p><b>lbmimsg.c</b></p>
<p>We can demonstrate the default operation of Immediate Messaging with lbmimsg and lbmrcv.</p>
<ol>
<li>
Run <b>lbmrcv -v topicName</b> </li>
<li>
Run <b>lbmimsg topicName</b> </li>
</ol>
<p>The lbmrcv output should resemble the following:</p>
<pre class="fragment">Immediate messaging target: TCP:10.29.1.78:14391
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][0], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][1], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][2], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][3], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][4], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][5], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][6], 25 bytes
</pre><p>Each line in the lbmrcv output is a message received, showing the topic name, transport type, receiver IP:Port, multicast address and message number.</p>
<p><b>lbmireq.c</b></p>
<p>Sending an UM request by MIM can be demonstrated with lbmireq and lbmrcv, which shows a single request being sent by lbmireq and received by lbmrcv. (lbmrcv sends no response.)</p>
<ol>
<li>
Run <b>lbmrcv -v topicName</b> </li>
<li>
Run <b>lbmireq topicName</b> </li>
</ol>
<p>The lbmrcv output should resemble the following:</p>
<pre class="fragment">$ lbmrcv -v topicName
Immediate messaging target: TCP:10.29.1.78:14391
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
[topicName][LBTRM:10.29.1.78:14390:92100885:224.10.10.21:14401][0],   Request
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
</pre><p>The lbmireq output should resemble the following:</p>
<pre class="fragment">$ lbmireq topicName
Using TCP port 4392 for responses
Sending 1 requests of size 25 bytes to target &lt;&gt; topic &lt;topicName&gt;
Sending request 0
Sent request 0. Pausing 5 seconds.
Done waiting for responses. 0 responses (0 bytes) received. Deleting request
Quitting...
Lingering for 5 seconds...
</pre><p><br />
 </p>
<h2><a class="anchor" id="spectrum"></a>
Spectrum</h2>
<p>UM Spectrum, which refers to a "spectrum of channels", allows the application designer to sub-divide a topic into any number of channels, which can be individually subscribed to by a receiving application. This provides an extra level of message filtering.</p>
<p>The sending application first allocates the desired number of source channel objects using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a73298f53aa9c5572cd0b1e68a4ec435a">lbm_src_channel_create()</a>. Then it creates a topic source in the normal way. Finally, the application sends messages using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a091b5806bf18d10ebd0d9117e0c70229">lbm_src_send_ex()</a>, specifying the source channel object in the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a21504de56612c7c6e4be655402b47a37">lbm_src_send_ex_info_t</a>'s channel_info field.</p>
<p>A receiving application first creates a topic receiver in the normal way. Then it subscribes to channels using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aa8304114445d291e6f16472d733ab250">lbm_rcv_subscribe_channel()</a> or lbm_wrcv_subscribe_channel(). Since each channel requires a different receiver callback, the receiver application can achieve more granular filtering of messages. Moreover, messages are received in-order across channels since all messages are part of the same topic stream.</p>
<p>You can accomplish the same level of filtering with a topic space design that creates separate topics for each channel, however, UM cannot guarantee the delivery of messages from multiple sources/topics in any particular order. Not only can UM Spectrum deliver the messages over many channels in the order they were sent by the source, but it also reduces topic resolution traffic since UM advertises only topics, not channels.</p>
<dl class="section note"><dt>Note</dt><dd>With the UMQ product, you cannot use UM Spectrum with Queuing.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="spectrumperformanceadvantages"></a>
Spectrum Performance Advantages</h3>
<p>The use of separate callbacks for different channels improves filtering and also relieves the source application of the task of including filtering information in the message data.</p>
<p>Java and .NET performance also receives a boost because messages not of interest can be discarded before they transition to the Java or .NET level.</p>
<p><br />
 </p>
<h3><a class="anchor" id="spectrumconfigurationoptions"></a>
Spectrum Configuration Options</h3>
<p>Spectrum's default behavior delivers messages on any channels the receiver has subscribed to on the callbacks specified when subscribing, and all other messages on the receiver's default callback. This behavior can be changed with the following configuration options.</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeliverycontrol.html#nullchannelbehaviorreceiver">null_channel_behavior (receiver)</a> - behavior for messages delivered with no channel information. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeliverycontrol.html#unrecognizedchannelbehaviorreceiver">unrecognized_channel_behavior (receiver)</a> - behavior for messages delivered with channel information but are on a channel for which the receiver has not registered interest. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpdeliverycontrol.html#channelmaptableszreceiver">channel_map_tablesz (receiver)</a> - controls the size of the table used by a receiver to store channel subscriptions. </li>
</ul>
<p><br />
 </p>
<h3><a class="anchor" id="smartsourcesandspectrum"></a>
Smart Sources and Spectrum</h3>
<p><a class="el" href="index.html#smartsources">Smart Sources</a> support Spectrum, but via different API functions. You need to tell UM that you intend to use spectrum at Smart Source creation time using the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpsmartsource.html#smartsrcenablespectrumchannelsource">smart_src_enable_spectrum_channel (source)</a> configuration option. This pre-allocates space in the message header for the spectrum channel.</p>
<p>With Smart Sources, there is no need to allocate a Spectrum source object with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a73298f53aa9c5572cd0b1e68a4ec435a">lbm_src_channel_create()</a>. Instead, you simply set the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a5aa5ef8cbf768dd5ad5bb8a709cf9d78">LBM_SSRC_SEND_EX_FLAG_CHANNEL</a> flag and the spectrum channel number in the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a33886eeac2e67170effea009d2dc3a35">lbm_ssrc_send_ex_info_t</a> passed to the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a2f50f56536778332e9f5712b06546425">lbm_ssrc_send_ex()</a> API function. For example:</p>
<pre class="fragment">  lbm_ssrc_send_ex_info_t ss_send_info;
  memset((char *)&amp;ss_send_info, 0, sizeof(ss_send_info));
  /* If this flag had been cleared previously, must set it. */
  ss_send_info.flags |= LBM_SSRC_SEND_EX_FLAG_CHANNEL;
  ss_send_info.channel = desired_channel_number;

  err = lbm_ssrc_send_ex(ss, msg_buff, msg_size, 0, &amp;ss_send_info);
</pre><p>When a Smart Source is created with Spectrum enabled, it is possible to send messages without a Spectrum channel, either by clearing the LBM_SSRC_SEND_EX_FLAG_CHANNEL flag in <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a33886eeac2e67170effea009d2dc3a35">lbm_ssrc_send_ex_info_t</a>, or by simply not supplying a <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a33886eeac2e67170effea009d2dc3a35">lbm_ssrc_send_ex_info_t</a> object by passing NULL for the <code>info</code> parameter. This suppresses all features enabled by that structure.</p>
<dl class="section note"><dt>Note</dt><dd>If using both Spectrum and <a class="el" href="index.html#messageproperties">Message Properties</a> with a single Smart Source, there is an added restriction: it is not possible to send a message omitting only one of those features. I.e. if both are enabled when the Smart Source is created, it is not possible to send a message with a message property and not a channel, and it is not possible to send a message with a channel and not a property. This is because the message header is defined at Smart Source creation, and the header either must contain both or neither.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="hotfailoverhf"></a>
Hot Failover (HF)</h2>
<p>UM Hot Failover (HF) lets you implement sender redundancy in your applications. You can create multiple HF senders in different UM contexts, or, for even greater resiliency, on separate machines. There is no hard limit to the number of HF sources, and different HF sources can use different transport types.</p>
<dl class="section note"><dt>Note</dt><dd>With the UMQ product, you cannot use Hot Failover with Queuing.</dd></dl>
<p>Hot Failover receivers filter out the duplicate messages and deliver one message to your application. Thus, sources can drop a few messages or even fail completely without causing message loss, as long as the HF receiver receives each message from at least one source.</p>
<p>The following diagram displays Hot Failover operation.</p>
<div class="image">
<img src="Hot_Failover.png" alt="Hot_Failover.png"/>
</div>
 <p>In the figure above, HF sources send copies of Message X. An HF receiver delivers the first copy of Message X it receives to the application, and discards subsequent copies coming from the other sources.</p>
<p><br />
 </p>
<h3><a class="anchor" id="implementinghotfailoversources"></a>
Implementing Hot Failover Sources</h3>
<p>You create Hot Failover sources with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ab5f6226d21dd4294bbad7d9f3e7c0bf6">lbm_hf_src_create()</a>. This returns a source object with internal state information that lets it send HF messages. You delete HF sources with the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a29d45db8f76835b4ae78f4568c25712f">lbm_src_delete()</a> function.</p>
<p>HF sources send HF messages via <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac515c1425d9b3f04f1e2cea5d66d3005">lbm_hf_src_send_ex()</a> or <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#acb6f42a8811cb998b4b19748b190f39b">lbm_hf_src_sendv_ex()</a>. These functions take a sequence number, supplied via the exinfo object, that HF receivers use to identify the same message sent from different HF sources. The exinfo has an hf_sequence_number, with a flag (LBM_SRC_SEND_EX_FLAG_HF_32 or LBM_SRC_SEND_EX_FLAG_HF_64) that identifies whether it's a 32- or 64-bit number. Each HF source sends the same message content for a given sequence number, which must be coordinated by your application.</p>
<p>If the source needs to restart its sequence number to an earlier value (e.g. start of day; not needed for normal wraparound), delete and re-create the source and receiver objects. Without re-creating the objects, the receiver sees the smaller sequence number, assumes the data are duplicate, and discards it. In (and only in) cases where this cannot be done, use <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a9f7ed3785938fcfd4771965d6430c4f2">lbm_hf_src_send_rcv_reset()</a>.</p>
<dl class="section note"><dt>Note</dt><dd>Your application must synchronize calling <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac515c1425d9b3f04f1e2cea5d66d3005">lbm_hf_src_send_ex()</a> or <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#acb6f42a8811cb998b4b19748b190f39b">lbm_hf_src_sendv_ex()</a> with all threads sending on the same source. (One symptom of not doing so is messages appearing at the receiver as inside intentional gaps and being erroneously discarded.)</dd></dl>
<p>Please be aware that non-HF receivers created for an HF topic receive multiple copies of each message. We recommend you establish local conventions regarding the use of HF sources, such as including "HF" in the topic name.</p>
<p>For an example source application, see <a href="../../example/lbmhfsrc.c">lbmhfsrc.c</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="implementinghotfailoverreceivers"></a>
Implementing Hot Failover Receivers</h3>
<p>You create HF receivers with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac208c246a6e856e24e1130060e1806c3">lbm_hf_rcv_create()</a>, and delete them using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#abc68152bcf4d18ef1d31d8f6a15ac080">lbm_hf_rcv_delete()</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a755bd1ee0a12622098b618cef46d254f">lbm_hf_rcv_delete_ex()</a>.</p>
<p>Incoming messages have an hf_sequence_number field containing the sequence number, and a message flag (LBM_MSG_FLAG_HF_32 or LBM_MSG_FLAG_HF_64) noting the bit size.</p>
<dl class="section note"><dt>Note</dt><dd>Previous UM versions used sequence_number for HF message identification. This field holds a 32-bit value and is still set for backwards compatibility, but if the HF sequence numbers are 64-bit lengths, this non-HF sequence number is set to 0. Also, you can retrieve the original (non-HF) topic sequence number via lbm_msg_retrieve_original_sequence_number() or, in Java and .NET, via LBMMessage.osqn().</dd></dl>
<p>For the maximum time period to recover lost messages, the HF receiver uses the minimum of the LBT-RM and LBT-RU NAK generation intervals (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmreliability.html#transportlbtrmnakgenerationintervalreceiver">transport_lbtrm_nak_generation_interval (receiver)</a>, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrureliability.html#transportlbtrunakgenerationintervalreceiver">transport_lbtru_nak_generation_interval (receiver)</a>). Each transport protocol is configured as normal, but the lost message recovery timer is the minimum of the two settings.</p>
<p>Some lbm_msg_t objects coming from HF receivers may be flagged as having "passed through" the HF receiver. This means that the message has not been ordered with other HF messages. These messages have the LBM_MSG_FLAG_HF_PASS_THROUGH flag set. UM flags messages sent from HF sources using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a> in this manner, as do all non-HF sources. Also, UM flags EOS, no source notification, and requests in this manner as well.</p>
<p>For an example receiver application, see <a href="../../example/lbmhfrcv.c">lbmhfrcv.c</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="implementinghotfailoverwildcardreceivers"></a>
Implementing Hot Failover Wildcard Receivers</h3>
<p>To create an HF wildcard receiver, set option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grphotfailoveroperation.html#hfreceiverwildcardreceiver">hf_receiver (wildcard_receiver)</a> to 1, then create a wildcard receiver with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a5b5d52f6b87499213757b73b09bc8160">lbm_wildcard_rcv_create()</a>. This actually creates individual HF receivers on a per-topic basis, so that each topic can have its own set of HF sequence numbers. Once the HF wildcard receiver detects that all sources for a particular topic are gone it closes the individual topic HF receivers and discards the HF sequence information (unlike a standard HF receiver). You can extend or control the delete timeout period of individual HF receivers with option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpwildcardreceiver.html#resolvernosourcelingertimeoutwildcardreceiver">resolver_no_source_linger_timeout (wildcard_receiver)</a>.</p>
<p><br />
 </p>
<h3><a class="anchor" id="javaandnet"></a>
Java and .NET</h3>
<p>For information on implement the HF feature in a Java application, go to UM Java API and see the documentation for classes <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/javaapi.tag:../../JavaAPI/" href="../../JavaAPI/classcom_1_1latencybusters_1_1lbm_1_1LBMHotFailoverReceiver.html">com::latencybusters::lbm::LBMHotFailoverReceiver</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/javaapi.tag:../../JavaAPI/" href="../../JavaAPI/classcom_1_1latencybusters_1_1lbm_1_1LBMHotFailoverSource.html">com::latencybusters::lbm::LBMHotFailoverSource</a>.</p>
<p>For information on implement the HF feature in a .NET application, go to UM .NET API and navigate to Namespaces-&gt;<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/javaapi.tag:../../JavaAPI/" href="../../JavaAPI/classcom_1_1latencybusters_1_1lbm_1_1LBM.html">com.latencybusters.lbm</a>-&gt;LBMHotFailoverReceiver and LBMHotFailoverSource.</p>
<p><br />
 </p>
<h3><a class="anchor" id="usinghotfailoverwithpersistence"></a>
Using Hot Failover with Persistence</h3>
<p>When implementing Hot Failover with Persistence, you must consider the following impact on hardware resources:</p>
<ul>
<li>
Additional storage space required for a Persistent Store </li>
<li>
Higher disk activity </li>
<li>
Higher network activity </li>
<li>
Increased application complexity regarding message filtering </li>
</ul>
<p>Also note that you must enable UME explicit ACKs and Hot Failover duplicate delivery in each Hot Failover receiving application.</p>
<p>For detailed information on using Hot Failover with Persistence, see the Knowledge Base article <a href="https://kb.informatica.com/faq/5/Pages/80173.aspx">FAQ: Is UMP compatible with Hot Failover?</a></p>
<p><br />
 </p>
<h3><a class="anchor" id="hotfailoverintentionalgapsupport"></a>
Hot Failover Intentional Gap Support</h3>
<p>UM supports intentional gaps in HF message streams. Your HF sources can supply message sequence numbers with number gaps up to 1073741824. HF receivers automatically detect the gaps and consider any missing message sequence numbers as not sent and do not attempt recovery for these missing sequence numbers. See the following example.</p>
<ol>
<li>
HF source 1 sends message sequence numbers: 10, 11, 12, 13, 25, 26, 38 </li>
<li>
HF source 2 sends message sequence numbers: 10, 11, 12, 13, 25, 26, 38 </li>
</ol>
<p>HF receiver 1 receives message sequence numbers in order with no pause between any messages: 10, 11, 12, 13, 25, 26, 38</p>
<p><br />
 </p>
<h3><a class="anchor" id="hotfailoveroptionalmessages"></a>
Hot Failover Optional Messages</h3>
<p>Hot Failover sources can send optional messages that HF receivers can be configured to receive or not receive (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grphotfailoveroperation.html#hfoptionalmessagesreceiver">hf_optional_messages (receiver)</a>). HF receivers detect an optional message by checking <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/structlbm__msg__t__stct.html#a9041a176f44dca95c3a5c6cc23d32d6c">lbm_msg_t.flags</a> for LBM_MSG_FLAG_HF_OPTIONAL. HF sources indicate an optional message by passing <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a5bf62d916b1acee97156dc8077ac3584">LBM_SRC_SEND_EX_FLAG_HF_OPTIONAL</a> in the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/structlbm__src__send__ex__info__t__stct.html#aa450a079510ebdc97b19625d10bd18ea">lbm_src_send_ex_info_t.flags</a> field to <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ac515c1425d9b3f04f1e2cea5d66d3005">lbm_hf_src_send_ex()</a> or <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#acb6f42a8811cb998b4b19748b190f39b">lbm_hf_src_sendv_ex()</a>. In the examples below, optional messages appear with an "o" after the sequence number.</p>
<ol>
<li>
HF source 1 sends message sequence numbers: 10, 11, 12, 13o, 14o, 15, 16o, 17o, 18o, 19o, 20 </li>
<li>
HF source 2 sends message sequence numbers: 10, 11, 12, 13o, 14o, 15, 16o, 17o, 18o, 19o, 20 </li>
</ol>
<p>HF receiver 1 receives: 10, 11, 12, 13o, 14o, 15, 16o, 17o, 18o, 19o, 20</p>
<p>HF receiver 2, configured to ignore optional messages, receives: 10, 11, 12, 15, 20</p>
<p><br />
 </p>
<h3><a class="anchor" id="usinghotfailoverwithordereddelivery"></a>
Using Hot Failover with Ordered Delivery</h3>
<p>An HF receiver takes some of its operating parameters directly from the receive topic attributes. The <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#ordereddeliveryreceiver">ordered_delivery (receiver)</a> setting indicates the ordering for the HF receiver.</p>
<dl class="section note"><dt>Note</dt><dd>UM supports Arrival Order with HF only when all sources use the same transport type.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="hotfailoveracrossmultiplecontexts"></a>
Hot Failover Across Multiple Contexts</h3>
<p>If you have a receiving application on a multi-homed machine receiving HF messages from HF sources, you can set up the Hot Failover Across Contexts (HFX) feature. This involves setting up a separate UM context to receive HF messages over each NIC and then creating an HFX Object, which drops duplicate HF messages arriving over all contexts. Your receiving application then receives only one copy of each HF message. The HFX feature achieves the same effect across multiple contexts as the normal Hot Failover feature does within a single context.</p>
<p>The following diagram displays Hot Failover operation across UM contexts.</p>
<div class="image">
<img src="Hot_Failover_X.png" alt="Hot_Failover_X.png"/>
</div>
 <p>For each context that receives HF messages, create one HFX Receiver per topic. Each HFX Receiver can be configured independently by passing in a UM Receiver attributes object during creation. A unique client data pointer can also be associated with each HFX Receiver. The HFX Object is a special Ultra Messaging object and does not live in any UM context.</p>
<p>Note: You never have to call lbm_topic_lookup() for a HFX Receiver. If you are creating HFX Receivers along with normal UM receivers for the same topic, do not interleave the calls. For example, call <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a82e9efbf70242d83ab287916ac497645">lbm_hfx_create()</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ae717b7b9923a6e4277ae9f7409983ffc">lbm_hfx_rcv_create()</a> for the topic. Then call lbm_topic_lookup() and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#aa7491c50fefbc2b70f8035fce7ac1477">lbm_rcv_create()</a> for the topic to create the normal UM receivers.</p>
<p>The following outlines the general procedure for HFX.</p>
<ol>
<li>
Create an HFX Object for every HF topic of interest with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a82e9efbf70242d83ab287916ac497645">lbm_hfx_create()</a>, passing in an attributes object created with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a0e904e14d61eee45af197c17f7e3dc08">lbm_hfx_attr_create()</a> to specify any attributes desired. </li>
<li>
Create a context for the first NIC receiving HF messages with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8058947690bd0995bc2c59d4a61b462f">lbm_context_create()</a>. </li>
<li>
Create a HFX Receiver for every HF topic with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#ae717b7b9923a6e4277ae9f7409983ffc">lbm_hfx_rcv_create()</a>, passing in UM Receive Topic Attributes. </li>
<li>
Repeat steps 2 and 3 for all NICs receiving HF message </li>
<li>
Receive messages. The HFX Object identifies and drops all duplicates, delivering messages through a single callback (and optional event queue) specified when you created the HFX Object. </li>
</ol>
<p>Delete each HFX Receiver with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a096626db73533d6c39b22765014485b7">lbm_hfx_rcv_delete()</a> or <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a08d8cbd7f47af1d7b2199c85ecf7c44c">lbm_hfx_rcv_delete_ex()</a>. Delete the HFX Object with <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#abc9924a0bd826db0c45a42d7199030b1">lbm_hfx_delete()</a>.</p>
<dl class="section note"><dt>Note</dt><dd>When writing source-side HF applications for HFX, be aware that HFX receivers do not support hf_sequence, 64-bit sequence numbers, the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a9f7ed3785938fcfd4771965d6430c4f2">lbm_hf_src_send_rcv_reset()</a> function, or HF wildcard receivers. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grphotfailoveroperation.html">Hot Failover Operation Options</a>, especially HFX-specific options.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="daemonstatistics"></a>
Daemon Statistics</h2>
<p>The Persistent Store daemon and the UM Router daemon each have a simple web server which provides operational information. This information is important for monitoring the operation and performance of these daemons. However, while the web-based presentation is convenient for manual, on-demand monitoring, it is not suitable for automated collection and recording of operational information for historical analysis.</p>
<p>Starting with UM version 6.11, a feature called "Daemon Statistics" has been added to the Store and Router daemons. This feature supports the background publishing of their operational information via UM messages. System designers can now subscribe to this information for their own automated monitoring systems.</p>
<p>While the information published by the Store and the Router daemons differ in their content, the general feature usage is the same between them. When the feature is configured, the daemon will periodically collect and publish its operational information.</p>
<p>The following sections give general information which is common across both daemons, followed by links to daemon-specific details.</p>
<p><br />
 </p>
<h3><a class="anchor" id="daemonstatisticsstructures"></a>
Daemon Statistics Structures</h3>
<p>The operational information is published as messages of different types sent over a normal UM topic source (topic name configurable). Each message is in the form of a binary, C-style data structure.</p>
<p>There are generally two categories of messages: <em>config</em> and <em>stat</em>. A given instance of a category config message does not have content which changes over time. An instance of a category stat message has content that does change over time. The daemon-specific documentation indicates which messages are in which category.</p>
<p>Each message type is configured for a publishing interval. However, config category messages are treated differently than stat. When the publishing interval for a given instance of a config message expires, the message is re-published unconditionally. These publishing intervals are typically set to long periods. However, when the publishing interval for a stat message expires, the message is checked to see if its content has materially changed since the last interval. If not, then the message is <em>not</em> republished. The publishing interval for a stat message is typically set to shorter periods to see those changes as they occur.</p>
<p>Finally, note that while the contents of a given instance of a config message does not change over time, new instances of the message type can be sent as a result of state changes in the store. For example, a new instance of <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/umedmonmsgs_8h.html#a3e3a1b935708cc8ac42cb70b0caf6808">umestore_repo_dmon_config_msg_t</a> is published each time a new source registers with the store.</p>
<p>More detailed information is available in the daemon-specific documentation referenced below.</p>
<p><br />
 </p>
<h3><a class="anchor" id="daemonstatisticsbinarydata"></a>
Daemon Statistics Binary Data</h3>
<p>The messages published are in binary form and map onto the C data structures defined for each message type.</p>
<p>The byte order of the structure fields is defined as the host endian architecture of the publishing daemon. Thus, if a monitoring host receiving the messages has the same endian architecture, the binary structures can be used directly. If the monitoring host has the opposite endian architecture, the receiver must byte-swap the fields.</p>
<p>The message structure is designed to make it possible for a monitoring application to detect a mismatch in endian architecture. Detection and byte swapping is demonstrated with daemon-specific example monitoring applications.</p>
<p>More detailed information is available in the daemon-specific documentation referenced below.</p>
<p><br />
 </p>
<h3><a class="anchor" id="daemonstatisticsversioning"></a>
Daemon Statistics Versioning</h3>
<p>Each message sent by the daemon consists of a standard header followed by a message-type-specific set of fields. The standard header contains a <code>version</code> field which identifies the version of the C include file used to build the daemon.</p>
<p>For example, the Store daemon is built with the include file <code><a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/umedmonmsgs_8h.html">umedmonmsgs.h</a></code>. With each daemon statistics message sent by the Store daemon, it sets the header version field to <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/umedmonmsgs_8h.html#af43ca32ea1917897c4ff1310d214c20b">LBM_UMESTORE_DMON_VERSION</a>. With each new release of the UM package, if that include file changes in a substantive way, the value of <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/umedmonmsgs_8h.html#af43ca32ea1917897c4ff1310d214c20b">LBM_UMESTORE_DMON_VERSION</a> is increased. In this way, a monitoring application can determine if it is receiving messages from a store daemon whose data structures match the monitoring application's structure definitions.</p>
<p>More detailed information is available in the daemon-specific documentation referenced below.</p>
<p><br />
 </p>
<h3><a class="anchor" id="daemonstatisticsrequests"></a>
Daemon Statistics Requests</h3>
<p>The daemon can optionally be configured to respond to requests to transmit information. The request might be sent by a monitoring application which has only just started running and needs a full snapshot of the operational information. The monitoring application sends a request to the daemon, and the daemon sends information messages in response. This is especially important for rarely-published message types, like those of the config category.</p>
<p>The request message is sent via standard UM <a class="el" href="index.html#requestresponse">Request/Response</a> messaging. The request message is formatted as an ASCII string, and is sent as a unicast immediate request message. The daemon reacts by parsing the request and sending a UM response with status information about the parse. If the request was parsed successfully, the daemon then publishes the requested daemon information in the normal way (over the configured topic). There are daemon-specific example applications which demonstrate the use of this request feature.</p>
<p>There is also an optional limited ability for the monitoring application to request modification of the configured settings for Daemon Statistics.</p>
<p>More detailed information is available in the daemon-specific documentation referenced below.</p>
<p><br />
 </p>
<h3><a class="anchor" id="daemonstatisticsdetails"></a>
Daemon Statistics Details</h3>
<p>For details on the Persistent Store's daemon statistics feature, see <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/ume.tag:../../UME/" href="../../UME/storedaemonstatistics.html">Store Daemon Statistics</a>.</p>
<p>For details on the UM Router's daemon statistics feature, see <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/gateway.tag:../../Gateway/" href="../../Gateway/umrouterdaemonstatistics.html">UM Router Daemon Statistics</a>.</p>
<p><br />
 </p>
<h1><a class="anchor" id="manpageforlbmrd"></a>
Manpage for lbmrd</h1>
<p>Help for the lbmrd command line can be obtained by entering "lbmrd -h". Help for the lbmrd configuration file can be obtained by entering "lbmrd -d".</p>
<p><br />
 </p>
<h2><a class="anchor" id="lbmrdcommandline"></a>
lbmrd Command Line</h2>
<pre class="fragment">lbmrd [options] [config-file]
  -a, --activity=IVL    interval between client activity checks (in milliseconds)(default 60000)
  -d, --dump-dtd        dump the configuration DTD to stdout and exit
  -h, --help            display this help and exit
  -i, --interface=ADDR  listen for unicast topic resolution messages on interface ADDR
  -L, --logfile=FILE    use FILE as the log file
  -p, --port=PORT       use UDP port PORT for topic resolution messages (default 15380)
  -t, --ttl=TTL         use client time-to-live of TTL seconds (default 60)
  -r, --rcv-buf=SIZE    set the receive buffer to SIZE bytes.
  -s, --snd-buf=SIZE    set the send buffer to SIZE bytes.
  -v, --validate        validate config-file then exit
</pre><dl class="section user"><dt><b>Description</b> </dt><dd>Resolver services for UM messaging products are provided by lbmrd. </dd></dl>
<dl class="section user"><dt></dt><dd>The <code>-i</code> and <code>-p</code> (or <code>--interface</code> and <code>--port</code>) options identify the network interface IP address and port that lbmrd opens to listen for unicast topic resolution traffic. The defaults are INADDR_ANY and 15380, respectively. Specified either as dotted numeric IP address, or DNS host name. </dd></dl>
<dl class="section user"><dt></dt><dd>The <code>-a</code> and <code>-t</code> (or <code>--activity</code> and <code>--ttl</code>) options interact to detect and remove "dead" clients, i.e., UMS/UME client applications that are in the lbmrd active client list, but have stopped sending topic resolution queries, advertisements, or keepalives, usually due to early termination or looping. These are described in detail below. </dd></dl>
<dl class="section user"><dt></dt><dd>Option <code>-t</code> describes the length of time (in seconds), during which no messages have been received from a given client, that will cause that client to be marked "dead" and removed from the active client list. Ultra Messaging recommends a value at least 5 seconds longer than the longest network outage you wish to tolerate. </dd></dl>
<dl class="section user"><dt></dt><dd>Option <code>-a</code> describes a repeating time interval (in milliseconds) after which lbmrd checks for these "dead" clients. Ultra Messaging recommends a value not larger than <code>-t</code> * 1000. </dd></dl>
<dl class="section user"><dt></dt><dd>Even clients that send no topic resolution advertisements or queries will still send keepalive messages to lbmrd every 5 seconds. This value is hard-coded and not configurable. </dd></dl>
<dl class="section user"><dt></dt><dd>The <code>-s</code> option sets the send socket buffer size in bytes. </dd></dl>
<dl class="section user"><dt></dt><dd>The <code>-r</code> option sets the receive socket buffer size in bytes. </dd></dl>
<dl class="section user"><dt></dt><dd>The output is written to a log file if either <code>-L</code> or <code>--logfile</code> is supplied. </dd></dl>
<dl class="section user"><dt></dt><dd>The DTD used to validate a configuration file will be dumped to standard output with the <code>-d</code> or <code>--dump-dtd</code> option. After dumping the DTD, lbmrd exits immediately. </dd></dl>
<dl class="section user"><dt></dt><dd><code>config-file</code> is the XML configuration file. It will be validated against the DTD if either the <code>-v</code> or <code>--validate</code> options are given. After attempting validation, lbmrd exits immediately. The exit status will be 0 for a configuration file validated by the DTD and non-zero otherwise. </dd></dl>
<dl class="section user"><dt></dt><dd>Command line help is available with <code>-h</code> or <code>--help</code>.</dd></dl>
<dl class="section user"><dt><b>Exit</b> <b>Status</b> </dt><dd>The exit status from lbmrd is 0 for success and some non-zero value for failure.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="lbmrdconfigurationfile"></a>
lbmrd Configuration File</h2>
<p>Here is the DTD for the lbmrd XML configuration file:</p>
<pre class="fragment">&lt;!ELEMENT lbmrd (daemon?, domains, transformations)&gt;
&lt;!ATTLIST lbmrd
          version (1.0) #REQUIRED
&gt;


&lt;!ELEMENT daemon (activity|interface|port|ttl|log|resolver_unicast_receiver_socket_buffer|resolver_unicast_send_socket_buffer)*&gt;

&lt;!ELEMENT activity (#PCDATA) &gt;
&lt;!ELEMENT interface (#PCDATA) &gt;
&lt;!ELEMENT port (#PCDATA) &gt;
&lt;!ELEMENT ttl (#PCDATA) &gt;
&lt;!ELEMENT log (#PCDATA) &gt;
&lt;!ELEMENT resolver_unicast_receiver_socket_buffer (#PCDATA) &gt;
&lt;!ELEMENT resolver_unicast_send_socket_buffer (#PCDATA) &gt;

&lt;!ELEMENT domains (domain+)&gt;
&lt;!ELEMENT domain (network+)&gt;
&lt;!ATTLIST domain name ID #REQUIRED&gt;
&lt;!ELEMENT network ( #PCDATA )&gt;
&lt;!ELEMENT transformations ( transform+ )&gt;
&lt;!ELEMENT transform ( rule+ )&gt;
&lt;!ATTLIST transform
          source IDREF #REQUIRED
          destination IDREF #REQUIRED
&gt;
&lt;!ELEMENT rule ( match, replace )&gt;
&lt;!ELEMENT match EMPTY&gt;
&lt;!ATTLIST match
          address CDATA #REQUIRED
          port CDATA "*"
&gt;
&lt;!ELEMENT replace EMPTY&gt;
&lt;!ATTLIST replace
          address CDATA #REQUIRED
          port CDATA "*"
&gt;</pre><dl class="section note"><dt>Note</dt><dd>The configuration file must contain a '<b>&lt;domains&gt;</b>' element and a '<b>&lt;transformations&gt;</b>' element (and their contents), even if there is no NAT. See <a class="el" href="index.html#dummylbmrdconfigurationfile">Dummy lbmrd Configuration File</a>. The '<b>&lt;daemon&gt;</b>' element and its contents are optional.</dd></dl>
<dl class="section user"><dt><b>&lt;lbmrd&gt;</b> <b>Element</b> </dt><dd>The '<b>&lt;lbmrd&gt;</b>' element is the root element. It requires a single attribute, version, which defines the version of the DTD to be used. Currently, only version 1.0 is supported.</dd></dl>
<dl class="section user"><dt><b>&lt;activity&gt;IVL&lt;/activity&gt;</b> </dt><dd>interval between client activity checks (in milliseconds)(default 60000)</dd></dl>
<dl class="section user"><dt><b>&lt;interface&gt;ADDR&lt;/interface&gt;</b> </dt><dd>listen for unicast topic resolution messages on interface ADDR</dd></dl>
<dl class="section user"><dt><b>&lt;port&gt;PORT&lt;/port&gt;</b> </dt><dd>use UDP port PORT for topic resolution messages (default 15380)</dd></dl>
<dl class="section user"><dt><b>&lt;ttl&gt;TTL&lt;/ttl&gt;</b> </dt><dd>use client time-to-live of TTL seconds (default 60)</dd></dl>
<dl class="section user"><dt><b>&lt;log&gt;FILE&lt;/log&gt;</b> </dt><dd>use FILE as the log file</dd></dl>
<dl class="section user"><dt><b>&lt;resolver_unicast_receiver_socket_buffer&gt;SIZE&lt;/resolver_unicast_receiver_socket_buffer&gt;</b> </dt><dd>set the receive socket buffer to SIZE bytes.</dd></dl>
<dl class="section user"><dt><b>&lt;resolver_unicast_send_socket_buffer&gt;SIZE&lt;/resolver_unicast_send_socket_buffer&gt;</b> </dt><dd>set the send socket buffer to SIZE bytes.</dd></dl>
<dl class="section user"><dt><b>&lt;domains&gt;</b> <b>Element</b> </dt><dd>The '<b>&lt;domains&gt;</b>' element defines the set of network domains. The '<b>&lt;domains&gt;</b>' element may contain one or more '<b>&lt;domain&gt;</b>' elements. Domains are used to help lbmrd recognize networks and/or subnetworks which connect via Network Address Translation (NAT). See <a class="el" href="index.html#networkaddresstranslationnat">Network Address Translation (NAT)</a> for more information on NAT.</dd></dl>
<dl class="section user"><dt><b>&lt;domain&gt;</b> <b>Element</b> </dt><dd>The '<b>&lt;domain&gt;</b>' element defines a single network domain. Each domain must be named via the <code>name</code> attribute. This name is referenced in '<b>&lt;transform&gt;</b>' elements, which are discussed below. Each domain name must be unique. The '<b>&lt;domain&gt;</b>' element may contain one or more '<b>&lt;network&gt;</b>' elements.</dd></dl>
<dl class="section user"><dt><b>&lt;network&gt;</b> <b>Element</b> </dt><dd>The '<b>&lt;network&gt;</b>' element defines a single network specification which is to be considered part of the enclosing '<b>&lt;domain&gt;</b>'. The network specification must contain either an IP address, or a network specification in <a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation">CIDR notation</a>. DNS host names are not supported in the lbmrd configuration file.</dd></dl>
<dl class="section user"><dt><b>&lt;transformations&gt;</b> <b>Element</b> </dt><dd>The '<b>&lt;transformations&gt;</b>' element defines and contains the set of transformations to be applied to the TIRs. The '<b>&lt;transformations&gt;</b>' element contains one or more '<b>&lt;transform&gt;</b>' elements, described below. Transformations are used to help lbmrd know how to modify source advertisements when Network Address Translation (NAT) is being used. See <a class="el" href="index.html#networkaddresstranslationnat">Network Address Translation (NAT)</a> for more information on NAT.</dd></dl>
<dl class="section user"><dt><b>&lt;transform&gt;</b> <b>Element</b> </dt><dd>The '<b>&lt;transform&gt;</b>' element defines a set of transformation tuples. Each tuple applies to a TIR sent from a specific network domain (specified using the <code>source</code> attribute), and destined for a specific network domain (specified using the <code>destination</code> attribute). The <code>source</code> and <code>destination</code> attributes must specify a network domain name as defined by the '<b>&lt;domain&gt;</b>' elements. The '<b>&lt;transform&gt;</b>' element contains one or more '<b>&lt;rule&gt;</b>' elements, described below.</dd></dl>
<dl class="section user"><dt><b>&lt;rule&gt;</b> <b>Element</b> </dt><dd>Each '<b>&lt;rule&gt;</b>' element is associated with the enclosing '<b>&lt;transform&gt;</b>' element, and completes the transformation tuple. The '<b>&lt;rule&gt;</b>' element must contain one '<b>&lt;match&gt;</b>' element, and one '<b>&lt;replace&gt;</b>' element, described below.</dd></dl>
<dl class="section user"><dt><b>&lt;match&gt;</b> <b>Element</b> </dt><dd>The '<b>&lt;match&gt;</b>' element defines the address and port to match within the TIR. The attributes <code>address</code> and <code>port</code> specify the address and port. <code>address</code> must specify a full IP address (a network specification is not permitted). <code>port</code> specifies the port in the TIR. To match any port, specify port="*" (which is the default). DNS host names are not supported in the lbmrd configuration file.</dd></dl>
<dl class="section user"><dt><b>&lt;replace&gt;</b> <b>Element</b> </dt><dd>The '<b>&lt;replace&gt;</b>' element defines the address and port which are to replace those matched in the TIR. The attributes <code>address</code> and <code>port</code> specify the address and port. <code>address</code> must specify a full IP address (a network specification is not permitted). To leave the TIR port unchanged, specify <code>port="*"</code> (which is the default). DNS host names are not supported in the lbmrd configuration file.</dd></dl>
<p><br />
 </p>
<h3><a class="anchor" id="dummylbmrdconfigurationfile"></a>
Dummy lbmrd Configuration File</h3>
<p>If no NAT is present, and it is desired to use the XML configuration file for it's '<b>&lt;daemon&gt;</b>' contents, a "dummy" NAT configuration should be used.</p>
<pre class="fragment">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
&lt;lbmrd version="1.0"&gt;
  &lt;daemon&gt;
    ...
  &lt;/daemon&gt;
  &lt;domains&gt;
    &lt;domain name="dummy"&gt;
      &lt;network&gt;0.0.0.0/32&lt;/network&gt;
    &lt;/domain&gt;
  &lt;/domains&gt;
  &lt;transformations&gt;
    &lt;transform source="dummy" destination="dummy"&gt;
      &lt;rule&gt;
        &lt;match address="0.0.0.0" port="0"/&gt;
        &lt;replace address="0.0.0.0" port="0"/&gt;
      &lt;/rule&gt;
    &lt;/transform&gt;
  &lt;/transformations&gt;
&lt;/lbmrd&gt;
</pre><p><br />
 </p>
<h1><a class="anchor" id="umglossary"></a>
UM Glossary</h1>
<p><br />
 </p>
<h2><a class="anchor" id="glossarya"></a>
Glossary A</h2>
<p><a class="anchor" id="glossaryabi"></a></p><dl class="section user"><dt><b>ABI</b> - Application Binary Interface</dt><dd>The execution-time interfaces presented by one software system, generally in the form of a dynamic (shared) library, for use by other software systems. ABIs are generally considered to be in the realm of binary, compiled code, not source code. Two releases are considered ABI compatible if the dynamic libraries can be used interchangeably by an application without the need to rebuild or relink that application. See also <a class="el" href="index.html#glossaryapi">API</a>.</dd></dl>
<p><a class="anchor" id="glossaryack"></a></p><dl class="section user"><dt><b>ACK</b> - Acknowledge</dt><dd>Generally, a control message which acknowledges some event or condition. Within the context of Ultra Messaging, it is often used to refer to a persistence control message sent by a subscriber to the Persistent Store to indicate that it has completed processing of a given data message. See <a class="el" href="index.html#persistence">Persistence</a>.</dd></dl>
<p><a class="anchor" id="glossaryace"></a></p><dl class="section user"><dt><b>ACE</b> - Access Control Entry</dt><dd>A filter specifier to control which topics are allowed to transit a UM Router portal. One or more ACEs make up an Access Control List (ACL). See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/gateway.tag:../../Gateway/" href="../../Gateway/umrouterimplementation.html#accesscontrollistsacl">Access Control Lists (ACL)</a>.</dd></dl>
<p><a class="anchor" id="glossaryacl"></a></p><dl class="section user"><dt><b>ACL</b> - Access Control List</dt><dd>A method used by the Dynamic Routing Option (DRO) to control which topics are allowed to transit a UM Router portal. An ACL consists of one or more Access Control Entries (ACE). See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/gateway.tag:../../Gateway/" href="../../Gateway/umrouterimplementation.html#accesscontrollistsacl">Access Control Lists (ACL)</a>.</dd></dl>
<p><a class="anchor" id="glossaryactivemq"></a></p><dl class="section user"><dt><b>ActiveMQ</b> </dt><dd>The name of an open-source JMS-oriented messaging system. The Ultra Messaging UMQ product contains an enhanced form of ActiveMQ to provide queuing semantics and a JMS API. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/umq.tag:../../UMQ/" href="../../UMQ/index.html#umqoverview">UMQ Overview</a>.</dd></dl>
<p><a class="anchor" id="glossaryamqp"></a></p><dl class="section user"><dt><b>AMQP</b> - Advanced Message Queuing Protocol</dt><dd>An open standard messaging wire protocol. See <a href="https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol">Wikipedia's writeup</a> for more information on AMQP. The UMQ product grouping makes use of AMQP to provide interoperability between Ultra Messaging and ActiveMQ. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/umq.tag:../../UMQ/" href="../../UMQ/index.html#umqoverview">UMQ Overview</a>.</dd></dl>
<p><a class="anchor" id="glossaryapi"></a></p><dl class="section user"><dt><b>API</b> - Application Programming Interface</dt><dd>The callable functions, classes, methods, data formats, and structures presented by one software system for use by other software systems. APIs are generally considered to be in the realm of source code, not compiled binaries. APIs are generally documented, and can be extended from one release to the next. Two releases are considered API compatible if the application can be built against either release interchangeably without the need to modify the source code. Ultra Messaging has APIs available for the C, Java, and .NET (C#) programming languages. For example, <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/api.tag:../../API/" href="../../API/lbm_8h.html#a8058947690bd0995bc2c59d4a61b462f">lbm_context_create()</a> is part of the C API. See also <a class="el" href="index.html#glossaryabi">ABI</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryb"></a>
Glossary B</h2>
<p><a class="anchor" id="glossarybos"></a></p><dl class="section user"><dt><b>BOS</b> - Beginning Of Stream</dt><dd>An event delivered to a receiver callback indicating that the link between the source and the receiver is now active. Be aware that in a deployment that includes the UM Router, it may only indicate an active link between the receiver and the local router portal, not necessarily full end-to-end connectivity. See also <a class="el" href="index.html#glossaryeos">EOS</a></dd></dl>
<p><a class="anchor" id="glossarybroker"></a></p><dl class="section user"><dt><b>Broker</b> </dt><dd>A daemon which mediates the exchange of messages. In the context of Ultra Messaging, it refers to the ActiveMQ daemon which implements the queuing functionality and JMS. See <a class="el" href="index.html#queuing">Queuing</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryc"></a>
Glossary C</h2>
<p><a class="anchor" id="glossarycidr"></a></p><dl class="section user"><dt><b>CIDR</b> - Classless Inter-Domain Routing</dt><dd>Generally, CIDR refers to the division of a 32-bit IPv4 address between network and host parts. In the context of Ultra Messaging, CIDR notation can be used to ease the specification of host network interfaces. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/generalconfigurationguidelines.html#specifyinginterfaces">Specifying Interfaces</a>.</dd></dl>
<p><a class="anchor" id="glossarycontext"></a></p><dl class="section user"><dt><b>Context</b> </dt><dd>Within the context of Ultra Messaging, a context is an object which functions conceptually as an environment in which UM runs. Context is often abbreviated as "ctx". See <a class="el" href="index.html#contextobject">Context Object</a>.</dd></dl>
<p><a class="anchor" id="glossaryctx"></a></p><dl class="section user"><dt><b>CTX</b> - Context</dt><dd>Within the context of Ultra Messaging, a context is an object which functions conceptually as an environment in which UM runs. See <a class="el" href="index.html#contextobject">Context Object</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryd"></a>
Glossary D</h2>
<p><a class="anchor" id="glossarydbl"></a></p><dl class="section user"><dt><b>DBL</b> - Datagram Bypass Layer</dt><dd>A kernel-bypass driver that accelerates sending and receiving UDP traffic and operates with Myricom 10-Gigabit Ethernet adapter cards for Linux and Windows. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportacceleration.html#myricomdatagrambypasslayerdbl">Myricom® Datagram Bypass Layer (DBL™)</a>.</dd></dl>
<p><a class="anchor" id="glossarydeliveryconfirmation"></a></p><dl class="section user"><dt><b>Delivery</b> Confirmation</dt><dd>An optional event generated by a persistent subscriber's receiver and delivered to a persistent publisher's source to indicate that the subscriber has completed processing of a message. See <a class="el" href="index.html#persistence">Persistence</a>.</dd></dl>
<p><a class="anchor" id="glossarydlq"></a></p><dl class="section user"><dt><b>DLQ</b> - Dead Letter Queue</dt><dd>With queuing, the Dead Letter Queue (DLQ) is a destination for messages that cannot be delivered to a receiver. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/umq.tag:../../UMQ/" href="../../UMQ/conceptsandfeatures.html#deadletterqueue">Dead Letter Queue</a>.</dd></dl>
<p><a class="anchor" id="glossarydro"></a></p><dl class="section user"><dt><b>DRO</b> - Dynamic Routing Option</dt><dd>The name of an Ultra Messaging option which provides routing of messages different Topic Resolution Domains (TRDs). See <a class="el" href="index.html#glossarydynamicroutingoptiondro">Dynamic Routing Option (DRO)</a>.</dd></dl>
<p><a class="anchor" id="glossarydynamicroutingoptiondro"></a></p><dl class="section user"><dt><b>Dynamic</b> Routing Option (DRO)</dt><dd>The name of an Ultra Messaging option which provides routing of messages different Topic Resolution Domains (TRDs). The option consists of a daemon called the "UM Router", or just the DRO. The UM Router is frequently used to span the bandwidth-limited links in a wide-area network due to the fact that it only passes messages for topics that are of interest. See <a class="el" href="index.html#umrouter">UM Router</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossarye"></a>
Glossary E</h2>
<p><a class="anchor" id="glossaryeos"></a></p><dl class="section user"><dt><b>EOS</b> - End Of Stream</dt><dd>An event delivered to a receiver callback indicating that the link between the source and the receiver is deleted. Be aware that in a deployment that includes the UM Router, it may only indicate a deleted link between the receiver and the local router portal, not necessarily a full end-to-end link. See also <a class="el" href="index.html#glossarybos">BOS</a></dd></dl>
<p><a class="anchor" id="glossaryeventqueue"></a></p><dl class="section user"><dt><b>Event</b> Queue</dt><dd>Within the context of Ultra Messaging, an event queue object is a serialization queue structure and execution thread for delivery of other objects' events. Event queue is often abbreviated as "evq". See <a class="el" href="index.html#eventqueueobject">Event Queue Object</a>.</dd></dl>
<p><a class="anchor" id="glossaryevq"></a></p><dl class="section user"><dt><b>EVQ</b> - Event Queue</dt><dd>Within the context of Ultra Messaging, an event queue object is a serialization queue structure and execution thread for delivery of other objects' events. See <a class="el" href="index.html#eventqueueobject">Event Queue Object</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryf"></a>
Glossary F</h2>
<p><a class="anchor" id="glossaryflightsize"></a></p><dl class="section user"><dt><b>Flight</b> Size</dt><dd>The number of messages that a persistent publisher can have outstanding that are not stable. A persistent publisher generally limits the number of unstable messages it can have outstanding, and may block further attempts to send until some outstanding messages become stable. See <a class="el" href="index.html#persistence">Persistence</a>. See also <a class="el" href="index.html#glossarystability">Stability</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryg"></a>
Glossary G</h2>
<p><a class="anchor" id="glossarygateway"></a></p><dl class="section user"><dt><b>Gateway</b> </dt><dd>An early version of a message router, replaced as of version 6.10 with the Dynamic Routing Option (DRO). See <a class="el" href="index.html#glossarydynamicroutingoptiondro">Dynamic Routing Option (DRO)</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryh"></a>
Glossary H</h2>
<p><a class="anchor" id="glossaryhf"></a></p><dl class="section user"><dt><b>HF</b> - Hot Failover</dt><dd>A form of redundancy in which multiple instances of a publisher send the same messages at the same time to subscribers, which select for application delivery the first copy received. If one publisher instance fails, the subscribers are able to continue operation receiving from the remaining publisher. See <a class="el" href="index.html#hotfailoverhf">Hot Failover (HF)</a>.</dd></dl>
<p><a class="anchor" id="glossaryhfx"></a></p><dl class="section user"><dt><b>HFX</b> - Hot Failover eXtended</dt><dd>An extended form of redundancy in which multiple instances of a publisher send the same messages at the same time to subscribers, which select for application delivery the first copy received. If one publisher instance fails, the subscribers are able to continue operation receiving from the remaining publisher. HFX extends HF by allowing the subscribers to maintain the receiver objects in separate contexts, which gives greater flexibility in having the traffic use different network paths. See <a class="el" href="index.html#hotfailoveracrossmultiplecontexts">Hot Failover Across Multiple Contexts</a>.</dd></dl>
<p><a class="anchor" id="glossaryhrt"></a></p><dl class="section user"><dt><b>HRT</b> - High Resolution Timestamp</dt><dd>A feature that leverages the hardware timestamping function of certain network interface cards to measure sub-microsecond times that packets are transmitted and received. See <a class="el" href="index.html#highresolutiontimestamps">High-resolution Timestamps</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryi"></a>
Glossary I</h2>
<p><a class="anchor" id="glossaryipc"></a></p><dl class="section user"><dt><b>IPC</b> - InterProcess Communication</dt><dd>Generally, the term simply refers to any of several mechanisms by which an operating system allows processes to communicate or share data. Within the context of Ultra Messaging, LBT-IPC specifically refers to the shared memory transport type. A source configured for LBT-IPC can only pass messages to receivers running on the same machine (or virtual machine). See <a class="el" href="index.html#transportlbtipc">Transport LBT-IPC</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryj"></a>
Glossary J</h2>
<p><a class="anchor" id="glossaryjms"></a></p><dl class="section user"><dt><b>JMS</b> - Java Message Service</dt><dd>A standardized API for Java applications to send and receive messages. Ultra Messaging's UMQ product allows limited interoperability between applications using UM and applications using JMS. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/umq.tag:../../UMQ/" href="../../UMQ/index.html#jms">JMS</a>.</dd></dl>
<p><a class="anchor" id="glossaryjni"></a></p><dl class="section user"><dt><b>JNI</b> - Java Native Interface</dt><dd>A method by which Java code can invoke code written in C.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryl"></a>
Glossary L</h2>
<p><a class="anchor" id="glossarylbm"></a></p><dl class="section user"><dt><b>LBM</b> - Latency Busters Messaging</dt><dd>An old name of the Ultra Messaging product line. Superseded by UM. "LBM" is sometimes used to refer to the streaming product grouping. That use is superseded by "UMS". The abbreviation "lbm" lives on in various parts of the UM API, and was kept for backwards compatibility.</dd></dl>
<p><a class="anchor" id="glossarylbt"></a></p><dl class="section user"><dt><b>LBT</b> - Latency Busters Transport</dt><dd>Usually used as a prefix for a specific transport type: LBT-RM, LBT-RU, LBT-IPC, and LBT-SMX. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grpmajoroptions.html#transportsource">transport (source)</a>.</dd></dl>
<p><a class="anchor" id="glossarylj"></a></p><dl class="section user"><dt><b>LJ</b> - Late Join</dt><dd>A function by which a subscriber can create a receiver for a topic, and is able to retrieve one or more messages sent to that topic prior to the receiver being created. See <a class="el" href="index.html#latejoin">Late Join</a>.</dd></dl>
<p><a class="anchor" id="glossarylji"></a></p><dl class="section user"><dt><b>LJIR</b> - Late Join Information Request</dt><dd>A type of control message sent by a receiver to a source to request an Late Join Information control message. See <a class="el" href="index.html#latejoin">Late Join</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossarym"></a>
Glossary M</h2>
<p><a class="anchor" id="glossarymim"></a></p><dl class="section user"><dt><b>MIM</b> - Multicast Immediate Message</dt><dd>Alternate send method which makes use of a pre-configured LBT-RM transport which is shared by all like-configured applications. The "immediate" means that messages may be sent to arbitrary topic names without the creation of source objects. See <a class="el" href="index.html#multicastimmediatemessaging">Multicast Immediate Messaging</a>. See also <a class="el" href="index.html#glossaryuim">glossaryuim</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryn"></a>
Glossary N</h2>
<p><a class="anchor" id="glossarynak"></a></p><dl class="section user"><dt><b>NAK</b> - Negative AcKnowledgement</dt><dd>A type of control message sent by a receiver using LBT-RM or LBT-RU transports. Sent when packet loss causes a sequence number gap in received messages, the NAKs specify which sequence numbers are missing and request retransmission. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmreliability.html">Transport LBT-RM Reliability Options</a>.</dd></dl>
<p><a class="anchor" id="glossaryncf"></a></p><dl class="section user"><dt><b>NCF</b> - NAK ConFirmation</dt><dd>A type of control message sent by a source using LBT-RM transport. The LBT-RM protocol requires a source send an NCF if it receives a NAK for which it is not willing to send a re-transmission. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmreliability.html#lbtrmsourceignoringnaksforefficiency">LBT-RM Source Ignoring NAKs for Efficiency</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryo"></a>
Glossary O</h2>
<p><a class="anchor" id="glossaryopenonload"></a></p><dl class="section user"><dt><b>Open</b> Onload</dt><dd>A kernel-bypass driver that accelerates sending and receiving UDP traffic and operates with Solarflare 10-Gigabit Ethernet adapter cards for Linux. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportacceleration.html#solarflareonload">Solarflare® Onload</a>.</dd></dl>
<p><a class="anchor" id="glossaryopenssl"></a></p><dl class="section user"><dt><b>OpenSSL</b> - Open Secure Sockets Layer</dt><dd>A library which provides encryption services. OpenSSL is used by Ultra Messaging's encryption feature. See <a href="https://www.openssl.org">https://www.openssl.org</a> for general information about OpenSSL. See <a class="el" href="index.html#encryptedtcp">Encrypted TCP</a> for information about Ultra Messaging's encryption feature.</dd></dl>
<p><a class="anchor" id="glossaryotid"></a></p><dl class="section user"><dt><b>OTID</b> - Originating Transport IDentifier</dt><dd>Control information which uniquely identifies a source object within a UM network. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/gateway.tag:../../Gateway/" href="../../Gateway/umrouterconcepts.html#moreaboutproxysourcesandreceivers">More About Proxy Sources and Receivers</a>.</dd></dl>
<p><a class="anchor" id="glossaryotr"></a></p><dl class="section user"><dt><b>OTR</b> - Off-Transport Recovery</dt><dd>A method by which are lost and are not recoverable by the source transport can be recovered by UIMs using a method similar to Late Join. See <a class="el" href="index.html#offtransportrecoveryotr">Off-Transport Recovery (OTR)</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryp"></a>
Glossary P</h2>
<p><a class="anchor" id="glossarypcre"></a></p><dl class="section user"><dt><b>PCRE</b> - Perl Compatible Regular Expressions</dt><dd>An open-source library which closely implements the Perl 5 regular expression language. UM uses PCRE for wildcard receiver pattern matching. See <a href="https://en.wikipedia.org/wiki/Perl_Compatible_Regular_Expressions">Wikipedia's writeup</a> for information on PCRE. See also <a class="el" href="index.html#umwildcardreceivers">UM Wildcard Receivers</a>.</dd></dl>
<p><a class="anchor" id="glossarypdm"></a></p><dl class="section user"><dt><b>PDM</b> - Pre-Defined Messages</dt><dd>A message encoding scheme based on integer field identifiers for structured messages can be assembled and sent by applications. Includes field types and performs data marshaling across different CPU architectures. See <a class="el" href="index.html#predefinedmessages">Pre-Defined Messages</a>. See also <a class="el" href="index.html#glossarysdm">SDM</a>.</dd></dl>
<p><a class="anchor" id="glossarypersistence"></a></p><dl class="section user"><dt><b>Persistence</b> </dt><dd>A form of messaging, sometimes called "guaranteed messaging", in which messages sent by a publisher are temporarily saved in non-volatile storage so that subscribers can recover missed messages under a variety of failure scenarios. See <a class="el" href="index.html#persistence">Persistence</a>.</dd></dl>
<p><a class="anchor" id="glossarypgm"></a></p><dl class="section user"><dt><b>PGM</b> - Pragmatic General Multicast</dt><dd>A standards-based protocol for reliable multicast. Ultra Messaging's "LBT-RM" protocol is inspired by PGM. See <a class="el" href="index.html#transportlbtrm">Transport LBT-RM</a> for a list of differences between LBT-RM and PGM..</dd></dl>
<p><a class="anchor" id="glossaryportal"></a></p><dl class="section user"><dt><b>Portal</b> </dt><dd>An interface to the UM Router. A UM Router portal can either be an endpoint portal (interfaces with a Topic Resolution Domain), or a peer portal (interfaces with another UM Router). See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/gateway.tag:../../Gateway/" href="../../Gateway/droarchitecture.html#umrouterportals">UM Router Portals</a>.</dd></dl>
<p><a class="anchor" id="glossaryptp"></a></p><dl class="section user"><dt><b>PTP</b> - Precision Time Protocol</dt><dd>A protocol used to synchronize clocks throughout a computer network. Used by some NICs to synchronize host clocks (e.g. Solarflare). See <a href="https://en.wikipedia.org/wiki/Precision_Time_Protocol">Wikipedia's writeup</a> for more information.</dd></dl>
<p><a class="anchor" id="glossarypubsub"></a></p><dl class="section user"><dt><b>Pub/Sub</b> - Publish / Subscribe</dt><dd>A model of messaging passing in which the publisher (sender) does not keep track of the subscribers (intended recipients) of messages. Instead, the messages carry metadata (topic name) in which the subscribers express interest, and the underlying messaging software forwards messages to the subscribers based on that interest.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryr"></a>
Glossary R</h2>
<p><a class="anchor" id="glossaryrcv"></a></p><dl class="section user"><dt><b>RCV</b> - Receiver</dt><dd>Within the context of Ultra Messaging, a receiver is an object used to subscribe to a topic. "Receiver" is sometimes used to refer generally to an entire subscribing application. See <a class="el" href="index.html#receiverobject">Receiver Object</a>. See also <a class="el" href="index.html#glossarywildcardreceiver">Wildcard Receiver</a>.</dd></dl>
<p><a class="anchor" id="glossaryreceiver"></a></p><dl class="section user"><dt><b>Receiver</b> </dt><dd>Within the context of Ultra Messaging, a receiver is an object used to subscribe to a topic. "Receiver" is sometimes used to refer generally to an entire subscribing application. Receiver is often abbreviated as "rcv". See <a class="el" href="index.html#receiverobject">Receiver Object</a>. See also <a class="el" href="index.html#glossarywildcardreceiver">Wildcard Receiver</a>.</dd></dl>
<p><a class="anchor" id="glossaryregistration"></a></p><dl class="section user"><dt><b>Registration</b> </dt><dd>When a publisher creates a persistent source, that source must register with the configured Persistent Stores before it can start sending messages. This registration prepares the Persistent Store and the source to cooperate in the transfer of persisted messages. Likewise, when a subscriber creates a persistent receiver, that receiver must register with the configured Persistent Stores before it can start receiving messages. See <a class="el" href="index.html#persistence">Persistence</a>.</dd></dl>
<p><a class="anchor" id="glossaryrm"></a></p><dl class="section user"><dt><b>RM</b> - Reliable Multicast</dt><dd>A shortening of "LBT-RM". The Ultra Messaging protocol and implementation in which user messages sent via Multicast UDP are monitored for loss, and retransmissions are arranged to recover loss. See <a class="el" href="index.html#transportlbtrm">Transport LBT-RM</a>.</dd></dl>
<p><a class="anchor" id="glossaryrpp"></a></p><dl class="section user"><dt><b>RPP</b> - Receiver-Paced Persistence.</dt><dd>A form of persistence in which a publisher can be blocked from sending if receivers are having trouble keeping up with the message rate. See <a class="el" href="index.html#persistence">Persistence</a>. See also <a class="el" href="index.html#glossaryspp">SPP</a>.</dd></dl>
<p><a class="anchor" id="glossaryrouter"></a></p><dl class="section user"><dt><b>Router</b> </dt><dd>Within the context of Ultra Messaging, "UM Router" generally refers to the daemon within the Dynamic Routing Option (DRO). See <a class="el" href="index.html#glossarydynamicroutingoptiondro">Dynamic Routing Option (DRO)</a>.</dd></dl>
<p><a class="anchor" id="glossaryrsa"></a></p><dl class="section user"><dt><b>RSA</b> - Rivest, Shamir, and Aleman</dt><dd>A public-key cryptosystem developed by Ron Rivest, Adi Shamir, and Leonard Adleman. Included in the OpenSSL library used by Ultra Messaging's encryption feature. See <a class="el" href="index.html#encryptedtcp">Encrypted TCP</a>.</dd></dl>
<p><a class="anchor" id="glossaryru"></a></p><dl class="section user"><dt><b>RU</b> - Reliable Unicast</dt><dd>A shortening of "LBT-RU". The Ultra Messaging protocol and implementation in which user messages sent via Unicast (point-to-point) UDP are monitored for loss, and retransmissions are arranged to recover loss. See <a class="el" href="index.html#transportlbtru">Transport LBT-RU</a>.</dd></dl>
<p><a class="anchor" id="glossaryrx"></a></p><dl class="section user"><dt><b>RX</b> - Re-transmission</dt><dd>Depending on the context, RX can either mean the messages retransmitted by the LBT-RM and LBT-RU transport protocols (e.g. in transport statistics), or it can mean the messages recovered via the Persistent Store or Late Join.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossarys"></a>
Glossary S</h2>
<p><a class="anchor" id="glossarysdm"></a></p><dl class="section user"><dt><b>SDM</b> - Self-Describing Messages</dt><dd>A message encoding scheme based on keyword-value pairs for structured messages can be assembled and sent by applications. Includes field types and performs data marshaling across different CPU architectures. See <a class="el" href="index.html#selfdescribingmessaging">Self Describing Messaging</a>. See also <a class="el" href="index.html#glossarypdm">PDM</a>.</dd></dl>
<p><a class="anchor" id="glossarysm"></a></p><dl class="section user"><dt><b>SM</b> - Session Message</dt><dd>A type of control message used by the LBT-RM protocol to keep a transport session alive. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportlbtrmoperation.html">Transport LBT-RM Operation Options</a>.</dd></dl>
<p><a class="anchor" id="glossarysnmp"></a></p><dl class="section user"><dt><b>SNMP</b> - Simple Network Management Protocol</dt><dd>A standardized protocol by which computers and network equipment can be monitored and managed from a central point (management station). SNMP is also the name of an Ultra Messaging option which makes UM application usage statistics available for monitoring by a standard SNMP management station.</dd></dl>
<p><a class="anchor" id="glossarysource"></a></p><dl class="section user"><dt><b>Source</b> </dt><dd>Within the context of Ultra Messaging, a source is an object used to send messages to a topic. "Source" is sometimes used to refer generally to an entire publishing application. Source is often abbreviated as "src". See <a class="el" href="index.html#sourceobject">Source Object</a>.</dd></dl>
<p><a class="anchor" id="glossaryspp"></a></p><dl class="section user"><dt><b>SPP</b> - Source-Paced Persistence.</dt><dd>A form of persistence in which a publisher is allowed to continue sending at its natural rate, even if one or more receivers are falling behind to the point that the message repository's oldest messages are overwritten, leading to unrecoverable loss. See <a class="el" href="index.html#persistence">Persistence</a>.</dd></dl>
<p><a class="anchor" id="glossarysrc"></a></p><dl class="section user"><dt><b>SRC</b> - Source</dt><dd>Within the context of Ultra Messaging, a source is an object used to send messages to a topic. "Source" is sometimes used to refer generally to an entire publishing application. See <a class="el" href="index.html#sourceobject">Source Object</a>.</dd></dl>
<p><a class="anchor" id="glossarysri"></a></p><dl class="section user"><dt><b>SRI</b> - Source Registration Information</dt><dd>A type of control message used to communicate persistence information between persistent publishers and subscribers. A subscriber of persistent messages needs an SRI to successfully register with a persistent store. See <a class="el" href="index.html#persistence">Persistence</a>.</dd></dl>
<p><a class="anchor" id="glossarystability"></a></p><dl class="section user"><dt><b>Stability</b> </dt><dd>The state that a persistent publisher's sent message has been successfully persisted in the Persistent Store. In the time between message transmission and message stability, the message is at risk of being lost. The term is also used to refer to the source event delivered to a publishing application to indicate a message's stability. See <a class="el" href="index.html#persistence">Persistence</a>. See also <a class="el" href="index.html#glossaryflightsize">Flight Size</a>.</dd></dl>
<p><a class="anchor" id="glossarystore"></a></p><dl class="section user"><dt><b>Store</b> </dt><dd>A shortening of "Persistent Store". An Ultra Messaging component which works with persistent sources and receivers to record messages, and also deliver previously-recorded messages for recovery. The UMP and UMQ product groupings include the Persistent Store; the UMS product grouping does not. See <a class="el" href="index.html#persistence">Persistence</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryt"></a>
Glossary T</h2>
<p><a class="anchor" id="glossarytir"></a></p><dl class="section user"><dt><b>TIR</b> - Topic Information Record</dt><dd>A type of topic resolution control message used by a source to advertise its details. Subscribers use TIRs to discover and connect to sources of interest. See <a class="el" href="index.html#topicresolutionoverview">Topic Resolution Overview</a>.</dd></dl>
<p><a class="anchor" id="glossarytqr"></a></p><dl class="section user"><dt><b>TQR</b> - Topic Query Record</dt><dd>A type of topic resolution control message used by a receiver to discover sources of interest. Publishers use TQRs to trigger the sending of TIRs. See <a class="el" href="index.html#topicresolutionoverview">Topic Resolution Overview</a>.</dd></dl>
<p><a class="anchor" id="glossarytr"></a></p><dl class="section user"><dt><b>TR</b> - Topic Resolution</dt><dd>The protocol used by Ultra Messaging components to exchange information about available topics and topic interest. See <a class="el" href="index.html#topicresolutionoverview">Topic Resolution Overview</a>. See also <a class="el" href="index.html#glossarytir">TIR</a> and <a class="el" href="index.html#glossarytqr">TQR</a>.</dd></dl>
<p><a class="anchor" id="glossarytransportsession"></a></p><dl class="section user"><dt><b>Transport</b> Session</dt><dd>A specific run-time instance of a transport type to carry application messages. The transport session can be thought of as a communications channel. As a publishing application creates sources, it maps those sources onto transport sessions. A transport session is fairly resource-intensive, so it is frequently the case that many sources are mapped to each transport session. See <a class="el" href="index.html#umtransports">UM Transports</a>.</dd></dl>
<p><a class="anchor" id="glossarytrd"></a></p><dl class="section user"><dt><b>TRD</b> - Topic Resolution Domain</dt><dd>A group of Ultra Messaging applications and UM components which communicate with each other directly, not through a UM Router. Specifically, it refers to those applications and components which directly exchange Topic Resolution control messages. Applications in different TRDs are not able to communicate with each other unless one or more UM Routers are used to interconnect the TRDs. See <a class="el" href="index.html#topicresolutionoverview">Topic Resolution Overview</a>.</dd></dl>
<p><a class="anchor" id="glossarytsni"></a></p><dl class="section user"><dt><b>TSNI</b> - Topic Sequence Number Information</dt><dd>A type of control message sent by a source to assist in the detection and recovery of certain types loss. See <a class="el" href="index.html#lossdetectionusingtsnis">Loss Detection Using TSNIs</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryu"></a>
Glossary U</h2>
<p><a class="anchor" id="glossaryuim"></a></p><dl class="section user"><dt><b>UIM</b> - Unicast Immediate Message</dt><dd>Alternate send method which makes use of pre-configured TCP transports. The "immediate" means that messages may be sent to arbitrary topic names without the creation of source objects. Sending a UIM bypasses Topic Resolution, so the calling application must specify the address information for the intended recipient. Because of this, the UIM feature is rarely used directly by user applications. However, Ultra Messaging uses UIMs internally for many of its control messages. See <a class="el" href="index.html#multicastimmediatemessaging">Multicast Immediate Messaging</a>. See also <a class="el" href="index.html#glossarymim">glossarymim</a>.</dd></dl>
<p><a class="anchor" id="glossaryulb"></a></p><dl class="section user"><dt><b>ULB</b> - Ultra Load Balance</dt><dd>A feature of the Ultra Messaging UMQ product grouping which provides a limited subset of queuing semantics without the use of a central message broker. ULB is generally used to provide high-speed load balancing of UM messages. In the Pub/Sub model, if multiple subscribers create receivers for the same topic, each subscriber will receive a copy of every message sent. In the Queuing model, the messages are <em>distributed</em> to the multiple subscribers, with each message only being acted on by one of those subscribers. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/umq.tag:../../UMQ/" href="../../UMQ/ultraloadbalancingulb.html">Ultra Load Balancing (ULB)</a>.</dd></dl>
<p><a class="anchor" id="glossaryum"></a></p><dl class="section user"><dt><b>UM</b> - Ultra Messaging</dt><dd>The name of the Informatica messaging middleware product line. UM is based on the pub/sub model of message passing, which allows the components of distributed applications to communicate. Note that Ultra Messaging is registered trademark of Informatica, LLC.</dd></dl>
<p><a class="anchor" id="glossaryumrouter"></a></p><dl class="section user"><dt><b>UM</b> Router</dt><dd>Within the context of Ultra Messaging, "UM Router" generally refers to the daemon within the Dynamic Routing Option (DRO). See <a class="el" href="index.html#glossarydynamicroutingoptiondro">Dynamic Routing Option (DRO)</a>.</dd></dl>
<p><a class="anchor" id="glossaryumcache"></a></p><dl class="section user"><dt><b>UMCache</b> - Ultra Messaging Cache</dt><dd>The name of an Ultra Messaging option which provides a limited degree of message storage and retrieval.</dd></dl>
<p><a class="anchor" id="glossaryumds"></a></p><dl class="section user"><dt><b>UMDS</b> - Ultra Messaging Desktop Services</dt><dd>The name of an Ultra Messaging option which consists of a server daemon and a set of client libraries which provides simplified access to an Ultra Messaging network.</dd></dl>
<p><a class="anchor" id="glossaryume"></a></p><dl class="section user"><dt><b>UME</b> - Ultra Messaging, Enterprise edition</dt><dd>An old name of the UMP product grouping. Superseded by UMP. The abbreviation "ume" lives on in various parts of the UM API, and was kept for backwards compatibility.</dd></dl>
<p><a class="anchor" id="glossaryumm"></a></p><dl class="section user"><dt><b>UMM</b> - Ultra Messaging Manager</dt><dd>A component of UM which allows users to centrally edit, store, and distribute configuration information to distributed applications. See the <a href="../../UMM/UM_Manager_Guide=en.pdf">UM Manager Guide</a>.</dd></dl>
<p><a class="anchor" id="glossaryump"></a></p><dl class="section user"><dt><b>UMP</b> - Ultra Messaging, Persistence edition</dt><dd>An Ultra Messaging product grouping which supports message streaming and persistence. The term is sometimes used to refer specifically to the persistence function. See <a class="el" href="index.html#persistence">Persistence</a>.</dd></dl>
<p><a class="anchor" id="glossaryumq"></a></p><dl class="section user"><dt><b>UMQ</b> - Ultra Messaging, Queuing edition</dt><dd>An Ultra Messaging product grouping which supports message streaming, persistence, and queuing. The term is sometimes used to refer specifically to the queuing function. See <a class="el" href="index.html#queuing">Queuing</a>.</dd></dl>
<p><a class="anchor" id="glossaryums"></a></p><dl class="section user"><dt><b>UMS</b> - Ultra Messaging, Streaming edition</dt><dd>An Ultra Messaging product grouping which supports message streaming. The term is sometimes used to refer specifically to the streaming function.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryv"></a>
Glossary V</h2>
<p><a class="anchor" id="glossaryvma"></a></p><dl class="section user"><dt><b>VMA</b> - Voltaire Messaging Accelerator</dt><dd>A kernel-bypass driver that accelerates sending and receiving UDP traffic and operates with Mellanox 10-Gigabit Ethernet and Infiniband adapter cards for Linux. (The software used to be owned by a company called Voltaire, which was acquired by Mellanox.) See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.1/rc/UMQ_6.11.1_RC1/doc/Design/config.tag:../../Config/" href="../../Config/grptransportacceleration.html#mellanoxudacceleration">UD Acceleration for Mellanox® Hardware Interfaces</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryw"></a>
Glossary W</h2>
<p><a class="anchor" id="glossarywildcardreceiver"></a></p><dl class="section user"><dt><b>Wildcard</b> Receiver</dt><dd>An object created by an application using the UM API to subscribe to a group of topics based on a Regular Expression pattern match. See <a class="el" href="index.html#umwildcardreceivers">UM Wildcard Receivers</a>. See also <a class="el" href="index.html#glossarypcre">PCRE</a>. See also <a class="el" href="index.html#glossaryreceiver">Receiver</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryx"></a>
Glossary X</h2>
<p><a class="anchor" id="glossaryxsp"></a></p><dl class="section user"><dt><b>XSP</b> - Transport Services Provider</dt><dd>An object created by a subscribing application to control the threading of message reception. See <a class="el" href="index.html#transportservicesproviderobject">Transport Services Provider Object</a>.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="glossaryz"></a>
Glossary Z</h2>
<p><a class="anchor" id="glossaryzod"></a></p><dl class="section user"><dt><b>ZOD</b> - Zero Object Delivery</dt><dd>Feature which allows a Java or .NET subscribers to have received messages delivered without per-message object creation. This is more efficient than creating objects with each received message, and also avoids garbage collection. See <a class="el" href="index.html#zeroobjectdeliverysource">Zero Object Delivery (Source)</a>. </dd></dl>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.11-->
</body>
</html>
