<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Concepts Guide: Fundamental Concepts</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="doxygen_manual.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Concepts Guide
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('fundamentalconcepts.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Fundamental Concepts </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Ultra Messaging is a software layer, supplied in the form of a dynamic library (shared object), which provides applications with message delivery functionality that adds considerable value to the basic networking services contained in the host operating system. The UMP and UMQ products also include a "Store" daemon that implements Persistence. The UMQ product also includes a "broker" daemon that implements Brokered Queuing.</p>
<p>See <a class="el" href="umglossary.html">UM Glossary</a> for Ultra Messaging terminology, abbreviations, and acronyms.</p>
<p>Ultra Messaging is supported on a variety of platforms. There are two general categories of supported platforms: </p><ul>
<li>
Core platforms: Linux, Windows, Solaris. These are built and shipped every release of UM. </li>
<li>
On-demand Platforms: AIX, HP-UX, Stratus (VOS), HP-NonStop (OSS), OpenVMS. These are only built and shipped by request from users. </li>
</ul>
<p>In addition, Darwin (Mac OS) is supported, primarily for development and test purposes. Production on Darwin is not recommended.</p>
<dl class="section note"><dt>Note</dt><dd>There are many different distributions of Linux and many different releases of all operating systems. Informatica does not certify UM on specific distributions or versions of operating systems. We do keep our test lab current and test on recent versions of the Core platforms. And we support users on the OS versions that they use in production. But we do not formally certify.</dd></dl>
<p>Applications access Ultra Messaging features through the Ultra Messaging Application Programming Interface (API). Ultra Messaging includes the following APIs: the UM C API, the UM Java API, and the UM .NET API. For details on these APIs, see: </p><ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/index.html#umcapi">UM C API</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/javaapi.tag:../JavaAPI/" href="../JavaAPI/index.html#umjavaapi">UM Java API</a> </li>
<li>
<a href="../DotNetAPI/index.html#umnetapi">UM .NET API</a> </li>
</ul>
<p>These APIs are very similar, and for the most part, this document concentrates on the C API. The translation from C functions to Java or .NET methods should be reasonably straightforward; see <a href="../QuickStart/index.html">Quick Start Guide</a> for sample applications in C, Java, and .NET. See also <a href="../example/index.html">C Example Source Code</a>, <a href="../java_example/index.html">Java Example Source Code</a>, and <a href="../dotnet_example/index.html">C# Example Source Code</a>.</p>
<p>The UMQ product also supports the JMS API via the ActiveMQ broker.</p>
<p>The UM product is highly configurable to allow optimization over a wide variety of use cases. See <a class="el" href="configurationintroduction.html">Configuration Introduction</a> for more information.</p>
<p>The three most important design goals of Ultra Messaging are to minimize message latency (the time that a given message spends "in transit"), maximize throughput, and ensure delivery of all messages under a wide variety of operational and failure scenarios. Ultra Messaging achieves these goals by not duplicating services provided by the underlying network whenever possible. Instead of implementing special messaging servers and daemons to receive and re-transmit messages, Ultra Messaging routes messages primarily with the network infrastructure at wire speed. Placing little or nothing in between the sender and receiver is an important and unique design principle of Ultra Messaging.</p>
<p>A UM application can function as a publisher (sometimes call a "source"), or a subscriber (sometimes called a "receiver"). A publishing application sends messages, and a subscribing application receives them. (It is also common for an application to function as both publisher and subscriber; we separate the concepts for organizational purposes.)</p>
<p><br />
 </p>
<h1><a class="anchor" id="messagingparadigms"></a>
Messaging Paradigms&nbsp;&nbsp;<small><a href="#messagingparadigms">&lt;-</a></small></h1>
<p>UM supports three basic messaging paradigms (sometimes called Quality Of Service, or QOS): </p><ul>
<li>
<a class="el" href="fundamentalconcepts.html#streaming">Streaming</a>. </li>
<li>
<a class="el" href="fundamentalconcepts.html#persistence">Persistence</a>. </li>
<li>
<a class="el" href="fundamentalconcepts.html#queuing">Queuing</a>. </li>
</ul>
<p>Sometimes people equate those paradigms with the UM product names "UMS", "UMP", and "UMQ". But this is not accurate. The UMP product supports both streaming and persistence. I.e. you can write streaming applications with UMP. The UMQ product supports streaming, persistence, and queuing. You can write streaming or persistent applications with UMQ.</p>
<p><br />
 </p>
<h2><a class="anchor" id="streaming"></a>
Streaming&nbsp;&nbsp;<small><a href="#streaming">&lt;-</a></small></h2>
<p>The UMS, UMP, and UMQ products support "Streaming" as their basic messaging paradigm. With Streaming, messages are sent directly from publisher to subscriber (no broker). A subscriber to a given topic joins the data stream of a publisher of that topic to receive messages. Messages sent during times that the subscriber is not joined are generally not available to the subscriber (live-only), although see <a class="el" href="fundamentalconcepts.html#latejoin">Late Join</a>.</p>
<p><br />
 </p>
<h2><a class="anchor" id="persistence"></a>
Persistence&nbsp;&nbsp;<small><a href="#persistence">&lt;-</a></small></h2>
<p>The UMP and UMQ products support <a class="el" href="fundamentalconcepts.html#streaming">Streaming</a> and Persistence messaging paradigms. Persistence, sometimes called "durable" or "guaranteed" messages, saves messages sent by a publisher in non-volatile storage so that subscribers can recover missed messages under a variety of failure scenarios. If multiple subscribers exist for the same topic, each subscriber will get all messages sent by the publisher.</p>
<p>Persistence includes a component known as the persistent Store, which provides stable storage (disk or memory) of message streams.</p>
<p>UM delivers persisted messages from publisher to subscriber with very low latency by using the same technology as <a class="el" href="fundamentalconcepts.html#streaming">Streaming</a>. This offers the functionality of durable subscriptions and confirmed message delivery.</p>
<p>(FYI - you will see references to "UME" in the configuration and APIs for persistence. "UME" is an earlier abbreviation for "UMP".)</p>
<p>For full details on UM Persistence, see the <a href="../UME/index.html">UM Guide for Persistence</a>.</p>
<p><br />
 </p>
<h2><a class="anchor" id="queuing"></a>
Queuing&nbsp;&nbsp;<small><a href="#queuing">&lt;-</a></small></h2>
<p>The UMQ product supports <a class="el" href="fundamentalconcepts.html#streaming">Streaming</a>, <a class="el" href="fundamentalconcepts.html#persistence">Persistence</a>, and Queuing messaging paradigms. Queuing supports "load balancing" whereby published messages can be distributed across a set of subscribers such each message is only handled by one of the subscribers.</p>
<p>UMQ supports both Brokered queuing (where the Queue is a separate component which can store messages independent of the source and receiver), and Ultra Load Balancing (ULB), where the Queue is memory-based and resides in the source.</p>
<p>For full details on UM Queuing, see the <a href="../UMQ/index.html">UM Guide to Queuing</a>.</p>
<p><br />
 </p>
<h1><a class="anchor" id="messages"></a>
Messages&nbsp;&nbsp;<small><a href="#messages">&lt;-</a></small></h1>
<p>The primary function of UM is to transport application messages from a publisher to one or more subscribers. For the purposes of UM, a message is a sequence of bytes, the parsing and interpretation of which is the responsibility of the application.</p>
<p>Since UM does not parse or interpret the messages, UM cannot reformat messages for architectural differences in a heterogeneous environment. For example, UM does not do byte-swapping between big and little endian CPUs.</p>
<p>However, there are some specific exceptions to this rule: </p><ul>
<li>
The <a class="el" href="umfeatures.html#selfdescribingmessaging">Self Describing Messaging</a> feature is a separate library that allows the construction and parsing of structured messages as arbitrary name/value pairs. </li>
<li>
The <a class="el" href="umfeatures.html#predefinedmessages">Pre-Defined Messages</a> feature is another separate library that allows the construction and parsing of structured messages. </li>
<li>
The <a class="el" href="umfeatures.html#messageproperties">Message Properties</a> feature allows the setting of structured metadata which is sent along with an application message. </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="messageintegrity"></a>
Message Integrity&nbsp;&nbsp;<small><a href="#messageintegrity">&lt;-</a></small></h2>
<p>To minimize latency and CPU overhead, UM relies on the Operating System and the Network equipment to ensure the integrity of message data. That is, UM does not add a checksum or digital signature to detect message corruption. Modern network hardware implements very reliable CRCs.</p>
<p>However, we have encountered a case of a microwave-based link that apparently did not use a strong error detection method. This user reported occasional packet corruptions.</p>
<p>We also encountered a situation where an Operating System and a network interface card were configured in an unusual way which led to reproducible undetected packet corruption.</p>
<p>Users who wish to reduce the possibility of message corruption to near-zero will want to implement some sort of message checksum or digital signature outside of UM. (<a class="el" href="umfeatures.html#messageproperties">Message Properties</a> could be used to carry the checksum or signature.)</p>
<p><br />
 </p>
<h2><a class="anchor" id="messagemetadata"></a>
Message Metadata&nbsp;&nbsp;<small><a href="#messagemetadata">&lt;-</a></small></h2>
<p>It is sometimes useful for applications to send a message with additional metadata associated with the message. This metadata could be simply added to the message itself, but it is sometimes preferred that the metadata be separated from the message data.</p>
<p>For example, some organizations wrap UM in their own messaging middleware layer that provides a rich set of domain-specific functionality to their applications. This domain-specific functionality allows applications to be written more easily and quickly. However, that layer may need to add its own state-maintenance information which is independent from the application's message data. This middleware data can be supplied either as metadata attached to the message, or as separate non-application messages which are tagged with metadata. (The latter approach is often preferred when application messages must be sent with the minimum possible latency and overhead; adding metadata to a message adds processing overhead, so sending application messages without metadata is the most efficient.)</p>
<p>There are two different UM features that allow adding metadata to messages: </p><ul>
<li>
<a class="el" href="umfeatures.html#messageproperties">Message Properties</a> - a general system of typed name/value pairs. </li>
<li>
<a class="el" href="umfeatures.html#applicationheaders">Application Headers</a> - an older (deprecated) system of attaching small binary values. </li>
</ul>
<p>Informatica generally recommends the use of Message Properties over Application headers.</p>
<p><br />
 </p>
<h1><a class="anchor" id="topicstructureandmanagement"></a>
Topic Structure and Management&nbsp;&nbsp;<small><a href="#topicstructureandmanagement">&lt;-</a></small></h1>
<p>UM offers the Publish/Subscribe model for messaging ("Pub/Sub"), whereby one or more receiver programs express interest in a topic ("subscribe"), and one or more source programs send to that topic ("publish"). So, a topic can be thought of as a data stream that can have multiple producers and multiple consumers. One of the functions of the messaging layer is to make sure that all messages sent to a given topic are distributed to all receivers listening to that topic. So another way of thinking of a topic is as a generalized destination identifier - a message is sent "to" a topic, and all subscribers receive it. UM accomplishes this through an automatic process known as topic resolution.</p>
<p>(There is an exception to this Publish/Subscribe model; see <a class="el" href="fundamentalconcepts.html#immediatemessaging">Immediate Messaging</a>.)</p>
<p>A topic is just an arbitrary string. For example:</p>
<pre class="fragment">Orders
Market/US/DJIA/Sym1
</pre><p>It is not unusual for an application system to have many thousands of topics, perhaps even more than a million, with each one carrying a very specific range of information (e.g. quotes for a single stock symbol).</p>
<p>It is also possible to configure receiving programs to match multiple topics using wildcards. UM uses powerful regular expression pattern matching to allow applications to match topics in a very flexible way. Messages cannot be <em>sent</em> to wildcarded topic names. See <a class="el" href="umobjects.html#umwildcardreceivers">UM Wildcard Receivers</a>.</p>
<p><br />
 </p>
<h2><a class="anchor" id="messageordering"></a>
Message Ordering&nbsp;&nbsp;<small><a href="#messageordering">&lt;-</a></small></h2>
<p>UM normally ensures that received messages are delivered to the application in the same order as they were sent. However, this only applies to a specific topic from a single publisher. UM does not guarantee to retain order across different topics, even if those topics are carried on the same <a class="el" href="fundamentalconcepts.html#transportsessions">Transport Session</a>. It also does not guarantee order within the same topic across different publishers. For users that need to retain order between different topics from a single publisher, see <a class="el" href="umfeatures.html#spectrum">Spectrum</a>.</p>
<p>Alternatively, it is possible to enforce cross-topic ordering in a very restrictive use case: </p><ul>
<li>
The topics are from a single publisher (context), </li>
<li>
The topics are mapped to the same <a class="el" href="fundamentalconcepts.html#transportsessions">transport session</a>, </li>
<li>
The Transport Session is configured for <a class="el" href="transporttypes.html#transporttcp">TCP</a> (receiver-paced), <a class="el" href="transporttypes.html#transportlbtipc">IPC</a> (receiver-paced), or <a class="el" href="transporttypes.html#transportlbtsmx">SMX</a>, </li>
<li>
The subscriber is in the same <a class="el" href="fundamentalconcepts.html#topicresolutiondomain">Topic Resolution Domain</a> (TRD) as the publisher (no DRO in the data path), </li>
<li>
The messages being received are "live" - i.e. not being recovered from <a class="el" href="fundamentalconcepts.html#latejoin">Late Join</a>, <a class="el" href="umfeatures.html#offtransportrecoveryotr">OTR</a>, or Persistence, </li>
<li>
The subscriber is not participating in Queuing, </li>
<li>
The subscriber is not using <a class="el" href="umfeatures.html#hotfailoverhf">Hot Failover (HF)</a>. </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="topicresolutionoverview"></a>
Topic Resolution Overview&nbsp;&nbsp;<small><a href="#topicresolutionoverview">&lt;-</a></small></h2>
<p>Topic Resolution ("TR") is a set of protocols and algorithms used internally by Ultra Messaging to establish and maintain shared state. Here are the basic functions of TR:</p>
<ul>
<li>
Receiver discovery of sources. </li>
<li>
DRO routing information distribution. </li>
<li>
Persistent Store name resolution. </li>
<li>
Fault tolerance. </li>
</ul>
<p>For more information, see <a class="el" href="topicresolutiondescription.html">Topic Resolution Description</a>.</p>
<p><br />
 </p>
<h2><a class="anchor" id="topicresolutiondomain"></a>
Topic Resolution Domain&nbsp;&nbsp;<small><a href="#topicresolutiondomain">&lt;-</a></small></h2>
<p>A "Topic Resolution Domain" (TRD) is a set of applications and UM components which share the same Topic Resolution configuration and therefore participate in the TR protocols with each other. The key characteristic of a TRD is that all UM instances communicate directly with each other.</p>
<p>In small deployments of UM, a single TRD is all that is needed.</p>
<p>For larger deployments, especially deployments that are geographically separated with bandwidth-limited WAN links, the deployment is usually divided into multiple TRDs. Each TRD uses a different TR configuration, such that the applications in one TRD don't communicate directly applications in another TRD. The DRO is used to interconnect TRDs and provide connectivity between TRDs.</p>
<p>For more information, see <a class="el" href="topicresolutiondescription.html">Topic Resolution Description</a>.</p>
<p><br />
 </p>
<h1><a class="anchor" id="messagingreliability"></a>
Messaging Reliability&nbsp;&nbsp;<small><a href="#messagingreliability">&lt;-</a></small></h1>
<p>Users of a messaging system expect every sent message to be successfully received and processed by the appropriately subscribed receivers with the lowest possible latency, 100% of the time. However, this would require perfect networks and computers that can handle unlimited load at infinite speed with complete reliability. Real world networks, computers, and software systems have limitations and are subject to overload and failure, which can lead to message loss.</p>
<p>One job of a messaging system is to detect lost messages and take additional steps to arrange their successful recovery. But again, the limits of hardware and software robustness can make 100% reliability impractical. Part of UM's power is to give the user tools to make intelligent trade-offs between reliability and other important factors, like memory consumption, delivery latencies, hardware redundancies, etc.</p>
<p><br />
 </p>
<h2><a class="anchor" id="unrecoverableloss1"></a>
Unrecoverable Loss&nbsp;&nbsp;<small><a href="#unrecoverableloss1">&lt;-</a></small></h2>
<p>There are two important concepts when talking about loss: </p><ul>
<li>
Simple Loss - usually a case of lost packets due to an overloaded component. UM can be configured in a variety of ways to recover simple loss. </li>
<li>
Unrecoverable Loss - usually a case where a user-configured constraint has been exceeded and the messaging system has to give up trying to recover the lost data. </li>
</ul>
<p>Simple loss is undesirable, even if the messaging system is able to recover the loss. Any recovery mechanism adds delay to the ultimate delivery of the message, and most uses have limits on the amount of time they are willing to wait for recovery. For example, consider a network hardware outage that takes 10 minutes to repair. A user might have a 5 minutes limit on the age of a message. Thus, the user would like messages sent during the first 5 minutes of the 10-minute outage to simply be declare unrecoverable. Messages sent during the last 5 minutes should be recovered and delivered.</p>
<p>However, when the messaging layer gives up trying to recover messages, it is important for the application software to be informed of this fact. UM delivers unrecoverable loss <em>events</em> to the application followed by subsequent messages successfully received. Applications can use those unrecoverable loss events to take corrective action, like informing the end user, and possibly initiating a re-synchronization operation between distributed components.</p>
<p>Obviously unrecoverable loss is considered a serious event. However, even simple loss should be monitored by users. Daily data rates tend to increase over time. A "clean" network this month might have overload-related simple loss next month, which might progress to unrecoverable loss the month after that.</p>
<p>UM does not deliver specific events to the application when simple loss is detected and successfully recovered. Instead, users have a variety of tools at their disposal to monitor UM transport statistics, which includes counters for simple loss. Applications themselves can use the UM API to "self-monitor" and alert end users when simple loss happens. Or external monitoring applications can be written to receive transport statistics from many applications, and provide a central point where small problems can be detected and dealt with before they become big problems.</p>
<p>See <a class="el" href="packetloss.html">Packet Loss</a> for an extended discussion of packet loss and how UM deals with it.</p>
<p>There are some special cases of unrecoverable loss that deserve additional description: </p><ul>
<li>
<a class="el" href="fundamentalconcepts.html#headloss">Head Loss</a> </li>
<li>
<a class="el" href="fundamentalconcepts.html#leadingloss">Leading Loss</a> </li>
<li>
<a class="el" href="fundamentalconcepts.html#tailloss">Tail Loss</a> </li>
<li>
<a class="el" href="fundamentalconcepts.html#burstloss1">Burst Loss</a> </li>
</ul>
<p><br />
 </p>
<h2><a class="anchor" id="headloss"></a>
Head Loss&nbsp;&nbsp;<small><a href="#headloss">&lt;-</a></small></h2>
<p>When an application wants to publish messages, it creates one or more <em>UM sources</em> for topics. The design of UM is such that a subscriber <em>discovers</em> the sources of interest and <em>joins</em> them. The process of receivers discovering and joining sources (in UM it is called "Topic Resolution") takes a non-zero amount of time. Since UM is a fully-distributed system with no central master broker, the publisher has no way of knowing when the subscribers have completed the discovery/join process. As a result, it is possible for a publisher to create its sources and send messages, and some of those messages might not reach all of the subscribed receivers.</p>
<p>For many UM-based applications, this is not a problem. Consider a market data distribution system. The market data is a continuous stream of updates with no beginning or end. When a receiver joins, it has no expectation to get the "first" message; it joins at an arbitrary point in the stream and starts getting messages from that point.</p>
<p>But there are other applications where a sender comes up and wants to send a request to a pre-existing receiver. In this case, the sender is very interested in avoiding head loss so that the receiver will get the request.</p>
<p>UM's <a class="el" href="fundamentalconcepts.html#persistence">Persistence</a> feature does a rigorous job of recovering from head loss. UM's <a class="el" href="fundamentalconcepts.html#latejoin">Late Join</a> feature is sometimes used by streaming receivers to recover from head loss, although it requires care in the case of a receiver restart since late join can also delivery duplicate messages.</p>
<p><br />
 </p>
<h2><a class="anchor" id="leadingloss"></a>
Leading Loss&nbsp;&nbsp;<small><a href="#leadingloss">&lt;-</a></small></h2>
<p>The behavior described in this section does not apply to Persisted data streams where delivery of all messages is important.</p>
<p>For Streaming (non-persisted) data streams, once a receiver successfully joins a source, it should start getting messages. However, there are some circumstances which interfere with the initial message reception.</p>
<p>For example, if a sender is sending a series of very large messages, those messages are <a class="el" href="umglossary.html#glossaryumfragmentation">fragmented</a>, broken into smaller pieces and sent serially. If a receiver joins the message stream after the first message of a large message has already gone by, the receiver will no longer be able to successfully reassemble that first message. In UM versions prior to 6.12, this led to delivery of one or more Unrecoverable Loss events to the application receiver callback prior to delivery of the first successfully-received message.</p>
<p>Some users attempt to use the <a class="el" href="fundamentalconcepts.html#latejoin">Late Join</a> feature to avoid this problem, but the Late Join feature depends on a circular buffer of message fragments. Requesting Late Join may well recover the initial fragment of the message currently under transmission, but it might also recover the final fragments of the message before that. That leads to an unrecoverable loss event for that previous message.</p>
<p>As a final example, suppose that a receiver joins a source during a period of severe overload leading to packet loss. The receiver may not be able to get a full message until the overload condition subsides. This can deliver one or more unrecoverable loss events prior to the first successfully delivered message.</p>
<p>In all of these examples, UM has either gotten no messages or incomplete messages during the startup phase of a new receiver. Starting in UM version 6.12, UM will not deliver unrecoverable loss events to the application in these cases. Once UM is able to successfully deliver its first message to a receiver, UM will enable the delivery of unrecoverable loss events.</p>
<p>This matches what most programmers want to see. They are not interested in messages that came before their first, but they are interested in any gaps that happen after that first message.</p>
<p>Be aware that pre-6.12 versions of UM <em>do</em> deliver leading unrecoverable loss events to the application under some circumstances, leading application developers to implement their own filter for those leading events. Those application can safely upgrade to 6.12 and beyond; their filter will simply never be executed since UM filters the leading events first.</p>
<p>Finally, remember that it is important for UM-based systems to be monitored for transport statistics, including loss. Since leading unrecoverable loss events are now suppressed (and even pre-6.12 were not reliably delivered in all cases), the transport stats should be used to determine the "health" of the network.</p>
<p><br />
 </p>
<h2><a class="anchor" id="tailloss"></a>
Tail Loss&nbsp;&nbsp;<small><a href="#tailloss">&lt;-</a></small></h2>
<p>Packet loss is a fact of life. Temporary overloads of network hardware can lead to dropped packets. UM receivers are designed to recover those lost packets from the sender, but that recovery takes greater than zero time.</p>
<p>Suppose a application has some messages to send, and then exits. You could have a situation where the last message sent fell victim to a network drop. If the sending application exits immediately, the receivers may not have had enough time to recover the lost packets; may not even have detected the loss.</p>
<p>If the delivery of those tail messages is important, UM's persistence functionality should be used. A sender should delay its exit until the persistence layer informs it that all messages are "stable".</p>
<p>Non-persistent applications can implement an application-level handshake where the receivers tell the senders that they have successfully processed the final message.</p>
<p>Sometimes, delivery of the final message is not of critical importance. In that case, some application developers choose to simply introduce a delay of a second or two after the last message is sent before the sources are deleted. This will give UM a chance to detect and recover any lost messages.</p>
<p>See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/interrelatedconfigurationoptions.html#preventingnakstormswithnakintervals">Preventing NAK Storms with NAK Intervals</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/interrelatedconfigurationoptions.html#preventingundetectedloss">Preventing Undetected Unrecoverable Loss</a> for configuration details related to tail loss.</p>
<p><br />
 </p>
<h2><a class="anchor" id="burstloss1"></a>
Burst Loss&nbsp;&nbsp;<small><a href="#burstloss1">&lt;-</a></small></h2>
<p>UM's "burst loss" feature is no longer recommended. All known use cases for the burst loss feature are better accomplished through other means. For example, controlling latency after loss should be done using NAK-related and OTR-related configuration options. Informatica recommends disabling the burst loss feature by setting the configuration options <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpdeliverycontrol.html#deliverycontrolmaximumburstlossreceiver">delivery_control_maximum_burst_loss (receiver)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grphotfailoveroperation.html#deliverycontrolmaximumburstlosshfx">delivery_control_maximum_burst_loss (hfx)</a> to 1,000,000,000.</p>
<p>When setting the burst loss options, be sure to include all subscribers, including all instances of UM Stores, DROs, and UMDS servers.</p>
<p>This is especially important for persistent receivers and Stores.</p>
<p><b>Feature Description</b></p>
<p>Normally, when the <a class="el" href="architecture.html#deliverycontroller">Delivery Controller</a> detects a gap in topic sequence numbers of received message fragments, it waits for a NAK generation interval (defaults to 10 seconds) before declaring the missing message fragments unrecoverably lost. This wait time allows the underlying transport layer to attempt to retrieve the missing message fragments.</p>
<p>The configuration options <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpdeliverycontrol.html#deliverycontrolmaximumburstlossreceiver">delivery_control_maximum_burst_loss (receiver)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grphotfailoveroperation.html#deliverycontrolmaximumburstlosshfx">delivery_control_maximum_burst_loss (hfx)</a> specify a size for a contiguous gap in topic sequence numbers beyond which the gap is defined to be a "burst loss". When this happens, the delivery controller <em>immediately</em> declares the entire gap to be unrecoverably lost and resets its loss-handling structures.</p>
<p>Note that the burst loss feature does not reduce NAKs and retransmissions. If burst loss is invoked, the underlying transport layer will still attempt to recover the lost messages. NAK-based protocols will continue to send NAKs and retransmissions. However, the delivery controller will discard any successfully recovered messages because they were already declared unrecoverable as part of the burst loss event.</p>
<p>For burst loss, a single <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a6629139aaf902976c8df9de3f37d10db">LBM_MSG_UNRECOVERABLE_LOSS_BURST</a> event is delivered for the entire sequence number gap. Contrast this with simple (not burst) loss events, where a separate <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a88920e0a4188081f9a14fc8f76c18578">LBM_MSG_UNRECOVERABLE_LOSS</a> event will be delivered to the receiver for each lost sequence number.</p>
<dl class="section note"><dt>Note</dt><dd>The burst loss control takes priority over all recovery methods. For example, if the subscriber is receiving persistent data and OTR is enabled, a gap longer than delivery_control_maximum_burst_loss will immediately declare the gap as unrecoverable without trying to use OTR to recover.</dd></dl>
<p>Finally, be aware that successfully-received but buffered messages can be discarded when a burst loss is detected. For example, let's say that topic sequence number 10 is lost, and number 11 through 30 are successfully received. Datagrams 11 through 30 will be buffered, awaiting datagram 10 being retransmitted. But if the next topic sequence number is 1055, that exceeds the burst loss threshold, which clears the entire order map, discarding messages 11 through 30. The application sees message 9, followed by a burst loss notification, followed by message 1055.</p>
<p><br />
 </p>
<h1><a class="anchor" id="umrouter"></a>
DRO&nbsp;&nbsp;<small><a href="#umrouter">&lt;-</a></small></h1>
<p>The Ultra Messaging Dynamic Routing Option (DRO) consists of a daemon named "tnwgd" that bridges disjoint <a class="el" href="fundamentalconcepts.html#topicresolutiondomain">Topic Resolution Domains</a> (TRDs) by effectively forwarding control and user traffic between them. Thus, the DRO facilitates WAN routing where multicast routing capability is absent, possibly due to technical obstacles or enterprise policies.</p>
<p>The DRO transfers multicast and/or unicast topic resolution information, thus ensuring that receivers in disjoint topic resolution domains from the source can receive the topic messages to which they subscribe.</p>
<p>See the <a href="../Gateway/index.html">Dynamic Routing Guide</a> for more information.</p>
<p><br />
 </p>
<h1><a class="anchor" id="latejoin"></a>
Late Join&nbsp;&nbsp;<small><a href="#latejoin">&lt;-</a></small></h1>
<p>In many applications, a new receiver may be interested in messages sent before that receiver joins the source's transport session. The Ultra Messaging Late Join feature allows a new receiver to obtain previously-sent messages from a source. Without the Late Join feature, the receiver would only deliver messages sent after the receiver successfully joins the source's transport session. With Late Join, the source locally stores recently sent messages according to its Late Join configuration options, and a new receiver is able to retrieve those messages.</p>
<p>For late join to happen, the source must be configured to offer it, and the receiver must be configured to participate.</p>
<p>Source-side configuration options:</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#latejoinsource">late_join (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitretentionagethresholdsource">retransmit_retention_age_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitretentionsizelimitsource">retransmit_retention_size_limit (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpunicastimmediatemessagingnetwork.html#requesttcpinterfacecontext">request_tcp_interface (context)</a> </li>
</ul>
<p>Receiver-side configuration options:</p>
<ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#uselatejoinreceiver">use_late_join (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitrequestintervalreceiver">retransmit_request_interval (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitrequestmessagetimeoutreceiver">retransmit_request_message_timeout (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitrequestoutstandingmaximumreceiver">retransmit_request_outstanding_maximum (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#latejoininforequestintervalreceiver">late_join_info_request_interval (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#latejoininforequestmaximumreceiver">late_join_info_request_maximum (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitinitialsequencenumberrequestreceiver">retransmit_initial_sequence_number_request (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitmessagecachingproximityreceiver">retransmit_message_caching_proximity (receiver)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpunicastimmediatemessagingoperation.html#responsetcpinterfacecontext">response_tcp_interface (context)</a> </li>
</ul>
<dl class="section note"><dt>Note</dt><dd>With <a class="el" href="advancedoptimizations.html#smartsources">Smart Sources</a>, the following configuration options have limited or no support: <ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitretentionsizethresholdsource">retransmit_retention_size_threshold (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitretentionsizelimitsource">retransmit_retention_size_limit (source)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grplatejoin.html#retransmitretentionagethresholdsource">retransmit_retention_age_threshold (source)</a> </li>
</ul>
</dd>
<dd>
You cannot use Late Join with Queuing functionality (UMQ).</dd></dl>
<p><br />
 </p>
<h1><a class="anchor" id="requestresponse"></a>
Request/Response&nbsp;&nbsp;<small><a href="#requestresponse">&lt;-</a></small></h1>
<p>Ultra Messaging also offers a Request/Response messaging model. A sending application (the requester) sends a message to a topic. Every receiving application listening to that topic gets a copy of the request. One or more of those receiving applications (responder) can then send one or more responses back to the original requester. Ultra Messaging sends the request message via the normal pub/sub method, whereas Ultra Messaging delivers the response message directly to the requester.</p>
<p>An important aspect of the Ultra Messaging Request/Response model is that it allows the application to keep track of which request corresponds to a given response. Due to the asynchronous nature of Ultra Messaging requests, any number of requests can be outstanding, and as the responses come in, they can be matched to their corresponding requests.</p>
<p>Request/Response can be used in many ways and is often used during the initialization of Ultra Messaging receiver objects. When an application starts a receiver, it can issue a request on the topic the receiver is interested in. Source objects for the topic can respond and begin publishing data. This method prevents the Ultra Messaging source objects from publishing to a topic without subscribers.</p>
<p>Be careful not to be confused with the sending/receiving terminology. Any application can send a request, including one that creates and manages Ultra Messaging receiver objects. And any application can receive and respond to a request, including one that creates and manages Ultra Messaging source objects.</p>
<dl class="section note"><dt>Note</dt><dd>You cannot use Request/Response with Queuing functionality (UMQ).</dd></dl>
<p><br />
 </p>
<h1><a class="anchor" id="umtransports"></a>
UM Transports&nbsp;&nbsp;<small><a href="#umtransports">&lt;-</a></small></h1>
<p>A source application uses a UM transport to send messages to a receiver application. An Ultra Messaging transport type is built on top of a standard IP protocol. For example, the UM transport type "LBT-RM" is built on top of the standard UDP protocol using standard multicast addressing. The different Ultra Messaging transport types have different trade offs in terms of latency, scalability, throughput, bandwidth sharing, and flexibility. The sending application chooses the transport type that is most appropriate for the data being sent, at the topic level. A programmer might choose different transport types for different topics within the same application.</p>
<p><br />
 </p>
<h2><a class="anchor" id="transportsessions"></a>
Transport Sessions&nbsp;&nbsp;<small><a href="#transportsessions">&lt;-</a></small></h2>
<p>An Ultra Messaging sending application can make use of very many topics - possibly over a million. Ultra Messaging maps those topics onto a much smaller number of <em>Transport Sessions</em>. A Transport Session can be thought of as a specific running instance of a transport type, running within a context. A given Transport Session might carry a single topic, or might carry hundreds of thousands of topics.</p>
<p>A publishing application can either explicitly map each topic source to specific Transport Sessions, or it can make use of an automatic mapping of sources to a pool of Transport Sessions. If explicitly mapping, the application must configure a new source with identifying information to specify the desired Transport Session. The form of this identifying information depends on the transport type. For example, in the case of the LBT-RM transport type, a Transport Session is identified by a <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmnetwork.html#transportlbtrmmulticastaddresssource">multicast group IP address</a> and a <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmnetwork.html#transportlbtrmdestinationportsource">destination port number</a>. Alternatively, if the application does not specify a Transport Session for a new topic source, a Transport Session is implicitly selected from a pool of Transport Sessions, configured when the context was created. For example, with the LBT-RM transport type, the pool of implicit Transport Sessions is created with a range of multicast groups, from <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmnetwork.html#transportlbtrmmulticastaddresslowcontext">low</a> to <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmnetwork.html#transportlbtrmmulticastaddresshighcontext">high</a>, and the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmnetwork.html#transportlbtrmdestinationportsource">destination port number</a>. Note that at context creation, the Transport Sessions in the configured pool are not activated. As topic sources are created and mapped to pool Transport Sessions, those Transport Sessions are activated.</p>
<dl class="section note"><dt>Note</dt><dd>When two contexts are in use, each context may be used to create a topic source for the same topic name. These sources are considered separate and independent, since they are owned by separate contexts. This is true regardless of whether the contexts are within the same application process or are separate processes. A Transport Session is also owned by a context, and sources are mapped to Transport Sessions within the same context. So, for example, if application process A creates two contexts, ctx1 and ctx2, and creates a source for topic "current_price" in each context, the sources will be mapped to completely independent Transport Sessions. This can even be true if the same Transport Session identification information is supplied to both. For example, if the source for "current_price" is created in ctx1 with LBT-RM on multicast group 224.10.10.10 and destination port 14400, and the source for the same topic is created in ctx2, also on LBT-RM with the same multicast group and destination port, the two Transport Sessions will be separate and independent, although a subscribing application will receive both Transport Sessions on the same network socket.</dd></dl>
<p>See the configuration section for each transport type for specifics on how explicit Transport Sessions and implicit pools are created: </p><ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransporttcpnetwork.html#tcptransportsessionmanagement">TCP Transport Session Management</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmnetwork.html#lbtrmtransportsessionmanagement">LBT-RM Transport Session Management</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrunetwork.html#lbtrutransportsessionmanagement">LBT-RU Transport Session Management</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtipcoperation.html#lbtipctransportsessionmanagement">LBT-IPC Transport Session Management</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtsmxoperation.html#lbtsmxtransportsessionmanagement">LBT-SMX Transport Session Management</a> </li>
</ul>
<p>A receiving application might subscribe to a small subset of the topics that a sending application has mapped to a given Transport Session. In most cases, the subscribing process will receive all messages for all topics on that Transport Session, and the UM library will discard messages for topics not subscribed. This user-space filtering does consume system resources (primarily CPU and bandwidth), and can be minimized by carefully mapping topics onto Transport Sessions according to receiving application interest (having receivers). (Certain transport types allow that filtering to happen in the publishing application; see <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpmajoroptions.html#transportsourcesidefilteringbehaviorsource">transport_source_side_filtering_behavior (source)</a>.)</p>
<p>When a subscribing application creates its first receiver for a topic, UM will join any and all Transport Sessions that have that topic mapped. The application might then create additional receivers for other topics on that same Transport Session, but UM will not "join" the Transport Session multiple times. It simply sets UM internal state indicating the topic subscriptions. When the publisher sends its next message of any kind on that Transport Session, the subscribing UM will deliver a BOS event (Beginning Of Stream) to all topic receivers mapped to that Transport Session, and will consider the Transport Session to be <em>active</em>. Once active, any subsequent receivers created for topics mapped to that same Transport Session will deliver an immediate BOS to that topic receiver.</p>
<p>If the publisher deletes a topic source, the subscribing application may or may not get an immediate EOS event (End Of Stream), depending on different circumstances. For example, in many cases, the deletion of topic sources by a publisher will not trigger an EOS event until <em>all</em> sources mapped to a Transport Session are deleted. When the last topic is deleted, the Transport Session itself is deleted, and an EOS event might then be delivered to <em>all</em> topic receivers that were mapped to that Transport Session. Note that for UDP transports, the deletion of a Transport Session by the publisher is not immediately detected by a subscriber, until an activity timeout expires.</p>
<p>Be aware that in a deployment that includes the DRO, BOS and EOS may only indicate the link between the receiver and the local DRO portal, not necessarily full end-to-end connectivity. Subscribing application should not use BOS and EOS events as an accurate and timely indication of the creation and deletion of sources by a publisher.</p>
<dl class="section note"><dt>Note</dt><dd>Non-multicast Ultra Messaging transport types can use source-side filtering to decrease user-space filtering on the receiving side by doing the filtering on the sending side. However, be aware that system resources consumed on the source side affect all receivers, and that the filtering for multiple receivers must be done serially, whereas letting the receivers do the filtering allows that filtering to be done in parallel, only affecting those receivers that need the filtering.</dd></dl>
<p>With the UMQ product, a ULB source makes use of the same transport types as Streaming, but a Brokered Queuing source must use the <b>broker</b> transport.</p>
<p><br />
 </p>
<h2><a class="anchor" id="transportpacing"></a>
Transport Pacing&nbsp;&nbsp;<small><a href="#transportpacing">&lt;-</a></small></h2>
<p>Pacing refers to the controlling of when messages can be sent. <em>Source Pacing</em> is when the publisher of messages controls when messages are sent, and <em>Receiver Pacing</em> is when the subscribers can essentially push back on the publisher if the publisher is sending faster than the subscribers can consume messages.</p>
<p><b>Source Pacing</b></p>
<p>In its simplest case, source pacing means that the publishing application controls when to send messages by having messages to send. For example, market data distribution system sends messages when the exchanges it is monitoring sends updates. The subscribers must be able to accept those messages at the rates that the exchanges send them.</p>
<p>A slow subscriber will fall behind and can lose data if buffers overflow. There is no way for a slow subscriber to "push back" on a fast publisher.</p>
<p>Some of Ultra Messaging's transport types have features that allow the publisher to establish upper limits on the outgoing message data. For example, LBT-RM has the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmoperation.html#transportlbtrmdataratelimitcontext">transport_lbtrm_data_rate_limit (context)</a> configuration option. If the application attempts to send too many messages in too short a time, the send function can block for a short time, or return an error indicating that it attempted to exceed the configured rate limit. This is still called source pacing because the rate limit is optional and is under the control of the publisher.</p>
<p>The source-paced transports are: </p><ul>
<li>
<a class="el" href="transporttypes.html#transporttcp">Transport TCP</a> (can be <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransporttcpoperation.html#transporttcpmultiplereceiverbehaviorsource">configured</a> for source or receiver pacing) </li>
<li>
<a class="el" href="transporttypes.html#transportlbtru">Transport LBT-RU</a> (source pacing only) </li>
<li>
<a class="el" href="transporttypes.html#transportlbtrm">Transport LBT-RM</a> (source pacing only) </li>
<li>
<a class="el" href="transporttypes.html#transportlbtipc">Transport LBT-IPC</a> (can be <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtipcoperation.html#transportlbtipcbehaviorsource">configured</a> for source or receiver pacing) </li>
</ul>
<p><b>Receiver Pacing</b></p>
<p>In a receiver-paced transport, a publisher still attempts to send when it has messages to send, but the send function can block or return an error if the publisher is sending faster than the slowest subscribed receiver can consume. There is a configurable amount of buffering that can be used to allow the publisher to exceed the consumption rate for short periods of time, but when those buffers fill, the sender will be prevented from sending until the buffers have enough room.</p>
<p>The receiver-paced transports are: </p><ul>
<li>
<a class="el" href="transporttypes.html#transporttcp">Transport TCP</a> (can be <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransporttcpoperation.html#transporttcpmultiplereceiverbehaviorsource">configured</a> for source or receiver pacing) </li>
<li>
<a class="el" href="transporttypes.html#transportlbtipc">Transport LBT-IPC</a> (can be <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtipcoperation.html#transportlbtipcbehaviorsource">configured</a> for source or receiver pacing) </li>
<li>
<a class="el" href="transporttypes.html#transportlbtsmx">Transport LBT-SMX</a> (receiver-pacing only) </li>
</ul>
<p>However, it is generally inadvisable to rely on receiver pacing to ensure reliable system operation. Subscribers should be designed and provisioned to support the maximum possible incoming data rates. The reasons for this recommendation are described below.</p>
<p><b>Receiver Queuing</b></p>
<p>This use case is not related to the <a class="el" href="fundamentalconcepts.html#queuing">Queuing</a> paradigm. It is referring to the use of a software queue between the context thread which receives the UM message and the application thread which processes the message.</p>
<p>A receiver-paced transport does not necessarily mean that a slow application will push back on a fast publisher. Suppose that the actual message reception action by UM's context thread is fast, and the received messages are placed in an unbounded memory queue. Then, one or more application threads take messages from the queue to process them. If those application threads don't process messages quickly enough, instead of pushing back on the publisher, the message queue will grow.</p>
<p>For example, the UM <a class="el" href="umobjects.html#eventqueueobject">Event Queue Object</a> is an unbounded memory-based queue. You could use <a class="el" href="transporttypes.html#transporttcp">Transport TCP</a> configured for receiver pacing, but if the subscriber uses an event queue for message delivery, then a slow consumer will not slow down the publisher. Instead the subscriber's event queue will grow without bound, eventually leading to an out-of-memory condition.</p>
<p><b>Pacing and DRO</b></p>
<p>Transport pacing refers to the connection within a a <a class="el" href="fundamentalconcepts.html#topicresolutiondomain">Topic Resolution Domain</a> (TRD) from source to receiver. If multiple TRDs are connected with a <a class="el" href="fundamentalconcepts.html#umrouter">DRO</a>, there can be multiple hops between the originating publisher and the final subscriber, with the DROs providing proxy sources and receivers to pass messages across the hops. The pacing of a particular transport session only applies to the link between the source (or proxy source) and the receiver (or proxy receiver) of a particular hop.</p>
<p>This means that UM does not support end-to-end transport pacing.</p>
<p>For example, if a DRO joins two TRDs, both of which use receiver-paced TCP for transport, a slow receiver might push back on the DRO's proxy source, leading to queuing in the DRO. Since the DRO uses bounded queues, the DRO's queue will fill, leading to dropped messages.</p>
<p><b>Pacing and Queuing</b></p>
<p>Brokered <a class="el" href="fundamentalconcepts.html#queuing">Queuing</a> is receiver paced between the source and the broker. For ULB queuing, the transport pacing is determined by the chosen transport type.</p>
<p>There is also a form of end-to-end application receiver-pacing with queuing. For both brokered ULB, the size of queue is configurable. As receivers consume messages, they are removed from the queue. If the queue fills due to the source exceeding the consumption rate of the receiver, the next send call will either block or return a "WOULDBLOCK" error until sufficient room opens up in the queue. Note that lifetimes can be configured for messages (to prevent unbounded blocking) and the application can be notified if a message exceeds its lifetime.</p>
<p>See <a href="../UMQ/index.html">UM Guide to Queuing</a> for more information.</p>
<p><b>Pacing and Persistence</b></p>
<p>With Persistence, the pacing is layered: </p><ul>
<li>
<p class="startli">At the transport level, pacing is determined by the chosen transport type.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">At the persistence level, <a class="el" href="fundamentalconcepts.html#transportpacing">Transport Pacing</a> provides receiver pacing between the source and the Store. This helps to ensure that a publisher sending on a source-paced transport like LBT-RM will not overwhelm the Store.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">By default, the end-to-end pacing is source-paced. Which is to say that if a subscribed receiver cannot keep up with the publish rate, eventually the receiver can experience unrecoverable loss, although this normally will only happen if the receiver falls further behind than the total size of the Store's repository.</p>
<p class="endli"></p>
</li>
<li>
Alternatively, the end-to-end pacing can be switched to receiver-paced. This is done using <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/ume.tag:../UME/" href="../UME/operationalview.html#receiverpacedpersistenceoperations">RPP: Receiver-Paced Persistence</a>. Note that if a subscribed receiver crashes, it can lead to unbounded blockage of the publisher until the subscriber is successfully restarted. </li>
</ul>
<p><b>Suspended Receiver Problem</b></p>
<p>This is a problem that one of our users encountered. Their system used receiver-paced TCP because they wanted the publishing speed to be limited to the rate that the slowest receiver could consume. This was fine until one day the publisher appeared to stop working.</p>
<p>With some help from Support, the problem was trace to a receiver at a particular IP address that was joined to the transport but apparently was not reading any data. It took some time to find the receiver by its IP address, and what they found was a Windows machine with a dialog box telling the user that the process had generated an exception and did the user want abort the process or enter the debugger.</p>
<p>When Windows does this, it suspends the process waiting for user input. In that suspended state, the kernel maintains the network connections, but the process is not able to read any data. So the socket buffers filled up and the publisher's send call blocked.</p>
<p><br />
 </p>
<h1><a class="anchor" id="eventdelivery"></a>
Event Delivery&nbsp;&nbsp;<small><a href="#eventdelivery">&lt;-</a></small></h1>
<p>There are many different events that UM may want to deliver to the application. Many events carry data with them (e.g. received messages); some do not (e.g. end-of-stream events). Some examples of UM events:</p>
<ul>
<li>
Received message. UM delivers messages on subscribed topics to the receiver. </li>
<li>
Receiver loss. UM can inform the application when a data gap is detected on a subscribed topic that could not be recovered through the normal retransmission mechanism. </li>
<li>
End of Stream. UM can inform a receiving application when a data stream (<a class="el" href="fundamentalconcepts.html#transportsessions">Transport Session</a>) has terminated. </li>
<li>
Connect and Disconnect events. Source-side events delivered to a sending application when receivers connect to and disconnect from the source's transport session. </li>
<li>
A timer expiring. Applications can schedule timers to expire in a desired number of milliseconds (although the OS may not deliver them with millisecond precision). </li>
<li>
An application-managed file descriptor event. The application can register its own file descriptors with UM to be monitored for state changes (readable, writable, error, etc.). </li>
<li>
New source notification. UM can inform the application when sources are discovered by Topic Resolution. </li>
</ul>
<p>UM delivers events to the application via callbacks. The application explicitly gives UM a pointer to one of its functions to be the handler for a particular event, and UM calls that function to deliver the event, passing it the parameters that the application requires to process the event. In particular, the last parameter of each callback type is a client data pointer (clientdp). This pointer can be used at the application's discretion for any purpose. It's value is specified by the application when the callback function is identified to UM (typically when UM objects are created), and that same value is passed back to the application when the callback function is called.</p>
<p>There are two methods that UM can use to call the application callbacks: through context thread callback, or <a class="el" href="umobjects.html#eventqueueobject">event queue</a> dispatch.</p>
<p>In the context thread callback method (sometimes called direct callback), the UM context thread calls the application function directly. This offers the lowest latency, but imposes significant restrictions on the application function. See <a class="el" href="umobjects.html#eventqueueobject">Event Queue Object</a>.</p>
<p>The <a class="el" href="umobjects.html#eventqueueobject">event queue</a> dispatch of application callback introduces a dynamic buffer into which the UM context thread writes events. The application then uses a thread of its own to dispatch the buffered events. Thus, the application callback functions are called from the application thread, not directly from the context thread.</p>
<p>With event queue dispatching, the use of the application thread to make the callback allows the application function to make full, unrestricted use of the UM API. It also allows parallel execution of UM processing and application processing, which can significantly improve throughput on multi-processor hardware. The dynamic buffering provides resilience between the rate of event generation and the rate of event consumption (e.g. message arrival rate v.s. message processing rate).</p>
<p>In addition, an UM event queue allows the application to be warned when the queue exceeds a threshold of event count or event latency. This allows the application to take corrective action if it is running too slow, such as throwing away all events older than a threshold, or all events that are below a given priority.</p>
<p>Note that while most UM events can be delivered via event queue, there are some that cannot (e.g. <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpmajoroptions.html#resolversourcenotificationfunctioncontext">resolver_source_notification_function (context)</a>).</p>
<p><br />
 </p>
<h2><a class="anchor" id="receiverbosandeosevents"></a>
Receiver BOS and EOS Events&nbsp;&nbsp;<small><a href="#receiverbosandeosevents">&lt;-</a></small></h2>
<p>There are two receive-side events that some applications use but which are not recommended for most use cases: </p><ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#ab5489080adc7157549a9930b30c68425">LBM_MSG_BOS</a> - Beginning of (transport) Session. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a2647b87f92adb5a34ea129fbfeeed5a3">LBM_MSG_EOS</a> - End of (transport) Session. </li>
</ul>
<p>The BOS and EOS events are delivered to receivers on a topic basis, but were originally designed to represent the joining and exiting of the underlying <a class="el" href="fundamentalconcepts.html#transportsessions">Transport Session</a>.</p>
<p>Note that the BOS and EOS receive-side events are very similar to the <a class="el" href="fundamentalconcepts.html#sourceconnectanddisconnectevents">Source Connect and Disconnect Events</a>.</p>
<p>The BOS event means slightly different things for different transport types. The basic principal is that a UM receiver won't deliver BOS until it has seen some kind of activity on the transport after joining it. For example, a session message for <a class="el" href="transporttypes.html#transportlbtrm">Transport LBT-RM</a>. Or perhaps a <a class="el" href="architecture.html#lossdetectionusingtsnis">TSNI</a> on any of the transport types. Or even an actual user message. Any of these will trigger BOS. But if the newly-joined transport session is completely silent, then BOS is delayed until first activity is detected. Under some configurations, that delay is unbounded.</p>
<p>EOS is also triggered by different things for different transport types. For example, for the TCP transport, a disconnect will trigger EOS for any receivers that were subscribed to topics carried on that transport session. For LBT-RM, an <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmoperation.html#transportlbtrmactivitytimeoutreceiver">activity timeout</a> can trigger EOS.</p>
<p>However, in recent versions of UM, the meaning of EOS has become more complicated, and no longer necessarily indicates that the transport session has ended. There are circumstances in many versions of UM where a publisher of a source that is in a remote TRD can delete that source, and the receiver will receive a timely EOS, even though the transport session that carried the source stays in effect and joined by the receiver. As of UM version 6.10, the configuration option <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpudpbasedresolveroperation.html#resolversendfinaladvertisementssource">resolver_send_final_advertisements (source)</a> can be used to trigger EOS on receivers in the same TRD, even if the transport session remains joined. As of UM version 6.12, <a class="el" href="topicresolutiondescription.html#tcpbasedtopicresolutiondetails">TCP-based Topic Resolution</a> will have the same effect. In in a mixed-version UM environment including <a class="el" href="fundamentalconcepts.html#umrouter">DROs</a>, it can be difficult to predict when an EOS will be generated for a deleted source.</p>
<p>Be aware that BOS does <em>not</em> necessarily indicate end-to-end connectivity between sources and receivers. In a <a class="el" href="fundamentalconcepts.html#umrouter">DRO</a> network, where the source is in a different <a class="el" href="fundamentalconcepts.html#topicresolutiondomain">Topic Resolution Domain</a> (TRD) from the receiver, BOS only indicates the establishment of the transport session between the DRO's proxy source and the receiver.</p>
<p>Also, BOS and EOS do not necessarily come in balanced pairs. For example, if a BOS is delivered to a receiver, and then the subscriber application deletes the receiver object, UM does not deliver an EOS to the receiver callback. Also, it is possible to get an EOS event without first getting a BOS. Let's say that a receiver attempts to join an LBT-RM transport session for a source that was just deleted. BOS will not be delivered because there will be no communication of a user or control message. However, after LBT-RM times out the transport session, it will deliver EOS.</p>
<p>Finally, in some versions of UM, EOS represents the end of the entire transport session, so you can have situations where a publisher deletes a source, but the receiver for that topic does not get an EOS for an unbounded period of time. Let's say that the publisher maps sources for topics X, Y, and Z to the same transport session. Let's further say that a subscriber has a receiver for topic Y. It will join the transport session, get a BOS for receiver Y, and will receive messages that the publisher sends to Y. Now let's say that the publisher deletes the source for topic Y, but keeps the sources for topics X and Z. The subscriber may not be informed of the deletion of the source for Y, and can remain subscribed to the transport session. It won't be until the publisher deletes sources X and Z that it will delete the underlying transport session, which can then deliver EOS to the subscriber. However, if using <a class="el" href="topicresolutiondescription.html#tcpbasedtopicresolutiondetails">TCP-based Topic Resolution</a>, this same scenario can produce an EOS event on the receiver immediately.</p>
<p>For these reasons and others, Informatica does not recommend using the BOS and EOS events to indicate "connectedness" between a source and a receiver. Instead, Informatica recommends logging the events in your application log file. If something goes wrong, these messages can assist in diagnosing the problem.</p>
<p>For programmers who are tempted to use BOS and EOS events, Informatica recommends instead using the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpdeliverycontrol.html#sourcenotificationfunctionreceiver">source_notification_function (receiver)</a> configuration option. This provides receiving applications a callbacks when a <a class="el" href="architecture.html#deliverycontroller">Delivery Controller</a> is created and deleted, and is usually what the programmer <em>really</em> wants.</p>
<p><br />
 </p>
<h2><a class="anchor" id="sourceconnectanddisconnectevents"></a>
Source Connect and Disconnect Events&nbsp;&nbsp;<small><a href="#sourceconnectanddisconnectevents">&lt;-</a></small></h2>
<p>There are two source-side events that some applications use but which are not recommended for most use cases: </p><ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#adb8a3d729fdaa96b9729144ee86668ad">LBM_SRC_EVENT_CONNECT</a> - Beginning of (transport) Session to receiver. </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#acf50e4167d38a398bf5ae12c163ff2bb">LBM_SRC_EVENT_DISCONNECT</a> - End of (transport) Session to receiver. </li>
</ul>
<p>The Connect and Disconnect events are delivered to source on a topic basis, but actually represent the joining and exiting of the underlying <a class="el" href="fundamentalconcepts.html#transportsessions">Transport Session</a> to a specific receiver.</p>
<dl class="section note"><dt>Note</dt><dd>The Connect and Disconnect events are <em>not</em> available for <a class="el" href="transporttypes.html#transportlbtrm">Transport LBT-RM</a> or <a class="el" href="transporttypes.html#transportlbtsmx">Transport LBT-SMX</a> sources.</dd></dl>
<p>Note that the Connect and Disconnect source-side events are very similar to the <a class="el" href="fundamentalconcepts.html#receiverbosandeosevents">Receiver BOS and EOS Events</a>. However, while BOS and especially EOS have deviated from their pure "transport session" roots, Connect and Disconnect are still purely implemented with respect to the underlying transport session.</p>
<p>Be aware that Connect does <em>not</em> necessarily indicate end-to-end connectivity between sources and receivers. In a <a class="el" href="fundamentalconcepts.html#umrouter">DRO</a> network, where the source is in a different <a class="el" href="fundamentalconcepts.html#topicresolutiondomain">Topic Resolution Domain</a> (TRD) from the receiver, Connect only indicates the establishment of the transport session between the DRO's proxy receiver and the source. For example, if a source in TRD1 is sending messages to two receivers in TRD2 via a DRO, the source will only receive a single Connect event when the first of the two receivers subscribe. Note also that the IP and port indicated in the Connect event will be for the DRO portal on TRD1.</p>
<p>Also, since Disconnect represents the end of the entire transport session, you can have situations where a subscriber deletes a receiver, but the source for that topic does not get a Disconnect for an unbounded period of time. Let's say that the publisher maps sources for topics X, Y, and Z to the same transport session. Let's further say that a subscriber has a receiver for topic Y and Z. It will join the transport session, and the source will get Connect events for <em>all three</em> topics, X, Y, and Z. Now let's say that the subscriber deletes the receiver for topic Y, but keeps the receiver for topic Z. The source will not be informed of the deletion of the receiver for Y, since the transport session continues to be maintained. It won't be until the subscriber deletes both receivers, Y and Z, that it will delete the underlying transport session, which can then deliver Disconnect to the source.</p>
<p>For these reasons and others, Informatica does not recommend using the Connect and Disconnect events to indicate "connectedness". Instead, Informatica recommends logging the events in your application log file. If something goes wrong, these messages can assist in diagnosing the problem.</p>
<p><br />
 </p>
<h2><a class="anchor" id="sourcewakeupevent"></a>
Source Wakeup Event&nbsp;&nbsp;<small><a href="#sourcewakeupevent">&lt;-</a></small></h2>
<p>The source event <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#aa905cb268bbee255c71b74694370fe61">LBM_SRC_EVENT_WAKEUP</a> is delivered to the application when a non-blocking "send" function is called but returns the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a75f0f83b8684df30d9816210cc20b4b0">LBM_EWOULDBLOCK</a> error. When that happens, the message was not sent due to a flow controlling condition. When that flow controlling condition is cleared, UM delivers the wakeup to the source event callback, informing the application that it can resume sending.</p>
<p>The flow controlling conditions are: </p><ul>
<li>
The source uses the TCP (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransporttcpoperation.html#transporttcpmultiplereceiverbehaviorsource">normal</a>), IPC (<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtipcoperation.html#transportlbtipcbehaviorsource">receiver_paced</a>), or SMX protocol, and one or more receivers are not reading fast enough. When both the receiver's and sender's buffers are full, a non-blocking "send" will return <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a75f0f83b8684df30d9816210cc20b4b0">LBM_EWOULDBLOCK</a>. When the slow receiver(s) read more data, the flow control condition is cleared and the wakeup source event is delivered. </li>
<li>
The source uses a UDP-based protocol and the data rate limit is exceeded (see <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmoperation.html#transportlbtrmdataratelimitcontext">transport_lbtrm_data_rate_limit (context)</a> or <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtruoperation.html#transportlbtrudataratelimitcontext">transport_lbtru_data_rate_limit (context)</a>). A non-blocking "send" will return <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a75f0f83b8684df30d9816210cc20b4b0">LBM_EWOULDBLOCK</a>. When the rate interval expires and the rate limiter adds bandwidth, the flow control condition is cleared and the wakeup source event is delivered. </li>
<li>
The source uses persistence and exceeds a flight size limit (see <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpultramessagingpersistence.html#umeflightsizesource">ume_flight_size (source)</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpultramessagingpersistence.html#umeflightsizebytessource">ume_flight_size_bytes (source)</a>). A non-blocking "send" will return <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a75f0f83b8684df30d9816210cc20b4b0">LBM_EWOULDBLOCK</a>. When the Store sends stability ACKs to the source and the in-flight message data drops below the limit, the flow control condition is cleared and the wakeup source event is delivered. </li>
</ul>
<p>In all cases, the wakeup event is delivered by the UM context thread.</p>
<p>However, note that typically a separate thread (created by the application) is calling the non-blocking "send" function. There can be cases where the call to "send" detects the flow control condition, but before it can return <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a75f0f83b8684df30d9816210cc20b4b0">LBM_EWOULDBLOCK</a>, the context thread clears the condition and delivers the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#aa905cb268bbee255c71b74694370fe61">LBM_SRC_EVENT_WAKEUP</a> event via the the application's source callback. From the application's point of view, this represents the notification of UM's internal state transitions is reversed, with the wakeup appearing to happen <em>before</em> the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a75f0f83b8684df30d9816210cc20b4b0">LBM_EWOULDBLOCK</a>. This potential reversal of event notification is a natural consequence of the design of UM and is not considered a bug. The application must be carefully coded to take this race condition into account.</p>
<p>For example, here's a modified excerpt from the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/example.tag:../example/" href="../example/index.html#examplelbmsrc_c">Example lbmsrc.c</a> program (see similar code in <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/java_example.tag:../java_example/" href="../java_example/index.html#examplelbmsrc_java">Java</a> and <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/dotnet_example.tag:../dotnet_example/" href="../dotnet_example/index.html#examplelbmsrc_cs">.NET</a>): </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> blocked = 0;  <span class="comment">/* global state variable. */</span></div><div class="line">...</div><div class="line"></div><div class="line">int handle_src_event(<a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a717ff27bb10ae7800330c21d810dffb8">lbm_src_t</a> *src, <span class="keywordtype">int</span> event, <span class="keywordtype">void</span> *extra_data, <span class="keywordtype">void</span> *clientd)</div><div class="line">{</div><div class="line">    <span class="keywordflow">switch</span> (event) {</div><div class="line">    <span class="keywordflow">case</span> <a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#aa905cb268bbee255c71b74694370fe61">LBM_SRC_EVENT_WAKEUP</a>:</div><div class="line">        blocked = 0;</div><div class="line">        <span class="keywordflow">break</span>;</div><div class="line">...</div></div><!-- fragment --><p>The wakeup event indicates that a blocked source is no longer blocked. This example uses a global variable to track the blocked state of the source, so the wakeup event clears it.</p>
<p>Here is the application sending code: </p><div class="fragment"><div class="line"><span class="comment">/* Assume that the source is blocked. */</span></div><div class="line">blocked = 1;</div><div class="line">err = <a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send</a>(src, message, opts-&gt;msglen, LBM_SRC_NONBLOCK);</div><div class="line"><span class="keywordflow">if</span> (err == LBM_FAILURE) {</div><div class="line">    <span class="keywordflow">if</span> (<a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#af3a827eb26d87be5b1a6b9fd3a4b63aa">lbm_errnum</a>() == LBM_EWOULDBLOCK) {</div><div class="line">        <span class="comment">/* Source is blocked, message did not send. The &quot;lbmsrc.c&quot; example</span></div><div class="line"><span class="comment">         * reacts by spin-waiting for &quot;blocked&quot; to be set to zero, and then</span></div><div class="line"><span class="comment">         * looping back to re-send the same message.</span></div><div class="line"><span class="comment">         * Alternatively, you could simply return to do other work, and</span></div><div class="line"><span class="comment">         * re-send the message later when &quot;blocked&quot; is zero.</span></div><div class="line"><span class="comment">         * Note that it is possible that &quot;blocked&quot; is already zero at this point.</span></div><div class="line"><span class="comment">         */</span></div><div class="line">        }</div><div class="line">    }</div><div class="line">}</div><div class="line">blocked = 0;  <span class="comment">/* The message sent successfully; source is not blocked. */</span></div></div><!-- fragment --><p>The important part of this code is that the global "blocked" flag is set before* the call to <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a>. If you try to set it after the send function returns, the wakeup event might execute before your sending thread can set it. This will leave "blocked" set even though the wakeup event has already been delivered.</p>
<p>Note that there should be a separate "blocked" variable for each source object the application creates. This flag would typically be placed in a "clientd" structure instead of being a process-global variable.</p>
<dl class="section warning"><dt>Warning</dt><dd>The above example code is NOT safe for multiple application threads sending to the same source object.</dd></dl>
<p><br />
 </p>
<h2><a class="anchor" id="sourceflightnotificationevent"></a>
Source Flight Notification Event&nbsp;&nbsp;<small><a href="#sourceflightnotificationevent">&lt;-</a></small></h2>
<p>The source event <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a6d75dfecae9635b61c289efa3a8aa017">LBM_SRC_EVENT_FLIGHT_SIZE_NOTIFICATION</a> can be delivered to the application when a source is configured for persistence and has set its <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpultramessagingpersistence.html#umeflightsizebehaviorsource">ume_flight_size_behavior (source)</a> to "notify".</p>
<p>As the application sends messages, the flight size increases, and as the Store delivers message stability ACKs, the flight size decreases. As the application sends messages increasing the flight size, if it crosses a flight size limit, the internal flight size state for that source becomes "over" and the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a6d75dfecae9635b61c289efa3a8aa017">LBM_SRC_EVENT_FLIGHT_SIZE_NOTIFICATION</a> event is delivered with state <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a117eda1a0792b41a8a6ffbab7becf834">LBM_SRC_EVENT_FLIGHT_SIZE_NOTIFICATION_STATE_OVER</a>.</p>
<p>Subsequently, as Store stability acknowledgements are delivered to the source decreasing the flight size, if it goes below the flight size limits, the internal flight size state for that source becomes "under" and the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a6d75dfecae9635b61c289efa3a8aa017">LBM_SRC_EVENT_FLIGHT_SIZE_NOTIFICATION</a> event is delivered with state <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#adf54f7b5bcae5127f6cf814945a62ab9">LBM_SRC_EVENT_FLIGHT_SIZE_NOTIFICATION_STATE_UNDER</a>.</p>
<p>However, these two events are delivered by separate threads. The "OVER" notification is delivered by the application thread calling the "send" function, and the "UNDER" notification is delivered by the UM context receiving the Store's stability ACK. There can be cases where the application will process the two events concurrently, or even in the reverse order that the internal state changed. I.e. the actual order of state transitions might be "UNDER", "OVER", "UNDER, but the application will process
the events as "UNDER", "UNDER", "OVER". This potential reversal of event notification is a natural consequence of the design of UM and is not considered a bug. The application must be carefully coded to take this race condition into account.</p>
<p>Here is some example code to demonstrate a possible use pattern: </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> over_delivered = 0;  <span class="comment">/* global. */</span></div><div class="line"><span class="keywordtype">int</span> under_delivered = 0;  <span class="comment">/* global. */</span></div><div class="line">...</div><div class="line"></div><div class="line">int handle_src_event(<a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a717ff27bb10ae7800330c21d810dffb8">lbm_src_t</a> *src, <span class="keywordtype">int</span> event, <span class="keywordtype">void</span> *extra_data, <span class="keywordtype">void</span> *client_data)</div><div class="line">{</div><div class="line">    <span class="keywordflow">switch</span> (event) {</div><div class="line">    <span class="keywordflow">case</span> <a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a6d75dfecae9635b61c289efa3a8aa017">LBM_SRC_EVENT_FLIGHT_SIZE_NOTIFICATION</a>:</div><div class="line">    {</div><div class="line">        <a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/structlbm__src__event__flight__size__notification__t__stct.html">lbm_src_event_flight_size_notification_t</a> *notification = (<a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/structlbm__src__event__flight__size__notification__t__stct.html">lbm_src_event_flight_size_notification_t</a> *)extra_data;</div><div class="line">        <span class="keywordflow">if</span> (notification-&gt;<a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/structlbm__src__event__flight__size__notification__t__stct.html#a4805e12cbac941f189ea511d48d02445">state</a> == LBM_SRC_EVENT_FLIGHT_SIZE_NOTIFICATION_STATE_OVER) {</div><div class="line">            over_delivered = 1;</div><div class="line">        }</div><div class="line">        <span class="keywordflow">else</span> {  <span class="comment">/* state == LBM_SRC_EVENT_FLIGHT_SIZE_NOTIFICATION_STATE_UNDER */</span></div><div class="line">            under_delivered = 1;</div><div class="line">        }</div><div class="line">        <span class="keywordflow">break</span>;</div><div class="line">...</div></div><!-- fragment --><p>This example uses two global state variables to indicate when the two notification events have been delivered.</p>
<p>Here's some code that checks to see if flight size is "over" and wait for it to be "under" before sending: </p><div class="fragment"><div class="line"><span class="keywordflow">if</span> (over_delivered) {</div><div class="line">    <span class="keywordflow">while</span> (! under_delivered) {</div><div class="line">        <span class="comment">/* While waiting for &quot;under&quot;, can do other things. */</span></div><div class="line">    }</div><div class="line">    <span class="comment">/* Both &quot;over&quot; and &quot;under&quot; events were delivered. Reset them so we can send again. */</span></div><div class="line">    over_delivered = 0;</div><div class="line">    under_delivered = 0;</div><div class="line">}</div><div class="line"><span class="comment">/* Send next message. */</span></div><div class="line">err = <a class="codeRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send</a>(src, message, opts-&gt;msglen, LBM_SRC_NONBLOCK);</div></div><!-- fragment --><p>This code works because the "over" event is delivered synchronously with the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a> function. If <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a91f4b9cb04fe1323ec56833211cc5cb7">lbm_src_send()</a> exceeds the flight size, UM guarantees that the "over" event will be delivered before the send function returns. This guarantee enables the code to handle the "under" event being delivered before the "over" event.</p>
<p>Note that there should be a separate "over_delivered" and "under_delivered" variables for each source object the application creates. These flags would typically be placed in a "clientd" structure instead of being process-global variables.</p>
<p>Also note that unlike the "wakeup" event (described <a class="el" href="fundamentalconcepts.html#sourceflightnotificationevent">above</a>), getting an "over" event does not prevent the "send" function from successfully sending the message. The point of setting <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpultramessagingpersistence.html#umeflightsizebehaviorsource">ume_flight_size_behavior (source)</a> to "notify" is to allow the publisher to continue sending in spite of exceeding flight size. But note that doing this can prevent UM from guaranteeing delivery of messages.</p>
<dl class="section warning"><dt>Warning</dt><dd>The above example code is NOT safe for multiple application threads sending to the same source object.</dd></dl>
<p><br />
 </p>
<h1><a class="anchor" id="ratecontrols"></a>
Rate Controls&nbsp;&nbsp;<small><a href="#ratecontrols">&lt;-</a></small></h1>
<p>For UDP-based communications (LBT-RU, LBT-RM, and <a class="el" href="fundamentalconcepts.html#topicresolutionoverview">Topic Resolution</a>), UM network stability is ensured through the use of rate controls. Without rate controls, sources can send UDP data so fast that the network can be flooded. Using rate controls, the source's bandwidth usage is limited. If the source attempts to exceed its bandwidth allocation, it is slowed down.</p>
<p>Setting the rate controls properly requires some planning; see <a href="https://www.informatica.com/downloads/1568_high_perf_messaging_wp/Topics-in-High-Performance-Messaging.htm#GROUP-RATE-CONTROL">Topics in High Performance Messaging, Group Rate Control</a> for details.</p>
<p>Ultra Messaging's rate limiter algorithms are based on dividing time into intervals (configurable), and only allowing a certain number of bits of data to be sent during each interval. That number is divided by the number of intervals per second. For example, a limit of 1,000,000 bps and an interval of 100 ms results in the limiter allowing 100,000 bits to be sent during each interval. Dividing by 8 to get bytes gives 12,500 bytes per interval.</p>
<p>Data are not sent over a network as individual bytes, but rather are grouped into datagrams. Since it is not possible to send only part of a datagram, the rate limiter algorithm needs to decide what to do if an outgoing datagram would exceed the number of bits allowed during the current time interval. The data transport rate limiter algorithm, for LBT-RM and LBT-RU, differs from the Topic Resolution rate limiter algorithm.</p>
<p><br />
 </p>
<h2><a class="anchor" id="transportratecontrol"></a>
Transport Rate Control&nbsp;&nbsp;<small><a href="#transportratecontrol">&lt;-</a></small></h2>
<p>With data transport, if an application sends a message and the outgoing datagram would exceed the number of bits allowed during the current time interval, that datagram is queued and the transport type is put into a "blocked" state in the current context. Note that success is returned to the application, even though the datagram has not yet been transmitted.</p>
<p>However, any subsequent sends within the same time interval will not queue, but instead will either block (for blocking sends), or return the error <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/api.tag:../API/" href="../API/lbm_8h.html#a75f0f83b8684df30d9816210cc20b4b0">LBM_EWOULDBLOCK</a> (for non-blocking sends). When the time interval expires, the context thread will refresh the number of allowable bits, send the queued datagram, and unblock the transport type.</p>
<p>Note that for very small settings of transport rate limit, the end-of-interval refresh of allowable bits may still not be enough to send a queued full datagram. In that case, the datagram will remain on the queue for additional intervals to pass, until enough bits have accumulated to send the queued datagram. However, it would be very unusual for a transport rate limit to be set that small.</p>
<p><b>Transport Rate Control Configuration</b></p>
<p>Configuration parameters of interest are: </p><ul>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmoperation.html#transportlbtrmrateintervalcontext">transport_lbtrm_rate_interval (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmoperation.html#transportlbtrmdataratelimitcontext">transport_lbtrm_data_rate_limit (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtrmoperation.html#transportlbtrmretransmitratelimitcontext">transport_lbtrm_retransmit_rate_limit (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtruoperation.html#transportlbtrurateintervalcontext">transport_lbtru_rate_interval (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtruoperation.html#transportlbtrudataratelimitcontext">transport_lbtru_data_rate_limit (context)</a> </li>
<li>
<a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grptransportlbtruoperation.html#transportlbtruretransmitratelimitcontext">transport_lbtru_retransmit_rate_limit (context)</a> </li>
</ul>
<p><b>LBM_EWOULDBLOCK</b></p>
<p>When non-blocking sends are done (LBM_SRC_NONBLOCK), the send can fail with an error number of LBM_EWOULDBLOCK. This means you have exceeded the rate limit and must wait before sending the message.</p>
<p>Most applications don't need to handle this because they use blocking sends. Instead of returning a failure when the rate limit is exceeded, the send function sleeps until the transport becomes unblocked again, at which point the UM context thread wakes up the sleeping send call. However, there are times that blocking behavior is not permitted. For example, if the application is running as a UM Context thread callback (timer, receiver event, source event, etc), then only non-blocking sends are allowed.</p>
<p>To assist the application in retrying the message send, the UM context thread will deliver the LBM_SRC_EVENT_WAKEUP source event to the application. (This only happens if a non-blocking send was tried and failed with LBM_EWOULDBLOCK.) The application can use that event to re-try sending the message.</p>
<p>Alternatively, exceeding the rate limit can be avoided by increasing the configured rate limit and/or rate interval. This can reduce latency, but also increases the risk of packet loss.</p>
<p>The rate limit controls how many bits can be transmitted during a given second of time. The rate interval controls the "shape" of the transmissions over the second of time.</p>
<p><b>Adjusting the Rate Interval</b></p>
<p>A long rate interval will allow intense bursts of traffic to be sent, which can overload switch port queues or NIC ring buffers, leading to packet loss. A short rate interval will reduce the intensity of the bursts, spreading the burst over a longer time, but does so by introducing short delays in the transmissions, which increases message latency.</p>
<p>The LBT-RM default rate interval of 10 milliseconds was chosen to be reasonably "safe" in terms of avoiding loss, at the expense of possible transmission delays. Latency-sensitive applications may require a larger value, but increases the risk of switch or NIC loss.</p>
<p>There is no analytical way of choosing an optimal value for the rate interval. Latency-sensitive users should test different values with intense bursts to find the largest value which avoids packet loss.</p>
<p><br />
 </p>
<h2><a class="anchor" id="topicresolutionratecontrol"></a>
Topic Resolution Rate Control&nbsp;&nbsp;<small><a href="#topicresolutionratecontrol">&lt;-</a></small></h2>
<p>With UDP-based Topic Resolution ("TR"), the algorithm acts differently. It is designed to allow at least one datagram per time interval, and is allowed to exceed the rate limit by at most one topic's worth. Thus, the TR rate limiter value should only be considered a "reasonably accurate" approximation.</p>
<p>This approximation can seem very inaccurate at very small rate limits. As an extreme example, suppose that a user configures the <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/config.tag:../Config/" href="../Config/grpudpbasedresolveroperation.html#resolversustainadvertisementbpscontext">sustaining advertisement rate limiter</a> to 1 bit per second. Since the TR rate limiter allows at least one Advertisement (TIR) to be sent per interval, and a TIR of a 240-character topic creates a datagram about 400 bytes long (exact size depends on user options), ten of those per second is 32,000 bits, which is over 3 million percent of the desired rate. This sounds extreme, but understand that this works out to only 10 packets per second, a trivial load for modern networks. In practice, the minimum <em>effective</em> rate limit works out to be one datagram per interval.</p>
<p>For details of Topic Resolution, see <a class="el" href="topicresolutiondescription.html">Topic Resolution Description</a>.</p>
<p><br />
 </p>
<h1><a class="anchor" id="operationalstatistics"></a>
Operational Statistics&nbsp;&nbsp;<small><a href="#operationalstatistics">&lt;-</a></small></h1>
<p>UM maintains a variety of transport-level statistics which gives a real-time snapshot of UM's internal handling. For example, it gives counts for transport messages transferred, bytes transferred, retransmissions requested, unrecoverable loss, etc.</p>
<p>The UM monitoring API provides framework to allow the convenient gathering and transmission of UM statistics to a central monitoring point. See <a class="elRef" doxygen="/29W/Amun/home/jenkins/backup_exclude.areas/builds/UMQ_6.15/doc/Design/operations.tag:../Operations/" href="../Operations/monitoring.html">Monitoring</a> for more information.</p>
<p><br />
 </p>
<h1><a class="anchor" id="immediatemessaging"></a>
Immediate Messaging&nbsp;&nbsp;<small><a href="#immediatemessaging">&lt;-</a></small></h1>
<p>UM has an alternate form of messaging that deviates from the normal publish/subscribe paradigm. An "immediate message" can be sent and received without the need for topic resolution. Note that immediate messaging is less efficient than normal source-based messaging and will not provide the same low latency and high throughput.</p>
<p>There are two forms of immediate messaging: </p><ul>
<li>
<a class="el" href="umfeatures.html#unicastimmediatemessaging">Unicast Immediate Messaging</a> (UIM) - TCP-based point-to-point. </li>
<li>
<a class="el" href="umfeatures.html#multicastimmediatemessaging">Multicast Immediate Messaging</a> (MIM) - flooding-based multicast; use rarely. </li>
</ul>
<p><br />
<br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
 <br />
</p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.11-->
</body>
</html>
